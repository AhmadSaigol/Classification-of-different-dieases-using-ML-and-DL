{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:55.183128Z","iopub.execute_input":"2023-01-15T02:26:55.183596Z","iopub.status.idle":"2023-01-15T02:26:55.210704Z","shell.execute_reply.started":"2023-01-15T02:26:55.183495Z","shell.execute_reply":"2023-01-15T02:26:55.209484Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2 \nimport os\n\nfrom collections import OrderedDict\n\nimport torch\nfrom torch import nn\nfrom torchvision.io import read_image,ImageReadMode\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold, KFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, f1_score, recall_score\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport matplotlib.image as mpimg\n\nimport json\n\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:02:14.918950Z","iopub.execute_input":"2023-01-15T04:02:14.919545Z","iopub.status.idle":"2023-01-15T04:02:14.931895Z","shell.execute_reply.started":"2023-01-15T04:02:14.919489Z","shell.execute_reply":"2023-01-15T04:02:14.930536Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"* load training labels.txt file and split the data set into train and valid dataset using simple Stratified or kfold stratified.\n* Setup Dataset and Dataloader in Pytorch for loading training, validation, test and noisy dataset and for applying transformations and data augmentation\n\nTransformations (examples):\n   * Normalize\n   * resize\n   * zero centering (AlexNet, VGG etc) during training and depedning the method, save values calculated during training and use them to apply on validation, testing and training\n   * denoise the image (if required...how to know that?)\n       \nData Augmentation (examples):\n   * cropping, scaling images, similar to ResNet,or maybe something else etc (which ones to use will depend upon type of images we expect in the real world...or in our project in noisy test/test dataset)\n   * If we know somehow what kind of noise will be there in noisy_test/test dataset (e.g. gaussion noise, salt and pepper, etc) then we can add something similar to training dataset to create more images and use them to train the model as well\n\nMake use of GPU\n\nSave all the hyperparameters somewhere. ","metadata":{}},{"cell_type":"markdown","source":"## Split the data","metadata":{}},{"cell_type":"code","source":"def split_data(y, split_type, test_size=0.3, n_folds=5):\n    \"\"\"\n    Split the datasets\n\n    Parameters:\n        y: array of labels and image ids with shape (num_images, 2)\n        split_type: type of splitting (\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\")\n        test_size: fraction of data for testing (default=0.3)\n        n_folds: number of folds (default=5)\n    Returns:\n        train_labels: numpy array of shape(folds, num_images, 2)\n        valid_labels: numpy array of shape(folds, num_images, 2)\n    \n    \"\"\"\n\n    if split_type==\"simple\":\n       \n        # shuffle data before split\n        ss = ShuffleSplit(n_splits=1, test_size=test_size)\n\n        for train_index, valid_index in ss.split(X=np.ones(len(y))):\n            y_train = np.expand_dims(y[train_index], axis=0)\n            y_valid = np.expand_dims(y[valid_index], axis=0)\n    \n    elif split_type==\"simpleStratified\":\n\n        # shuffle data before split\n        ss = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n\n        for train_index, valid_index in ss.split(X=np.ones(len(y)), y=y[:,1]):\n            y_train = np.expand_dims(y[train_index], axis=0)\n            y_valid = np.expand_dims(y[valid_index], axis=0)\n\n    \n    elif split_type==\"kfold\":\n\n        # shuffle data before creating folds\n        kf = KFold(n_splits=n_folds, shuffle=True)\n        \n        y_train = []\n        y_valid = []\n        for train_index, valid_index in kf.split(X=np.ones(len(y))):\n            y_train.append(y[train_index])\n            y_valid.append(y[valid_index])\n        \n        y_train = np.array(y_train)\n        y_valid = np.array(y_valid)\n\n    \n    elif split_type == \"kfoldStratified\":\n\n        # shuffle data before creating folds\n        skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n        y_train = []\n        y_valid = []\n        \n        for train_index, valid_index in skf.split(X=np.ones(len(y)), y=y[:,1]):\n\n            y_train.append(y[train_index])\n            y_valid.append(y[valid_index])\n\n        y_train = np.array(y_train)\n        y_valid = np.array(y_valid)\n\n    else:\n        raise ValueError(f\"Unknown value encountered for the parameter 'split_type' during splitting of the data. received {split_type}\")\n\n    return y_train, y_valid","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.158584Z","iopub.execute_input":"2023-01-15T02:26:58.159132Z","iopub.status.idle":"2023-01-15T02:26:58.171942Z","shell.execute_reply.started":"2023-01-15T02:26:58.159098Z","shell.execute_reply":"2023-01-15T02:26:58.170992Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n#path_to_labels = \"/kaggle/input/ismdatasetforclassificationofdieases/code_testing/code_testing/train_binary.txt\"\n#split_type = \"kfoldStratified\"\n#test_size= 0.2\n#n_folds = 2\n#img_ids_labels = np.loadtxt(path_to_labels, dtype=str, delimiter=\" \")\n#y_train, y_valid = split_data(y=img_ids_labels, split_type=split_type, test_size=test_size, n_folds=n_folds)  \n#print(\"train\")\n#print(y_train.shape)\n#print(\"valid\")\n#print(y_valid.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.174808Z","iopub.execute_input":"2023-01-15T02:26:58.175281Z","iopub.status.idle":"2023-01-15T02:26:58.186279Z","shell.execute_reply.started":"2023-01-15T02:26:58.175244Z","shell.execute_reply":"2023-01-15T02:26:58.185292Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Encode labels","metadata":{}},{"cell_type":"code","source":"def label_encoder(y, classes, to_numbers):\n    \"\"\"\n    encodes target labels with value between 0 and n_classes-1 and vice versa\n\n    Parameter:\n        y: labels of numpy array (num_images,)\n        classes: numpy array of names of classes\n        to_numbers True/False: whether to transfer from string to numbers or vice versa\n\n    Returns:\n        result: encoded labels of numpy array (num_images, 1)\n                or labels of numpy array (num_images, 1)\n    \"\"\"\n\n    le = preprocessing.LabelEncoder()\n    \n    if type(classes).__name__ == 'list':\n        classes = np.array(classes)\n    le.classes_ = classes\n    \n    if to_numbers:\n        return le.transform(y.ravel())\n    else:\n        return le.inverse_transform(y.ravel().astype(int)) \n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.189346Z","iopub.execute_input":"2023-01-15T02:26:58.189742Z","iopub.status.idle":"2023-01-15T02:26:58.200319Z","shell.execute_reply.started":"2023-01-15T02:26:58.189708Z","shell.execute_reply":"2023-01-15T02:26:58.199250Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#classes = np.array([\"Normal\", \"COVID\", \"pneumonia\", \"Lung_Opacity\"]) \n#classes = np.array([\"NO_COVID\", \"COVID\"])\n#for nf in range(n_folds):\n#    y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=True)\n#    y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=True)\n\n#print(\"y-train: \", y_train.shape)\n#print(\"y-valid: \", y_valid.shape)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.201863Z","iopub.execute_input":"2023-01-15T02:26:58.202314Z","iopub.status.idle":"2023-01-15T02:26:58.211204Z","shell.execute_reply.started":"2023-01-15T02:26:58.202278Z","shell.execute_reply":"2023-01-15T02:26:58.210239Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Dataset ","metadata":{}},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    \"\"\"\n    \n    Parameters:\n        labels: labels of shape(num_images, 2) or (num_images, 1)\n        path_to_images: path to the folder containing the images\n        transform: transform to be applied on a sample\n        \n        When combined with dataloader, it returns:\n            image: tensor of shape (batch, 1, height, width)\n            label: tensor of shape (batch)\n    \n    \"\"\"\n    def __init__(self, labels, path_to_images, transform=None):\n        self.img_labels = labels\n        self.img_dir = path_to_images\n        self.transform = transform\n\n    def __len__(self):\n        return self.img_labels.shape[0]\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.img_dir, self.img_labels[index, 0])\n        \n        # read image \n        image = read_image(img_path, ImageReadMode.GRAY).float()\n        \n        if self.img_labels.shape[-1]==2:\n            label = self.img_labels[index, 1].astype(int)\n        else:\n            label = -1.0 # just place holder for valid data\n            \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:12:15.234578Z","iopub.execute_input":"2023-01-15T04:12:15.235962Z","iopub.status.idle":"2023-01-15T04:12:15.246267Z","shell.execute_reply.started":"2023-01-15T04:12:15.235902Z","shell.execute_reply":"2023-01-15T04:12:15.245256Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"def data_preprocessing(transformations):\n    \"\"\"\n    Returns compose of transforms\n    \n    Parameters:\n        transformations: Ordered dict with structure\n        transformations[\"transform_1\"] = {}\n        transformations[\"transform_1\"][\"name\"] = value\n        transformations[\"transform_1\"][\"parameter_1\"] = value\n        transformations[\"transform_1\"][\"parameter_2\"] = value\n        \n        transformations[\"transform_2\"] = {}\n        transformations[\"transform_2\"][\"name\"] = value\n        transformations[\"transform_2\"][\"parameter_1\"] = value\n        transformations[\"transform_2\"][\"parameter_2\"] = value\n        \n    Currently supports transformation: \n        \"normalize\": \n                    keys: mean (default=0) \n                           std (default=255), \n        \"resize\": \n                keys: output_shape, \n                      \n    \n    \n    # train transform will be different from valid transform (CHECK)\n    \"\"\"\n    \n    preprocess = []\n    \n    for tran in transformations.keys():\n        tran_name = transformations[tran][\"name\"]\n        \n        # normalization\n        if tran_name == \"normalize\":\n            norm = transformations[tran].keys()\n            if \"mean\" in norm:\n                mean = [transformations[tran][\"mean\"]]\n            else:\n                mean = [0]\n            \n            if \"std\" in norm:\n                std = [transformations[tran][\"std\"]]\n            else:\n                std = [255]\n                \n            preprocess.append(transforms.Normalize(mean=mean,\n                             std=std))\n        # resize\n        elif tran_name == \"resize\":\n            resize = transformations[tran].keys()\n            \n            if \"output_shape\" in resize:\n                output_shape = transformations[tran][\"output_shape\"]\n            else:\n                raise ValueError(\"Output shape must be provided while resizing\")\n            \n            preprocess.append(transforms.Resize(output_shape))\n        \n        else:\n            raise ValueError(\"Unknown transformation passed\")\n    \n    return transforms.Compose(preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.224627Z","iopub.execute_input":"2023-01-15T02:26:58.225323Z","iopub.status.idle":"2023-01-15T02:26:58.236711Z","shell.execute_reply.started":"2023-01-15T02:26:58.225285Z","shell.execute_reply":"2023-01-15T02:26:58.235667Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n#path_to_images = \"/kaggle/input/ismdatasetforclassificationofdieases/code_testing/code_testing/train\"\n#batch_size = 2\n\n#data_transform = OrderedDict()\n#data_transform[\"t1\"] = {}\n#data_transform[\"t1\"][\"name\"] = \"normalize\"\n#data_transform[\"t1\"][\"mean\"] = 0\n#data_transform[\"t1\"][\"std\"] = 255\n#data_transform[\"t2\"] = {}\n#data_transform[\"t2\"][\"name\"] = \"resize\"\n#data_transform[\"t2\"][\"output_shape\"] = (5,5)\n\n\n#data_transforms = data_preprocessing(data_transform)\n\n#data_transforms = transforms.Compose([\n#        transforms.RandomSizedCrop(224),\n#        transforms.RandomHorizontalFlip(),\n#        transforms.ToTensor(),\n#        transforms.Normalize(mean=[0],\n#                             std=[255]),\n#        transforms.Resize((250,250))\n#    ])\n\n\n\n#for fold in range(n_folds):\n\n    #train_data = ImageDataset(y_train[fold], path_to_images, transform=data_transforms)\n    #train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n#    print(len(train_dataloader))\n #   for x, y in train_dataloader:\"\"\"\n  #  #print(f\"Fold No: {fold} Train: x shape: {x.shape} y_shape: {y.shape}\")\n   # \"\"\"\n   # valid_data = ImageDataset(y_valid[fold], path_to_images, transform=data_transforms)\n   # valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n  #  print(len(valid_dataloader))\n  #  for x, y in valid_dataloader:\"\"\"\n#print(f\"Fold No: {fold} Valid: x shape: {x.shape} y_shape: {y.shape}\")\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.238585Z","iopub.execute_input":"2023-01-15T02:26:58.239272Z","iopub.status.idle":"2023-01-15T02:26:58.257372Z","shell.execute_reply.started":"2023-01-15T02:26:58.239234Z","shell.execute_reply":"2023-01-15T02:26:58.256347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Setup Model","metadata":{}},{"cell_type":"markdown","source":"Model setup could be done using the following ways:\n   1. Model with user defined layers.\n   2. Pretrained Model\n   3. Ensemble of models\n\nLayers could be:\n   * Convolution\n   * Activation (Linear, ReLU, LReLU, PReLU, tanh, etc)\n   * Pooling (Max, Average, Global)\n   * Fully Connected Layer\n   * Dropout\n   * Batch Normalization\nand many others\n\nThese layers could be added to the any model. Which layers to be used can be find by hit and trial method or from literature\n\nPretrained Model could be:\n   * VGG\n   * ResNet\n   * GoogleLeNet\nand many others.\n\nWhich pretrained model to use can be find by literature and how many layers to be trained can be determined by hit and trial or from literature.\n\nWe can always combine pretrained model with own custom model.\n\nMake use of GPU\n\nSave the model, and all the hyperparamters and all the info that may be learned during training and may be required in testing phase","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    \"\"\"\n    Sets up the model\n    layers: OrderedDict with format:\n        layers[\"layer_1\"] = {}\n        layers[\"layer_1\"][\"name\"] = value\n        layers[\"layer_1\"][\"parameter1\"] = value\n        layers[\"layer_1\"][\"parameter2\"] = value\n        \n        layers[\"layer_2\"] = {}\n        layers[\"layer_2\"][\"name\"] = value\n        layers[\"layer_2\"][\"parameter1\"] = value\n        layers[\"layer_2\"][\"parameter2\"] = value\n        \n    currently supports layer names. \"linear\", \"flatten\", \"relu\", \"lrelu\"\n    \n    output layer must be added as well\n    \"\"\"\n    def __init__(self, input_shape, layers):\n        super(Model, self).__init__()\n        self.input_shape = input_shape\n        self.layers = layers\n        self.seq_model = nn.Sequential(self.get_model())\n    \n    def forward(self, x):\n        return self.seq_model(x)\n    \n    def get_model(self):\n        \n        arch = []\n        self.layer = \"Init\"\n        self.pre_layer_output = self.input_shape  \n        \n        for layer in self.layers.keys():\n            self.layer = layer\n            layer_name = self.layers[layer][\"name\"] \n            \n            # Linear Layer \n            if layer_name == \"linear\":\n                arch.append(self.add_linear(self.layers[layer]))\n                \n            # ReLU\n            elif layer_name == \"relu\":\n                arch.append(self.add_relu(self.layers[layer]))\n                \n            # LeakyReLU\n            elif layer_name == \"lrelu\":\n                arch.append(self.add_lrelu(self.layers[layer]))\n            \n            # flatten layer\n            elif layer_name == \"flatten\":\n                arch.append(self.add_flatten(self.layers[layer]))\n            \n            else:\n                pass\n\n        return OrderedDict(arch)\n    \n    def add_linear(self, parameters):\n        \"\"\"\n        Adds Linear Layer\n        \n        parameters: dict containing keys:\n            neurons: number of neurons in layer\n            bias: whether to add bias term (default = True)\n        \"\"\"\n        param = parameters.keys()\n        \n        if \"neurons\" in param:\n            neurons = parameters[\"neurons\"]\n        else:\n            raise ValueError (\"Number of neurons must be provided\")\n            \n        if \"bias\" in param:\n            bias = parameters[\"bias\"]\n        else:\n            bias = True\n            \n        linear = (f'{self.layer}', nn.Linear(\n                                    in_features = self.pre_layer_output, \n                                    out_features= neurons, \n                                    bias = bias))\n        self.pre_layer_output = neurons\n        \n        return linear\n    \n    def add_relu(self, parameters):\n        \"\"\"\n        Adds ReLU layer\n        \"\"\"\n        return (f'{self.layer}', nn.ReLU())\n    \n    def add_lrelu(self, parameters):\n        \"\"\"\n        Adds ReLU layer\n        Parameters:\n            alpha: negative slope (default = 1e-2)\n        \"\"\"\n        if \"alpha\" in parameters.keys():\n            alpha = parameters[\"alpha\"]\n        else:\n            alpha = 1e-2\n        return (f'{self.layer}', nn.LeakyReLU(alpha))\n    \n    def add_flatten(self, parameters):\n        \"\"\"\n        Adds Flatten layer\n        \"\"\"\n        flatten_layer = (f'{self.layer}', nn.Flatten())\n        in_shape = self.pre_layer_output\n        \n        # calculate output shape\n        out_shape = 1\n        for d in range(len(in_shape)):\n            out_shape *= in_shape[d]\n        \n        self.pre_layer_output = out_shape\n        \n        return flatten_layer\n        ","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.259233Z","iopub.execute_input":"2023-01-15T02:26:58.259995Z","iopub.status.idle":"2023-01-15T02:26:58.277593Z","shell.execute_reply.started":"2023-01-15T02:26:58.259955Z","shell.execute_reply":"2023-01-15T02:26:58.276625Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# order is important\n#layers = OrderedDict()\n\n#layers[\"flatten1\"] = {}\n#layers[\"flatten1\"][\"name\"] = \"flatten\"\n\n# layer 1\n#layers[\"linear1\"] = {}\n#layers[\"linear1\"][\"name\"] = \"linear\"\n#layers[\"linear1\"][\"neurons\"] = 10\n\n# layer 2\n#layers[\"relu1\"] = {}\n#layers[\"relu1\"][\"name\"] = \"relu\"\n\n# layer 3\n#layers[\"linear2\"] = {}\n#layers[\"linear2\"][\"name\"] = \"linear\"\n#layers[\"linear2\"][\"neurons\"] = 8\n#layers[\"linear2\"][\"bias\"] = False\n\n# layer 4\n#layers[\"lrelu2\"] = {}\n#layers[\"lrelu2\"][\"name\"] = \"lrelu\"\n#layers[\"lrelu2\"][\"alpha\"] = 1\n\n# layer 5\n#layers[\"linear3\"] = {}\n#layers[\"linear3\"][\"name\"] = \"linear\"\n#layers[\"linear3\"][\"neurons\"] = 2\n\n# layer 6\n#layers[\"relu3\"] = {}\n#layers[\"relu3\"][\"name\"] = \"relu\"\n\n\n\n#model = Model((5,5), layers )\n\n#print(model)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.282434Z","iopub.execute_input":"2023-01-15T02:26:58.282962Z","iopub.status.idle":"2023-01-15T02:26:58.290824Z","shell.execute_reply.started":"2023-01-15T02:26:58.282935Z","shell.execute_reply":"2023-01-15T02:26:58.289808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Setup loss function\n* Binary entropy loss \n* cross entropy loss\n* weighted loss function\n* maybe something from literature","metadata":{}},{"cell_type":"code","source":"def setup_loss(parameters):\n    \"\"\"\n    Returns loss function\n    \n    Parameters:\n        parameters: dict with the following keys:\n            \"type\": \"binary\" or \"cross_entropy\"\n            \"use_weighted_loss\": default = False\n            \"class_weights\": weights for each class (list)\n        \n        Note: currently the loss function is basically Softmax + Log Loss.\n        loss_type == \"binary\" assumes that output layer has single neuron\n        When loss_type == \"binary\", class weights must be equal to [num_of_neg_samples/num_of_pos_samples]\n        else: class_weights can be list containing any value but length of class_weights must be equal to number of classes\n        \n    \"\"\"\n    \n    loss_keys = parameters.keys()\n    \n    if \"type\" in loss_keys:\n        loss_type = parameters[\"type\"]\n    else:\n        raise ValueError (\"'loss_type' must be provided\")\n         \n    if \"use_weighted_loss\" in loss_keys:\n        use_weighted_loss = parameters[\"use_weighted_loss\"]\n    else:\n        use_weighted_loss = False\n    \n    if \"class_weights\" in loss_keys:\n        class_weights = parameters[\"class_weights\"]\n    else:\n        class_weights = []\n        \n    if use_weighted_loss and not class_weights:\n        raise ValueError(\"When using weighted loss, class weights must be provided\")\n        \n    class_weights = torch.tensor(class_weights).cuda()\n    \n    if loss_type == \"binary\":\n        \n        if use_weighted_loss:\n            loss_fnt = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n        else:\n            loss_fnt = nn.BCEWithLogitsLoss()\n    \n    elif loss_type == \"cross_entropy\":\n         \n        if use_weighted_loss:\n            loss_fnt= nn.CrossEntropyLoss(weight=class_weights)\n        else:\n            loss_fnt= nn.CrossEntropyLoss()\n            \n    else:\n        raise ValueError(\"Unknown Value for loss_type\")\n    \n    return loss_fnt\n    ","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.292467Z","iopub.execute_input":"2023-01-15T02:26:58.293464Z","iopub.status.idle":"2023-01-15T02:26:58.305741Z","shell.execute_reply.started":"2023-01-15T02:26:58.293426Z","shell.execute_reply":"2023-01-15T02:26:58.304581Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#loss_param = {}\n#loss_param[\"type\"] = \"cross_entropy\"\n#loss_param[\"use_weighted_loss\"] = True\n#loss_param[\"class_weights\"] = [8, 6]\n\n#loss_fnt = setup_loss(loss_param)\n#print(loss_fnt)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.307279Z","iopub.execute_input":"2023-01-15T02:26:58.308136Z","iopub.status.idle":"2023-01-15T02:26:58.322317Z","shell.execute_reply.started":"2023-01-15T02:26:58.308100Z","shell.execute_reply":"2023-01-15T02:26:58.321317Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Setup Optimizer\n* adam\n* SGD with momenteum\n* something from literature\n* regularization\n* learning rate change with time (if required) \n* betas","metadata":{}},{"cell_type":"code","source":"def setup_optimizer(model_parameters, optim_parameters):\n    \"\"\"\n    Setups Optimizer\n    \n    Parameters:\n        model_parameters: parameters of models that will be trained\n        \n        optim_parameters: dict with the following structure:\n            optim_parameters[\"name\"] = name of optimizer (adam or sgd)\n            optim_parameters[\"parameter1\"] = value\n            optim_parameters[\"parameter2\"] = value\n            \n        for Adam optimizer, it supports following keys:\n            \"betas\": default = (0.9,0.999)\n            \n        for SGD, it supports following keys.\n            \"momentum\":  (default = 0)\n            \"dampening\": (default=0)\n        \n        following keys are supported for both optimizers:\n            \"lr\": learning rate (default = 1e-3)\n            \"lmbda\": regularization (default = 0)     \n            \n    \"\"\"\n    \n    optim_keys=optim_parameters.keys()\n    \n    if \"name\" in optim_keys:\n        optim = optim_parameters[\"name\"]\n    else:\n        raise ValueError(\"'name' of the optimizer must be provided\")\n    \n    if \"lmbda\" in optim_keys:\n        lmbda = optim_parameters[\"lmbda\"]\n    else:\n        lmbda = 0\n    \n    if \"lr\" in optim_keys:\n        lr = optim_parameters[\"lr\"]\n    else: \n        lr = 1e-3\n    \n    if optim == \"adam\":\n        \n        if \"betas\" in optim_keys:\n            betas = optim_parameters[\"betas\"]\n        else:\n            betas = (0.9,0.999)\n        \n        optimizer = torch.optim.Adam(model_parameters,  lr=lr, betas=betas, amsgrad=True, weight_decay=lmbda)\n    \n    elif optim == \"sgd\":\n        \n        if \"momentum\" in optim_keys:\n            momentum = optim_parameters[\"momentum\"]\n        else:\n            momentum = 0\n        \n        if \"dampening\" in optim_keys:\n            dampening = optim_parameters[\"dampening\"]\n        else:\n            dampening = 0\n        \n        optimizer = torch.optim.SGD(model_parameters, momentum=momentum, dampening=dampening, weight_decay=lmbda)\n    else:\n        raise ValueError(\"Unknown name of the optimizer provided\")\n    \n    return optimizer","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.323804Z","iopub.execute_input":"2023-01-15T02:26:58.324883Z","iopub.status.idle":"2023-01-15T02:26:58.336119Z","shell.execute_reply.started":"2023-01-15T02:26:58.324844Z","shell.execute_reply":"2023-01-15T02:26:58.334987Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#optim_parameters = {}\n#optim_parameters[\"name\"] = \"adam\"\n#optimizer = setup_optimizer (model.parameters(), optim_parameters)\n#print(optimizer)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.337456Z","iopub.execute_input":"2023-01-15T02:26:58.338637Z","iopub.status.idle":"2023-01-15T02:26:58.350268Z","shell.execute_reply.started":"2023-01-15T02:26:58.338599Z","shell.execute_reply":"2023-01-15T02:26:58.349262Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"markdown","source":"## Accuracy ","metadata":{}},{"cell_type":"code","source":"def accuracy(y_true, y_pred, parameters):\n    \"\"\"\n    Calculates accuracy\n    \n    Parameters:\n        y_true: numpy array of shape (num_images,)\n        y_pred: numpy array of shape (num_images,)\n        parameters: dictionary with the following keys:\n            type: \"simple\" (default) or \"balanced\"\n    \n    Returns:\n        score: float\n        config:\n\n    Additional Notes:\n\n        Simple Accuracy: fraction of labels that are equal.\n        Balanced Accuracy: \n            Binary class: equal to the arithmetic mean of sensitivity (true positive rate) \n                            and specificity (true negative rate)\n                             = 1/2 ( (TP/TP+FN) + (TN/TN+FP))\n\n            Multiclass: the macro-average of recall scores per class\n                        recall for each class and then take the mean\n                        recall = TP /(TP+FN)\n\n            if the classifier predicts same label for all examples, the score will be equal to 1/num_classes (for binary: 0.5)\n            for more info, see\n                \"https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\"\n    \"\"\"\n\n    config={}\n    if \"type\" in parameters.keys():\n        accu_type = parameters[\"type\"]\n    else:\n        accu_type = \"simple\"\n\n    config[\"type\"] = accu_type\n    \n    if accu_type == \"simple\":\n        score = accuracy_score(y_true=y_true, y_pred=y_pred) \n    elif accu_type == \"balanced\":\n        score = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n    else:\n        raise ValueError(\"Unknown Value encountered for parameter 'type' while calculating accuracy\")#\n\n    \n    return score, config","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.351745Z","iopub.execute_input":"2023-01-15T02:26:58.352619Z","iopub.status.idle":"2023-01-15T02:26:58.361846Z","shell.execute_reply.started":"2023-01-15T02:26:58.352582Z","shell.execute_reply":"2023-01-15T02:26:58.360617Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#y_true = np.array([0, 2, 1, 3])\n#y_predict = np.array([0, 1, 2, 3])\n#print(\"simple: \", accuracy(y_true, y_predict, {}))\n#y_true = np.array([0, 1, 0, 0, 1, 0])\n#y_predict = np.array([0, 1, 0, 0, 0, 1])\n#print(\"balanced: \", accuracy(y_true, y_predict, {\"type\": \"balanced\"}))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.363380Z","iopub.execute_input":"2023-01-15T02:26:58.364362Z","iopub.status.idle":"2023-01-15T02:26:58.375212Z","shell.execute_reply.started":"2023-01-15T02:26:58.364325Z","shell.execute_reply":"2023-01-15T02:26:58.374107Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## MCC ","metadata":{}},{"cell_type":"code","source":"def mcc(y_true, y_pred, parameters):\n    \"\"\"\n    Calculates mcc\n    \n    Parameters:\n        y_true: numpy array of shape (num_images,)\n        y_pred: numpy array of shape (num_images,)\n        parameters: dictionary with the following keys:\n            \n    Returns:\n        score: float\n        config:\n\n    Additional Notes:\n        Binary:\n        \n            +1 -> prefect, 0-> random, -1 -> inverse \n\n            mcc = (tp*tn) - (fp*fn) / sqrt( (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)  )\n\n        Multiclass:\n            \n            +1 -> perfect, between -1 and 0 -> min\n\n            for more info, see\n                \"https://scikit-learn.org/stable/modules/model_evaluation.html#matthews-corrcoef\"\n    \"\"\"\n\n    config = {}\n\n    score = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n\n    return score, config","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.376785Z","iopub.execute_input":"2023-01-15T02:26:58.377497Z","iopub.status.idle":"2023-01-15T02:26:58.385617Z","shell.execute_reply.started":"2023-01-15T02:26:58.377377Z","shell.execute_reply":"2023-01-15T02:26:58.384695Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#y_true = np.array([+1, +1, +1, -1])\n#y_predict = np.array([+1, -1, +1, +1])\n#print(\"mcc: \", mcc(y_true, y_predict, {}))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.386998Z","iopub.execute_input":"2023-01-15T02:26:58.388093Z","iopub.status.idle":"2023-01-15T02:26:58.397819Z","shell.execute_reply.started":"2023-01-15T02:26:58.388017Z","shell.execute_reply":"2023-01-15T02:26:58.396704Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Sensitivity ","metadata":{}},{"cell_type":"code","source":"def sensitivity(y_true, y_pred, parameters):\n    \"\"\"\n    Calculates sensitivity (recall)\n    \n    Parameters:\n        y_true: numpy array of shape (num_images,)\n        y_pred: numpy array of shape (num_images,)\n        parameters: dictionary with the following keys:\n            class_result: for binary classes, name of class for which metric will be calculated\n            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n    \n    Returns:\n        score: float\n        config:\n\n    Additional Notes:\n        recall = TP/ TP+FN\n\n        average:\n            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n            'macro': Calculate metrics for each label, and find their unweighted mean\n            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n\n    \"\"\"\n\n    config = {}\n\n    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n\n        if \"class_result\" in parameters.keys():\n            pos_label = parameters[\"class_result\"]\n        else:\n           ytl = np.unique(y_true)\n           ypl = np.unique(y_pred)\n           labels = np.unique(np.concatenate((ytl, ypl))) \n           pos_label = labels[0]\n        \n        config[\"class_result\"] = pos_label\n\n        score = recall_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n    \n    else:\n        \n        if \"average\" in parameters.keys():\n            average = parameters[\"average\"]\n        else:\n            average = \"weighted\"\n\n        config[\"average\"] = average\n\n        score = recall_score(y_true=y_true, y_pred=y_pred, average=average)\n\n    return score, config","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.399223Z","iopub.execute_input":"2023-01-15T02:26:58.400912Z","iopub.status.idle":"2023-01-15T02:26:58.410542Z","shell.execute_reply.started":"2023-01-15T02:26:58.400870Z","shell.execute_reply":"2023-01-15T02:26:58.409683Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Precision ","metadata":{}},{"cell_type":"code","source":"def precision(y_true, y_pred, parameters):\n    \"\"\"\n    Calculates precision\n    \n    Parameters:\n        y_true: numpy array of shape (num_images,)\n        y_pred: numpy array of shape (num_images,)\n        parameters: dictionary with the following keys:\n            class_result: for binary classes, name of class for which metric will be calculated\n            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n    \n    Returns:\n        score: float\n        config:\n\n    Additional Notes:\n        precision = TP/ TP+FP\n\n        average:\n            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n            'macro': Calculate metrics for each label, and find their unweighted mean\n            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n\n    \"\"\"\n    config = {}\n\n    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n\n        if \"class_result\" in parameters.keys():\n            pos_label = parameters[\"class_result\"]\n        else:\n           ytl = np.unique(y_true)\n           ypl = np.unique(y_pred)\n           labels = np.unique(np.concatenate((ytl, ypl))) \n           pos_label = labels[0]\n        \n        config[\"class_result\"] = pos_label\n\n        score = precision_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n    \n    else:\n        \n        if \"average\" in parameters.keys():\n            average = parameters[\"average\"]\n        else:\n            average = \"weighted\"\n\n        config[\"average\"] = average\n\n        score = precision_score(y_true=y_true, y_pred=y_pred, average=average)\n\n    return score, config","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.412346Z","iopub.execute_input":"2023-01-15T02:26:58.412719Z","iopub.status.idle":"2023-01-15T02:26:58.424371Z","shell.execute_reply.started":"2023-01-15T02:26:58.412684Z","shell.execute_reply":"2023-01-15T02:26:58.423441Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## F1 Score","metadata":{}},{"cell_type":"code","source":"def F1_score(y_true, y_pred, parameters):\n    \"\"\"\n    Calculates f1 score\n    \n    Parameters:\n        y_true: numpy array of shape (num_images,)\n        y_pred: numpy array of shape (num_images,)\n        parameters: dictionary with the following keys:\n            class_result: for binary classes, name of class for which metric will be calculated\n            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n    \n    Returns:\n        score: float\n        config:\n\n    Additional Notes:\n        f1_score = 2 * (Precision * Recall)/ (Precision + Recall)\n\n        average:\n            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n            'macro': Calculate metrics for each label, and find their unweighted mean\n            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n\n    \"\"\"\n\n    config = {}\n\n    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n\n        if \"class_result\" in parameters.keys():\n            pos_label = parameters[\"class_result\"]\n        else:\n           ytl = np.unique(y_true)\n           ypl = np.unique(y_pred)\n           labels = np.unique(np.concatenate((ytl, ypl))) \n           pos_label = labels[0]\n        \n        config[\"class_result\"] = pos_label\n\n        score = f1_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n    \n    else:\n        \n        if \"average\" in parameters.keys():\n            average = parameters[\"average\"]\n        else:\n            average = \"weighted\"\n\n        config[\"average\"] = average\n\n        score = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n\n    return score, config\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.425819Z","iopub.execute_input":"2023-01-15T02:26:58.426441Z","iopub.status.idle":"2023-01-15T02:26:58.438678Z","shell.execute_reply.started":"2023-01-15T02:26:58.426405Z","shell.execute_reply":"2023-01-15T02:26:58.438027Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Metrics ","metadata":{}},{"cell_type":"code","source":"def evaluate_metrics(y_true, y_pred, metrics, y_pred_probs=None):\n    \"\"\"\n    Applies each metric and generates evaluation score\n\n    Parameters:\n        y_true: numpy array of shape (folds, num_images, 2)\n        y_pred: numpy array of shape (folds, num_images, 2)\n        metrics: dictionary with following structure:\n            metrics[\"metrics_1\"][\"name\"] = name of metric\n            metrics[\"metrics_1\"][\"parameter_1\"] = value\n            metrics[\"metrics_1\"][\"parameter_2\"] = value\n\n            metrics[\"metrics_2\"][\"name\"] = name of metric\n            metrics[\"metrics_2\"][\"parameter_1\"] = value\n            metrics[\"metrics_2\"][\"parameter_2\"] = value\n            \n    \n    currently, supports \"accuracy\", \"mcc\", \"precision\", \"sensitivity\", \"F1_score\"\n  \n\n    Returns:\n        scores:numpy array of shape (folds, metrics)\n        output_config:\n       \n    Additional Notes:\n\n    \"\"\"\n    # check whether correct shapes of y_* are provided or not\n\n    if len(y_true.shape) !=3:\n        raise ValueError(\"Shape of y_true is not correct.\")\n\n    if len(y_pred.shape) == 3:\n        num_folds = y_pred.shape[0]\n        met_keys = list(metrics.keys())\n        num_metrics = len(met_keys)\n    else:\n        raise ValueError(\"Shape of y_pred is not correct.\")\n\n    config={}\n\n    list_of_metrics = []\n\n    scores = np.full((num_folds, num_metrics), 1000, dtype=np.float32)\n    \n    flag = True\n\n\n    for fold_no in range(num_folds):\n\n        for metric_no in range(num_metrics):\n\n            print(f\"Processing: Fold No: {fold_no} Metric: {met_keys[metric_no]}\")\n\n            metric_name = metrics[met_keys[metric_no]][\"name\"]\n            \n            if metric_name == \"accuracy\":\n                fnt_pointer = accuracy\n            elif metric_name == \"mcc\":\n                fnt_pointer = mcc\n            elif metric_name == \"precision\":\n                fnt_pointer = precision\n            elif metric_name ==\"sensitivity\":\n                fnt_pointer = sensitivity\n            elif metric_name ==\"F1_score\":\n                fnt_pointer = F1_score\n            else:\n                raise ValueError(\"Unknown metric found\")\n\n            \n            metric_score, fnt_config = fnt_pointer(y_true=y_true[fold_no, :, 1], \n                                                    y_pred=y_pred[fold_no, :, 1], \n                                                    parameters=metrics[met_keys[metric_no]])\n\n\n            scores[fold_no, metric_no] = metric_score\n\n            # setup output config\n            if flag:\n                fnt_config[\"name\"] = metric_name\n                config[met_keys[metric_no]] = {} \n                config[met_keys[metric_no]] = fnt_config\n\n                list_of_metrics.append(met_keys[metric_no])\n\n        flag=False\n    \n    return scores, config, list_of_metrics\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.440177Z","iopub.execute_input":"2023-01-15T02:26:58.440952Z","iopub.status.idle":"2023-01-15T02:26:58.454549Z","shell.execute_reply.started":"2023-01-15T02:26:58.440911Z","shell.execute_reply":"2023-01-15T02:26:58.453594Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# multi\n#y_true = np.array([\"aa\", \"a\", \"ab\", \"b\", \"ac\", \"c\",\n#                    \"ad\", \"a\", \"ae\", \"c\", \"af\", \"a\",\n#                    \"ag\", \"c\", \"ah\", \"b\", \"ai\", \"a\"]).reshape(3,3, 2)\n#y_pred = np.array([\"aa\", \"b\", \"ab\", \"b\", \"ac\", \"b\",\n#                    \"ad\", \"a\", \"ae\", \"c\", \"af\", \"a\",\n#                    \"ag\", \"a\", \"ah\", \"b\", \"ai\", \"c\",]).reshape(3,3,2)\n\n\n\n\n#metrics = {}\n\n#metrics[\"simple_accuracy\"] = {}\n#metrics[\"simple_accuracy\"][\"name\"] = \"accuracy\"\n#metrics[\"simple_accuracy\"][\"type\"] = \"simple\"  \n\n#metrics[\"balanced_accuracy\"] = {}\n#metrics[\"balanced_accuracy\"][\"name\"] = \"accuracy\"\n#metrics[\"balanced_accuracy\"][\"type\"] = \"balanced\"\n\n\n# precision\n#metrics[\"precision\"] = {}\n#metrics[\"precision\"][\"name\"] = \"precision\" \n#metrics[\"precision\"][\"class_result\"] = \"a\"\n#metrics[\"precision\"][\"average\"] = \"weighted\"\n\n\n# recall\n#metrics[\"sensitivity\"] = {}\n#metrics[\"sensitivity\"][\"name\"] = \"sensitivity\"\n#metrics[\"sensitivity\"][\"class_result\"]  = \"a\"\n#metrics[\"sensitivity\"][\"average\"]  = \"weighted\"\n\n# f1_score\n#metrics[\"f1_score\"] = {}\n#metrics[\"f1_score\"][\"name\"] = \"F1_score\" \n#metrics[\"f1_score\"][\"class_result\"] = \"a\"\n#metrics[\"f1_score\"][\"average\"] = \"weighted\"\n\n# mcc\n#metrics[\"mcc\"] = {}\n#metrics[\"mcc\"][\"name\"] = \"mcc\" \n\n\n#print(\"true labels\")\n#print(y_true)\n#print(y_true.shape)\n\n#print(\"pred labels\")\n#print(y_pred)\n#print(y_pred.shape)\n\n#scores, config, list_of_metrics =evaluate_metrics(y_true=y_true, y_pred=y_pred, metrics =metrics)\n\n#print(\"scores \")\n#print(scores)\n\n#print(\"config \")\n#print(config)\n\n#print(\"metrics list \")\n#print(list_of_metrics)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.456066Z","iopub.execute_input":"2023-01-15T02:26:58.456462Z","iopub.status.idle":"2023-01-15T02:26:58.468052Z","shell.execute_reply.started":"2023-01-15T02:26:58.456428Z","shell.execute_reply":"2023-01-15T02:26:58.466958Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Plots","metadata":{}},{"cell_type":"markdown","source":"## Learning Curves ","metadata":{}},{"cell_type":"code","source":"def plot_LC(metric_score, path_to_results, path_to_images):\n\n    \"\"\"\n    Plots and saves learning curves\n    \n    metric_score: numpy array of shape (metrics, 2, epochs)\n    path_to_results: path where plot will be saved\n    \n    \"\"\"\n    num_metrics = metric_score.shape[0]\n    metrics = [\"CELoss\", \"Bal_Accu\", \"MCC\"]\n    \n    fig, axes = plt.subplots(num_metrics, 1)\n    \n    fig.suptitle(\"Learning Curves\")\n\n    for met in range(num_metrics):\n\n        # plot training curve\n        train_line, = axes[met].plot(metric_score[met][0], color='blue', label='Training')\n\n        # plot validation curve\n        valid_line, = axes[met].plot(metric_score[met][1], color= 'orangered', label='Validation')\n\n        # setup x-axis\n        if met != num_metrics -1 :\n            axes[met].set_xticks([])\n        else:\n            axes[met].set_xlabel(\"Epochs\")\n\n        # setup y-axis\n        axes[met].set_ylabel(metrics[met])\n\n    fig.legend(handles= [train_line, valid_line])\n\n    plt.savefig(path_to_results + \"_LC\")\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.469322Z","iopub.execute_input":"2023-01-15T02:26:58.470203Z","iopub.status.idle":"2023-01-15T02:26:58.482763Z","shell.execute_reply.started":"2023-01-15T02:26:58.470166Z","shell.execute_reply":"2023-01-15T02:26:58.482058Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#x= np.random.rand(3, 2, 10)\n#x[0,0] = np.arange(1, 11)\n#x[1, 1] = np.arange(11,21)\n\n#print(x)\n#path_to_results = \"/\"\n\n#plot_LC(\n#    x, path_to_results, x)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.483979Z","iopub.execute_input":"2023-01-15T02:26:58.484599Z","iopub.status.idle":"2023-01-15T02:26:58.496918Z","shell.execute_reply.started":"2023-01-15T02:26:58.484564Z","shell.execute_reply":"2023-01-15T02:26:58.495821Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Misidentified Samples ","metadata":{}},{"cell_type":"code","source":"def plot_MS(y_true, y_pred, path_to_results, path_to_images):\n    \"\"\"\n    Plots and save missclassified samples\n    \n    y_true: numpy array of shape (num_of_images,2)\n    y_pred: numpy array of shape (num_of_images,2)\n    path_to_results: path where plot will be saved\n    path_to_images: folder containing images\n\n\n    Only works with (num_samples)^2 = whole number\n\n    \"\"\"\n    num_samples_to_plot = 4\n\n    classes = np.unique(y_true[:,1])\n\n    if np.sqrt(num_samples_to_plot) %1 !=0:\n        raise ValueError(\"Currently, this function only supports those number of samples whose sqaure is a whole number\")\n\n    \n    \n    cm = create_dict(classes)\n\n    for true_label in classes:\n        \n        # get all images for a class in y_true\n        pos = y_true[np.where(y_true[:,1] == true_label)]\n        \n        pred_classes = classes.tolist()\n      \n        for sample in pos:\n            \n            # find given image in y_pred\n            img_id = y_pred[np.where(y_pred[:,0] == sample[0])]\n            \n            # store img_ids in their respective col\n            for pred_label in pred_classes:\n                if img_id[0,1] == pred_label:\n                    cm[true_label][pred_label].append(img_id[0,0])\n\n            # check whether there are requried number of samples in each col\n            for l in cm[true_label].keys():\n                \n                if l in pred_classes and len(cm[true_label][l]) == num_samples_to_plot:\n                    pred_classes.remove(l)\n                \n            if not len(pred_classes):\n                break\n    \n    plot_CM_images(cm, num_samples_to_plot, path_to_images, path_to_results)\n\n\n\ndef plot_CM_images(cm, num_samples, path_to_images, path_to_results):\n    \"\"\"\n    Plots and saves images\n    \n    \"\"\"\n    num_classes = len(cm.keys())\n    \n    num_imgs_axis = int(np.sqrt(num_samples)) \n    \n    num_rows= num_imgs_axis * num_classes\n    num_cols = num_imgs_axis * num_classes\n\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10,10))\n    \n    fig.suptitle(\"Confusion Matrix of misclassified images\")\n    plt.subplots_adjust(wspace=0, hspace=0)\n\n    fig.text(0.5, 0.04, 'Predicted Labels', ha='center', va='center')\n    fig.text(0.06, 0.5, 'True Labels', ha='center', va='center', rotation='vertical')\n\n    for i, true_label in enumerate(cm.keys()):\n        \n        pred_labels = cm[true_label]\n        \n        if i==0:\n            row_i = i\n        \n\n        for j, pred_label in enumerate(pred_labels.keys()):\n\n            img_ids = pred_labels[pred_label]\n\n            empty_img_ids = num_samples - len(img_ids)\n\n            if j==0:\n                col_j = j\n            \n            row = 0\n            col = 0\n\n            for id in img_ids:\n\n                img = mpimg.imread(os.path.join(path_to_images, id))\n                img_shape = img.shape\n                \n                axes[row_i+row, col_j+col].imshow(img, cmap='gray', vmin=0, vmax=255, aspect='auto')\n                axes[row_i+row, col_j+col].set_xticks([])\n                axes[row_i+row, col_j+col].set_yticks([])\n\n                if row_i + row == num_rows-1:\n                    axes[row_i+row, col_j+col].set_xlabel(pred_label)\n\n            \n                if col_j + col == 0:\n                    axes[row_i+row, col_j+col].set_ylabel(true_label)\n\n\n\n\n                if col ==num_imgs_axis-1:\n                    col =0\n                    row +=1\n                else:\n                    col +=1\n\n            if len(img_ids) ==0:\n                img_shape = (299,299)        \n            \n            if empty_img_ids > 0:\n                temp = np.full(img_shape, 255)\n\n                for _ in range(empty_img_ids):\n                    \n                    axes[row_i+row, col_j+col].imshow(temp, cmap='gray', vmin=0, vmax=255, aspect='auto')\n                    axes[row_i+row, col_j+col].set_xticks([])\n                    axes[row_i+row, col_j+col].set_yticks([])\n\n                    if row_i + row == num_rows-1:\n                        axes[row_i+row, col_j+col].set_xlabel(pred_label)\n\n                \n                    if col_j + col == 0:\n                        axes[row_i+row, col_j+col].set_ylabel(true_label)\n                        \n                    \n                    if col ==num_imgs_axis-1:\n                        col =0\n                        row+=1\n                    else:\n                        col +=1\n                   \n            if empty_img_ids<0:\n                raise ValueError(\"There are more image ids in the dict than number of samples to be plotted\")\n            \n            col_j = col_j + num_imgs_axis\n        \n        row_i += num_imgs_axis\n    \n    plt.savefig(path_to_results + \"_MS\")\n    plt.close()\n\n    \ndef create_dict(classes):\n    \"\"\"\n    Setups a dictionary for storing image ids in confusion matrix\n    \n    \"\"\"\n\n    output_dict = dict()\n    for i in classes:\n        output_dict[i] = {}\n        for j in classes:\n            output_dict[i][j]= []\n\n    return output_dict      ","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.499138Z","iopub.execute_input":"2023-01-15T02:26:58.499932Z","iopub.status.idle":"2023-01-15T02:26:58.524189Z","shell.execute_reply.started":"2023-01-15T02:26:58.499891Z","shell.execute_reply":"2023-01-15T02:26:58.523118Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"def plot_CM(y_true, y_pred, path_to_results, path_to_images):\n    \"\"\"\n    Plots and save Confusion Matrix\n    \n    y_true: numpy array of shape (num_of_images,2)\n    y_pred: numpy array of shape (num_of_images,2)\n    path_to_results: path where plot will be saved\n\n    \"\"\"\n\n    ConfusionMatrixDisplay.from_predictions(y_pred=y_pred[:,1], y_true =y_true[:,1])\n\n    plt.savefig(path_to_results + \"_CM\")\n    plt.close()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.527267Z","iopub.execute_input":"2023-01-15T02:26:58.527600Z","iopub.status.idle":"2023-01-15T02:26:58.538441Z","shell.execute_reply.started":"2023-01-15T02:26:58.527573Z","shell.execute_reply":"2023-01-15T02:26:58.537437Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Create Plots ","metadata":{}},{"cell_type":"code","source":"def create_plots(y_true, y_pred, path_to_results, path_to_images, plots, name_of_file, training_metric_scores=None, y_pred_probs = None):\n    \"\"\"\n    Generates differenet plots\n    Parameters:\n        y_true: numpy array of shape (folds, num_images, 2)\n        y_pred: numoy array of shape (folds, num_images, 2)\n        path_to_results: path to the folder where the results will be stored\n        plots: dictionary with following structure:\n                plots[\"plots_1\"][\"name\"] = name of plot\n                plots[\"plots_1\"][\"parameter_1\"] = value\n                plots[\"plots_1\"][\"parameter_2\"] = value\n\n                plots[\"plots_2\"][\"name\"] = name of plot\n                plots[\"plots_2\"][\"parameter_1\"] = value\n                plots[\"plots_2\"][\"parameter_2\"] = value\n        \n        name_of_file:\n        training_metric_scores: (default=None) list of numpy array with each having shape of (folds, metrics, 2, epochs).Each item in list should represent results of a network.\n\n    Returns:\n        output_config:\n\n    Additional Notes:\n    currently supports CM, LC and MS\n\n\n    \"\"\"\n\n    # check whether correct shapes of y_* are provided or not\n\n    if len(y_true.shape) !=3:\n        raise ValueError(\"Shape of y_true is not correct.\")\n\n    if len(y_pred.shape) == 3:\n        num_folds = y_pred.shape[0]\n    else:\n        raise ValueError(\"Shape of y_pred is not correct.\")\n\n    # determine whether to plot learning curves or not\n    if training_metric_scores is not None:\n        lc = True\n    else:\n        lc = False\n   \n\n\n    for fold_no in range(num_folds):\n\n        # create directory for fold\n        path_to_fold = os.path.join(path_to_results, str(fold_no))\n        if not os.path.exists(path_to_fold):\n            os.mkdir(path_to_fold)\n\n        # create directory for plots\n        path_to_plots = os.path.join(path_to_fold, \"plots\")\n        if not os.path.exists(path_to_plots):\n            os.mkdir(path_to_plots)\n\n        for pl in plots:\n\n            # if dict has key \"learning_curves\" but no metric score is provided,\n            if pl == \"LC\" and not lc:\n                print(\"Warning: key'learning_curves' provided in dict 'plots' but metric score not found. Skipping ploting learning curves\" )\n                continue \n\n\n            print(f\"Creating Plot: {pl} Fold No: {fold_no}\")\n            \n            plot_name = pl\n            if plot_name == \"CM\":\n                fnt_pointer = plot_CM\n            elif plot_name == \"MS\":\n                fnt_pointer = plot_MS\n            elif plot_name == \"LC\":\n                fnt_pointer = plot_LC\n            else:\n                raise ValueError(\"Unknown plot found\")\n                \n            path_to_figs = path_to_plots+f\"/{name_of_file}\"\n\n            if plot_name == \"LC\":\n                fnt_pointer(metric_score= training_metric_scores[fold_no], path_to_results=path_to_figs, path_to_images=path_to_images)\n            else:\n                fnt_pointer(y_true=y_true[fold_no], y_pred=y_pred[fold_no], path_to_results=path_to_figs, path_to_images=path_to_images)\n\n\n    return plots","metadata":{"execution":{"iopub.status.busy":"2023-01-15T03:52:08.529355Z","iopub.execute_input":"2023-01-15T03:52:08.529769Z","iopub.status.idle":"2023-01-15T03:52:08.541391Z","shell.execute_reply.started":"2023-01-15T03:52:08.529732Z","shell.execute_reply":"2023-01-15T03:52:08.540260Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# Misc","metadata":{}},{"cell_type":"markdown","source":"## Load from json ","metadata":{}},{"cell_type":"code","source":"def load_from_json(path_to_json):\n    \"\"\"\n    Load a json file\n\n    Parameters:\n        path_to_json: path to json file\n    \n    Returns:\n        dictionary with contents of the json\n    \"\"\"\n    with open(path_to_json, 'r') as f:\n        dic = json.load(f)\n    \n    return dic","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:47:49.600187Z","iopub.execute_input":"2023-01-15T04:47:49.600627Z","iopub.status.idle":"2023-01-15T04:47:49.607299Z","shell.execute_reply.started":"2023-01-15T04:47:49.600590Z","shell.execute_reply":"2023-01-15T04:47:49.605961Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":"## Save to json ","metadata":{}},{"cell_type":"code","source":"def save_to_json(dic, path_to_results):\n    \"\"\"\n    Save a dicitonary to a location\n\n    Parameters:\n        dic: dictionary to be saved\n        path_to_results: path where to save the dictionary\n\n    \"\"\"\n    with open(path_to_results+\".json\", \"w\") as fp:\n        json.dump(dic, fp, indent=4)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.561947Z","iopub.execute_input":"2023-01-15T02:26:58.562542Z","iopub.status.idle":"2023-01-15T02:26:58.574253Z","shell.execute_reply.started":"2023-01-15T02:26:58.562502Z","shell.execute_reply":"2023-01-15T02:26:58.573408Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Generate txt file ","metadata":{}},{"cell_type":"code","source":"def generate_txt_file(y, path_to_results, name_of_file, y_probs=None):\n    \"\"\"\n    Generates a text file with structure as follows:\n    file_name_1 label\n    file_name_2 label\n\n\n    Parameters:\n        y: numpy array of shape(folds, num_images, 2)\n        path_to_results: path to the folder where to store results\n        name_of_file (without .txt)\n        y_probs: numpy array of shape (folds, num_images, 1)\n\n    \"\"\"\n    \n\n    num_folds = y.shape[0]\n    num_images = y.shape[1]\n\n\n    for fold_no in range(num_folds):\n\n        print(f\"Processing Fold No: {fold_no}\")\n\n        path_to_fold = os.path.join(path_to_results, str(fold_no))\n        if not os.path.exists(path_to_fold):\n                os.mkdir(path_to_fold)\n        \n        # generate file\n        path_to_file = path_to_fold + \"/\" + name_of_file + \".txt\"\n        open(path_to_file, \"w\").close()\n        with open(path_to_file, \"a\") as file:\n            for img_no in range(num_images):\n                file.write(f\"{y[fold_no, img_no, 0]} {y[fold_no, img_no, 1]}\\n\")\n        \n        # generate files with prob\n        if y_probs is not None:\n            path_to_prob_file = path_to_fold + \"/\" + name_of_file + \"_with_probs.txt\"\n            open(path_to_prob_file, \"w\").close()\n            with open(path_to_prob_file, \"a\") as file:\n                for img_no in range(num_images):\n                    file.write(f\"{y[fold_no, img_no, 0]} {y[fold_no, img_no, 1]} {y_probs[fold_no, img_no]}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:24:18.410691Z","iopub.execute_input":"2023-01-15T04:24:18.411185Z","iopub.status.idle":"2023-01-15T04:24:18.426900Z","shell.execute_reply.started":"2023-01-15T04:24:18.411145Z","shell.execute_reply":"2023-01-15T04:24:18.425695Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"## Save results ","metadata":{}},{"cell_type":"code","source":"def save_results(results, metrics, path_to_results, name_of_file):\n    \"\"\"\n    Save results to csv file\n\n    Parameters:\n        results: numpy array of shape (num_folds, metrics)\n        metrics: numpy array of name of the metrics\n        path_to_results: path to the folder where the results will be stored\n        name_of_file: file name\n       \n    \"\"\"\n    df = pd.DataFrame([], columns=[\"Fold No\", \"Metric\", \"Score\"])\n    num_folds = results.shape[0]\n    num_metrics = results.shape[1]\n\n    for fold_no in range(num_folds):\n        for metric_no in range(num_metrics):\n            temp = pd.DataFrame([[fold_no, metrics[metric_no], results[fold_no, metric_no]]], columns=[\"Fold No\", \"Metric\", \"Score\"])\n            df = pd.concat([df, temp])\n\n    df.reset_index(inplace=True, drop=True ) \n       \n    df.to_csv(path_to_results + \"/\" + name_of_file +\".csv\")","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.589659Z","iopub.execute_input":"2023-01-15T02:26:58.590130Z","iopub.status.idle":"2023-01-15T02:26:58.602653Z","shell.execute_reply.started":"2023-01-15T02:26:58.590093Z","shell.execute_reply":"2023-01-15T02:26:58.601482Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"def get_predictions(path_to_results, path_to_images, y, data_transforms, batch_size, device, fold=-2):\n    \"\"\"\n    generates predictions\n    \n    path_to_results: where models are saved\n    path_to_images: images dir\n    y: (num_images, 1)\n    data_transforms: transformation to apply\n    fold: prediction for specific fold\n    \n    \n    Returns:\n        y_preds_folds: (num_folds, num_images)\n        y_preds_probs_folds: (num_folds, num_images, num_classes) \n        y_preds_en: (num_images,1)\n        y_preds_probs_ensemble: (num_images, num_classes)\n        \n    thresholding could be added for binary (>th)/multi(>th for each class) classsifcation\n    \"\"\"\n    y_preds_probs_folds=[]\n    y_preds_folds = []\n    \n    sigmoid = torch.nn.Sigmoid()\n    softmax = torch.nn.Softmax(dim=1)       \n\n    flag = False\n    single_neuron = False\n    \n    for fold_no in sorted(os.listdir(path_to_results)):\n        \n        if fold_no == str(fold_no):\n            flag = True\n        \n        path_to_model = os.path.join(path_to_results, fold_no)\n        \n        if os.path.isdir(path_to_model):\n            \n            print(f\"Generating predicitons for fold no: {fold_no}\")\n            \n            # get data\n            data = ImageDataset(y, path_to_images, transform=data_transforms)\n            dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n            \n            # load model\n            model_path = os.path.join(path_to_model, \"model.pt\")\n            print (f\"Loading model from {model_path}\")\n            model = torch.load(model_path)\n            model.to(device)\n            model.eval()\n            \n            with torch.no_grad():\n                \n                y_pred_prob=[]\n                y_pred_labels =[]\n                \n                for images, _ in dataloader:\n                    images = images.to(device)\n                    \n                    y_pred = model(images)\n                \n                    if y_pred.shape[-1] == 1:\n                        # get probs\n                        prob = sigmoid(y_pred)\n                        \n                        # get hard labels\n                        labels = np.round(prob.detach().cpu().clone().numpy())\n                        \n                        single_neuron = True\n                    else:\n                        #get probs\n                        prob = softmax(y_pred)\n                        \n                        # get hard labels\n                        labels = np.argmax(prob.detach().cpu().clone().numpy(), axis=1) \n                    \n                    #combine iter results\n                    y_pred_prob.extend(prob.detach().cpu().clone().numpy())\n                    y_pred_labels.extend(labels)\n            \n            \n            # combine fold results\n            y_preds_folds.append(y_pred_labels)\n            y_preds_probs_folds.append(y_pred_prob)\n            \n            if flag:\n                break\n        \n    # get ensemble results\n    y_preds_probs_ensemble = np.mean(y_preds_probs_folds, axis=0)\n    \n\n    if single_neuron:\n        y_preds_en = np.round(y_preds_probs_ensemble).reshape(-1,1)\n    else:\n        y_preds_en = np.argmax(y_preds_probs_ensemble, axis=1).reshape(-1,1)\n        \n    return np.array(y_preds_folds), np.array(y_preds_probs_folds), np.array(y_preds_en), np.array(y_preds_probs_ensemble)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:42:18.379990Z","iopub.execute_input":"2023-01-15T02:42:18.380467Z","iopub.status.idle":"2023-01-15T02:42:18.395711Z","shell.execute_reply.started":"2023-01-15T02:42:18.380424Z","shell.execute_reply":"2023-01-15T02:42:18.394610Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def CNN_prediction(path_to_images, path_to_json, save_path):\n    \"\"\"\n    Generates prediction for the given data set\n\n    Parameters:\n        path_to_images: path to the folder containing images on which prediction will be generated\n        path_to_results: path to the folder where models are saved\n        save_path: path to the folder where the results will be stored\n        data_transform: transformation to apply\n        batch_size: batch size\n\n    \"\"\"\n\n    if not os.path.isdir(path_to_images):\n        raise ValueError(\"'path_to_images' must be a directory\")\n\n    if not os.path.exists(save_path):\n        os.mkdir(save_path)\n        print(f\"Created directory {save_path}\")\n    else:\n        print(f\"Warning: {save_path} already exists. Content may get overwritten\")\n    \n    # loading training pipeline\n    pipeline = load_from_json(path_to_json)\n\n    pipeline[\"path_to_images\"] = path_to_images\n    path_to_results = pipeline[\"path_to_results\"]\n\n    del pipeline['path_to_labels']\n\n    del pipeline[\"split_type\"]\n    \n    device = pipeline[\"device\"]\n    \n    data_transform = pipeline[\"data_preprocessing\"][\"valid\"]\n    data_transforms = data_preprocessing(data_transform)\n    \n    y=np.array(sorted(os.listdir(path_to_images))).reshape(-1,1)\n    \n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using Device: {device}\")\n    print(y.shape)\n  \n    print(\"\\nGenerating labels for the data . . . \")\n    y_pred, y_pred_probs, y_pred_en, y_pred_probs_en = get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y, data_transforms=data_transforms, batch_size=batch_size, device=device)\n    \n    print(f\"Generated labels for the data successfully. Shape: y_pred: {y_pred.shape} y_pred_probs: {y_pred_probs.shape} y_pred_en: {y_pred_en.shape} y_pred_probs_en: {y_pred_probs_en.shape}\")\n    \n    y_pred = np.expand_dims(y_pred, axis=0)   \n    y_pred_probs_en = np.expand_dims(y_pred_probs_en, axis=0)\n    y_pred_en = np.expand_dims (np.concatenate((y, y_pred_en), axis=1), axis=0)\n    y_pred_en[0, :, 1] = label_encoder(y=y_pred_en[0, :, 1], classes=classes, to_numbers=False)\n    \n    \n    # save pipeline\n    print(\"\\nsaving pipeline dictionary to json\")\n    save_to_json(\n        pipeline, \n        save_path +\"/pipeline\"\n        )\n    \n    # save labels\n    print(\"\\nGenerating text file for the data\")\n    generate_txt_file(\n        y=y_pred, \n        path_to_results=save_path, \n        name_of_file=\"labels\",\n        y_probs = np.max(y_pred_probs, axis=-1)\n        )\n    \n     # save labels with probs\n    print(\"\\nGenerating text file for the data ensemble\")\n    generate_txt_file(\n        y=y_pred_en, \n        path_to_results=save_path, \n        name_of_file=\"labels_en\",\n        y_probs = np.max(y_pred_probs_en, axis=-1)\n        )\n    \n    print(\"\\nGenerated Predictions Successfully\")","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:55:00.501289Z","iopub.execute_input":"2023-01-15T04:55:00.501940Z","iopub.status.idle":"2023-01-15T04:55:00.524699Z","shell.execute_reply.started":"2023-01-15T04:55:00.501894Z","shell.execute_reply":"2023-01-15T04:55:00.523017Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":"# Training\n\n* for each epoch, train the model and evaluate the model on training and validaiton data using metrics: loss, balanced accuracy, mcc etc\n\n* store evaluation results for each epoch that will be used for learning curves\n* save the best model using val loss or some other metric\n\n* generate prediction and prediction probabilities using best model on training and validation data\n\nsave all the necessary info","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, device, dataloader, loss_fnt, optimizer):\n    \"\"\"\n    trains a model \n    \n    Parameters:\n        model: model to be trained\n        device: device on which model to be trained\n        dataloader: of training dataset\n        lost_fnt: loss function\n        optimizer:\n        \n    Returns:\n        train_loss, train_balanced_accu, train_mcc \n        unnormalized values (No multiplication of 1/num_images)\n    \n    \"\"\"\n    \n    train_loss = 0\n    train_balanced_accu = 0\n    train_mcc = 0\n    \n    sigmoid = torch.nn.Sigmoid()\n    \n    model.train()\n\n    for images, labels in dataloader:\n\n        images,labels = images.to(device),labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        output = model(images)\n        \n        loss = loss_fnt(output,labels)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_loss += loss.item() * images.size(0)\n        \n        if output.shape[-1] == 1:\n            y_pred = torch.round(sigmoid(output.detach().clone())).cpu().numpy()\n        else:\n            y_pred = np.argmax(output.detach().clone().cpu().numpy(), axis=1)\n                    \n        train_balanced_accu += accuracy(y_true=labels.detach().clone().cpu().numpy(), y_pred=y_pred, parameters={\"type\": \"balanced\"})[0] * images.size(0)\n        train_mcc += mcc(y_true=labels.detach().clone().cpu().numpy(), y_pred=y_pred, parameters={})[0] * images.size(0) \n\n        \n    return train_loss, train_balanced_accu, train_mcc","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.636290Z","iopub.execute_input":"2023-01-15T02:26:58.636981Z","iopub.status.idle":"2023-01-15T02:26:58.649676Z","shell.execute_reply.started":"2023-01-15T02:26:58.636929Z","shell.execute_reply":"2023-01-15T02:26:58.648696Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#print(device)\n#model = model.to(device)\n#loss_fnt.weight = loss_fnt.weight.cuda()\n#train_epoch(model, device, train_dataloader, loss_fnt, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.651550Z","iopub.execute_input":"2023-01-15T02:26:58.652304Z","iopub.status.idle":"2023-01-15T02:26:58.663037Z","shell.execute_reply.started":"2023-01-15T02:26:58.652269Z","shell.execute_reply":"2023-01-15T02:26:58.661902Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def valid_epoch(model, device, dataloader, loss_fnt):\n    \"\"\"\n    Generates results on validation data\n    \n    Parameters:\n        model: model to be used for evaluatioon\n        device: device on which model will be evaluated\n        dataloader: of validation dataset\n        lost_fnt: loss function\n        \n    Returns:\n        valid_loss, valid_balanced_accu, valid_mcc \n        unnormalized values (No multiplication of 1/num_images)\n    \n    \"\"\"\n    \n    valid_loss = 0\n    valid_balanced_accu = 0\n    valid_mcc = 0\n    \n    sigmoid = torch.nn.Sigmoid()\n    \n    model.eval()\n    \n    with torch.no_grad():\n        \n        for images, labels in dataloader:\n\n            images,labels = images.to(device),labels.to(device)\n\n            output = model(images)\n\n            loss=loss_fnt(output,labels)\n\n            valid_loss+=loss.item()*images.size(0)\n            \n            if output.shape[-1] == 1:\n                y_pred = torch.round(sigmoid(output.detach().clone())).cpu().numpy()\n            else:\n                y_pred = np.argmax(output.detach().clone().cpu().numpy(), axis=1)\n            \n            valid_balanced_accu += accuracy(y_true=labels.cpu().numpy(), y_pred=y_pred, parameters={\"type\": \"balanced\"})[0] * images.size(0)\n            valid_mcc += mcc(y_true=labels.cpu().numpy(), y_pred=y_pred, parameters={})[0] * images.size(0) \n\n    return valid_loss, valid_balanced_accu, valid_mcc\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T02:26:58.664502Z","iopub.execute_input":"2023-01-15T02:26:58.665042Z","iopub.status.idle":"2023-01-15T02:26:58.676943Z","shell.execute_reply.started":"2023-01-15T02:26:58.665005Z","shell.execute_reply":"2023-01-15T02:26:58.676096Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def CNN_training(pipeline):\n    \n    output_config = {}\n    \n    # set up whether to use cpu or gpu\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using Device: {device}\")\n    output_config[\"device\"] = device\n    \n    #get results folder\n    path_to_results = pipeline[\"path_to_results\"]\n    output_config[\"path_to_results\"] = path_to_results\n    if not os.path.exists(path_to_results):\n            os.mkdir(path_to_results)\n    \n    #get iamge folder\n    path_to_images = pipeline[\"path_to_images\"]\n    output_config[\"path_to_images\"] = path_to_images\n    \n    # get batch size\n    batch_size= pipeline[\"batch_size\"]\n    output_config[\"batch_size\"] =batch_size\n    \n    # get batch size\n    num_epochs= pipeline[\"num_epochs\"]\n    output_config[\"num_epochs\"] =num_epochs\n    \n    \n    # read labels from txt\n    path_to_labels = pipeline[\"path_to_labels\"]\n    output_config[\"path_to_labels\"] = path_to_labels\n\n    y = np.loadtxt(path_to_labels, dtype=str, delimiter=\" \")\n    \n    # get unique labels and their ratios\n    original_labels = {}\n    unique_labels, counts = np.unique(y[:,1], return_counts=True)\n    print(f\"Unique labels found and their frequencies: \")\n    for ul, c in zip(unique_labels, counts):\n        original_labels[ul] = format(c*100/y.shape[0], '.2f')\n        print(f\"Label: {ul}, %age: {format(c*100/y.shape[0], '.2f')}\")\n    output_config[\"original_labels\"] = original_labels\n    \n    # split data\n    split_type = pipeline[\"split_type\"]\n    output_config[\"split_type\"] = split_type\n    \n    if \"simple\" in split_type:\n        test_size = pipeline[\"test_size\"]\n        output_config[\"test_size\"] = test_size\n        num_folds=1\n        y_train, y_valid = split_data(y=y, split_type=split_type, test_size=test_size)\n    \n    elif \"fold\" in split_type:\n        num_folds = pipeline[\"num_folds\"]\n        output_config[\"num_folds\"] = num_folds\n        y_train, y_valid = split_data(y=y, split_type=split_type, n_folds=num_folds)\n    \n    else:\n        raise ValueError(\"Unknown spliting type\")\n        \n    print(f\"Split the data successfully. Shape: y_train: {y_train.shape} y_valid: {y_valid.shape}\")\n        \n        \n    # number of images in train and valid data\n    num_images_train = y_train.shape[1]\n    num_images_valid = y_valid.shape[1]\n    \n    # transform labels\n    classes = pipeline[\"classes\"]\n    for nf in range(num_folds):\n        y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=True)\n        y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=True)\n    \n    output_config[\"classes\"] = classes.tolist()\n    output_config[\"data_preprocessing\"]={}\n    output_config[\"data_preprocessing\"][\"train\"] = OrderedDict()\n    output_config[\"data_preprocessing\"][\"valid\"] = OrderedDict()\n    \n    # get preprocessing transformations for training data\n    train_data_transform = pipeline[\"data_preprocessing\"][\"train\"]\n    train_data_transforms = data_preprocessing(train_data_transform)\n    output_config[\"data_preprocessing\"][\"train\"] = train_data_transform\n        \n    # get preprocessing transformations for validation data\n    valid_data_transform = pipeline[\"data_preprocessing\"][\"valid\"]\n    valid_data_transforms = data_preprocessing(valid_data_transform)\n    output_config[\"data_preprocessing\"][\"valid\"] = valid_data_transform\n    \n     # get input shape for the model\n    input_shape = pipeline[\"input_shape\"]\n    output_config[\"input_shape\"] = input_shape\n    \n    # get layers of the model\n    layers = pipeline[\"model\"]\n    output_config[\"model\"] = layers\n    #print(layers)\n    \n    #get loss settings\n    loss_param = pipeline[\"loss\"]\n    output_config[\"loss\"] = loss_param\n    \n    # get optimizer settings\n    optim_parameters = pipeline[\"optimizer\"]\n    output_config[\"optimizer\"] =optim_parameters \n    \n    #get metrics\n    metrics = pipeline[\"metrics\"]\n    output_config[\"metrics\"] =metrics\n    \n    # get plots\n    plots = pipeline[\"plots\"]\n    output_config[\"plots\"] =plots\n    \n    \n    # for saving scores of each fold\n    train_loss_fold, train_accu_fold,train_mcc_fold = [],[],[]\n    valid_loss_fold, valid_accu_fold,valid_mcc_fold = [],[],[]\n    \n    # for saving scores of best model of each model\n    train_loss_fold_best, train_accu_fold_best,train_mcc_fold_best = [],[],[]\n    valid_loss_fold_best, valid_accu_fold_best,valid_mcc_fold_best = [],[],[]\n    best_model_epoch_no_fold = []\n    \n    train_labels ={}\n    valid_labels={}\n    \n    for fold_no in range(num_folds):\n        \n        path_to_fold = os.path.join(path_to_results, str(fold_no))\n        if not os.path.exists(path_to_fold):\n            os.mkdir(path_to_fold)\n        \n        # get training data\n        train_data = ImageDataset(y_train[fold_no], path_to_images, transform=train_data_transforms)\n        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n        \n        # get validation data\n        valid_data = ImageDataset(y_valid[fold_no], path_to_images, transform=valid_data_transforms)\n        valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n        \n        # load model\n        model = Model(input_shape,layers)\n        model.to(device)\n        print(model)\n        \n        # get ratio of each class in y_train\n        train_labels[str(fold_no)] = {}\n        unique_labels, counts = np.unique(y_train[fold_no,:,1], return_counts=True)\n\n        print(f\"\\nFold No: {fold_no} Training data: Unique labels: \")\n        \n        for ul, c in zip(unique_labels, counts):\n                train_labels[str(fold_no)][ul] = format(c*100/y_train.shape[1], '.2f')\n                print(f\"Label: {ul}, %age: {format(c*100/y_train.shape[1], '.2f')}\")\n\n        # get ratio of each class in y_valid\n        valid_labels[str(fold_no)] = {}\n        unique_labels, counts =np.unique(y_valid[fold_no, :,1], return_counts=True)\n\n        print(f\"\\nFold No: {fold_no} Validation data: Unique labels: \")\n\n        for ul, c in zip(unique_labels, counts):\n            valid_labels[str(fold_no)][ul] = format(c*100/y_valid.shape[1], '.2f')\n            print(f\"Label: {ul}, %age: {format(c*100/y_valid.shape[1], '.2f')}\")\n        \n        # calculate weights\n        if loss_param[\"use_single_neuron\"]:\n            class_weights = [train_labels[str(fold_no)][1] / train_labels[str(fold_no)][0]]\n        else:\n            class_weights = []\n            for cl in range(len(classes)):\n                class_weights.append(1 - float(train_labels[str(fold_no)][str(cl)]))\n        \n        # setup loss\n        loss_fnt = setup_loss({**loss_param, **{\"class_weights\": class_weights}})\n        print(loss_fnt)\n        \n        # setup optimizer\n        optimizer = setup_optimizer(model.parameters(), optim_parameters)\n        print(optimizer)\n        \n        # for saving scores of each epoch\n        train_loss_epoch, train_accu_epoch,train_mcc_epoch = [],[],[]\n        valid_loss_epoch, valid_accu_epoch,valid_mcc_epoch = [],[],[]\n        \n        \n        # for saving scores of each epoch of best model\n        train_loss_epoch, train_accu_epoch,train_mcc_epoch = [],[],[]\n        valid_loss_epoch, valid_accu_epoch,valid_mcc_epoch = [],[],[]\n        \n        for epoch in range(num_epochs):\n            \n            train_loss, train_accu, train_mcc = train_epoch(model, device, train_dataloader, loss_fnt, optimizer)\n            valid_loss, valid_accu, valid_mcc = valid_epoch(model, device, valid_dataloader, loss_fnt)\n            \n            train_loss, train_accu, train_mcc = train_loss/num_images_train, train_accu/num_images_train, train_mcc/num_images_train\n            valid_loss, valid_accu, valid_mcc = valid_loss/num_images_valid, valid_accu/num_images_valid, valid_mcc/num_images_valid\n            \n            print(f'Training:Fold No: {fold_no+1}/{num_folds} Epoch:{epoch+1}/{num_epochs} Training: Loss: {train_loss}, Bal_accu: {train_accu}, mcc: {train_mcc} Validation: Loss: {valid_loss}, Bal_accu: {valid_accu}, mcc: {valid_mcc}')\n             \n            # save best model\n            if epoch == 0:\n                print(f\"Saving Model of first epoch\")\n                \n                torch.save(model, os.path.join(path_to_fold, \"model.pt\"))\n                \n                # save best model scores\n                best_model_epoch_no = epoch\n                train_loss_epoch_best = train_loss\n                train_accu_epoch_best = train_accu\n                train_mcc_epoch_best = train_mcc\n\n                valid_loss_epoch_best = valid_loss\n                valid_accu_epoch_best = valid_accu\n                valid_mcc_epoch_best = valid_mcc   \n\n            elif  valid_loss_epoch_best > valid_loss:\n                \n                print(f\"Validation Loss score improved. Saving Model.\")\n                \n                torch.save(model, os.path.join(path_to_fold, \"model.pt\"))\n                \n                # save best model scores\n                best_model_epoch_no = epoch\n                train_loss_epoch_best = train_loss\n                train_accu_epoch_best = train_accu\n                train_mcc_epoch_best = train_mcc\n\n                valid_loss_epoch_best = valid_loss\n                valid_accu_epoch_best = valid_accu\n                valid_mcc_epoch_best = valid_mcc   \n\n            else:\n                print(\"Validaiton Loss score did not improve.\")\n            \n            # save scores for learning curves\n            train_loss_epoch.append(train_loss)\n            train_accu_epoch.append(train_accu)\n            train_mcc_epoch.append(train_mcc)\n            \n            valid_loss_epoch.append(valid_loss)\n            valid_accu_epoch.append(valid_accu)\n            valid_mcc_epoch.append(valid_mcc)\n            \n        \n        # save best model for each fold\n        best_model_epoch_no_fold.append(best_model_epoch_no)\n        \n        train_loss_fold_best.append(train_loss_epoch_best)\n        train_accu_fold_best.append(train_accu_epoch_best)\n        train_mcc_fold_best.append(train_mcc_epoch_best)\n\n        valid_loss_fold_best.append(valid_loss_epoch_best)\n        valid_accu_fold_best.append(valid_accu_epoch_best)\n        valid_mcc_fold_best.append(valid_mcc_epoch_best)\n        \n        # save scores for each fold\n        train_loss_fold.append(train_loss_epoch)\n        train_accu_fold.append(train_accu_epoch)\n        train_mcc_fold.append(train_mcc_epoch)\n\n        valid_loss_fold.append(valid_loss_epoch)\n        valid_accu_fold.append(valid_accu_epoch)\n        valid_mcc_fold.append(valid_mcc_epoch)\n    \n    \n    #convert to numpy\n    train_loss_fold = np.array(train_loss_fold)\n    train_accu_fold = np.array(train_accu_fold)\n    train_mcc_fold = np.array(train_mcc_fold)\n    \n    valid_loss_fold = np.array(valid_loss_fold)\n    valid_accu_fold = np.array(valid_accu_fold)\n    valid_mcc_fold = np.array(valid_mcc_fold)\n    \n    \n    \n    # generate learning curves array\n    score_for_learning_curves = np.full((num_folds, 3,2, num_epochs), -1000)\n    for nf in range(num_folds):\n        score_for_learning_curves[nf, 0, 0, :] = train_loss_fold\n        score_for_learning_curves[nf, 1, 0, :] = train_accu_fold\n        score_for_learning_curves[nf, 2, 0, :] = train_mcc_fold\n        \n        score_for_learning_curves[nf, 0, 1, :] = valid_loss_fold\n        score_for_learning_curves[nf, 1, 1, :] = valid_accu_fold\n        score_for_learning_curves[nf, 2, 1, :] = valid_mcc_fold\n    \n    print(f\"Trained the model for all folds. Shape: train: loss: {train_loss_fold.shape} accu: {train_accu_fold.shape} mcc: {train_mcc_fold.shape} valid: loss: {valid_loss_fold.shape} accu: {valid_accu_fold.shape} mcc: {valid_mcc_fold.shape} Learning scores: {score_for_learning_curves.shape}\")\n    \n    output_config[\"train_labels\"] = train_labels\n    output_config[\"valid_labels\"] = valid_labels\n    \n    output_config[\"results\"] = {}\n    output_config[\"results\"][\"best_model\"]={}\n    output_config[\"results\"][\"best_model\"][\"epoch_number\"]=best_model_epoch_no_fold\n    output_config[\"results\"][\"best_model\"][\"train\"]={}\n    output_config[\"results\"][\"best_model\"][\"train\"][\"loss\"]=train_loss_fold_best\n    output_config[\"results\"][\"best_model\"][\"train\"][\"balanced_accuracy\"]=train_accu_fold_best\n    output_config[\"results\"][\"best_model\"][\"train\"][\"mcc\"]=train_mcc_fold_best\n    output_config[\"results\"][\"best_model\"][\"valid\"]={}\n    output_config[\"results\"][\"best_model\"][\"valid\"][\"loss\"]=valid_loss_fold_best\n    output_config[\"results\"][\"best_model\"][\"valid\"][\"balanced_accuracy\"]=valid_accu_fold_best\n    output_config[\"results\"][\"best_model\"][\"valid\"][\"mcc\"]=valid_mcc_fold_best\n    \n    # generate predicitons\n    print(\"Generating Predictions\")\n    train_pred = []\n    train_pred_prob = []\n    valid_pred = []\n    valid_pred_prob = []\n    for fn in range(num_folds):\n        train_pred_fn, train_pred_prob_fn, _,_= get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y_train[fn], data_transforms=valid_data_transforms, fold=fn, batch_size=batch_size, device=device)\n        valid_pred_fn, valid_pred_prob_fn, _,_= get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y_valid[fn], data_transforms=valid_data_transforms, fold=fn, batch_size=batch_size, device=device)\n        \n        train_pred_fn = label_encoder(y=train_pred_fn, classes=classes, to_numbers=False)\n        valid_pred_fn = label_encoder(y=valid_pred_fn, classes=classes, to_numbers=False)\n     \n        \n        train_pred.append([y_train[fn, :, 0], train_pred_fn])\n        train_pred_prob.append(train_pred_prob_fn[0])\n        valid_pred.append([y_valid[fn, :, 0],valid_pred_fn])\n        valid_pred_prob.append(valid_pred_prob_fn[0])\n        \n\n    train_pred =np.array(train_pred).swapaxes(-1,-2)\n    train_pred_prob =np.array(train_pred_prob)\n    valid_pred =np.array(valid_pred).swapaxes(-1,-2)\n    valid_pred_prob =np.array(valid_pred_prob)\n    \n    print(f\"generated predictions. Shape: train: labels: {train_pred.shape} prob: {train_pred_prob.shape} valid: labels: {valid_pred.shape} prob: {valid_pred_prob.shape}\")    \n    \n    # transform int labels to name of classes\n    for nf in range(num_folds):\n        y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=False)\n        y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=False)\n    \n    \n    #evaluate metrics on training data\n    print(\"\\nEvaluating Metrics on training data . . . \")\n    metrics_train, metrics_train_config, metrics_train_list = evaluate_metrics(\n        y_true=y_train, \n        y_pred=train_pred, \n        metrics=metrics,\n        y_pred_probs = train_pred_prob\n        )\n    print(\"\\nResults\")\n\n\n    for fold_no in range(num_folds):\n        for met_no, met in enumerate(metrics_train_list):\n            print(f\"Fold No: {fold_no} Metric: {met}  Score: {metrics_train[fold_no, met_no]} \")\n\n    print(f\"Evaluated Metrics on the training data successfully. Shape:{metrics_train.shape}\")\n\n    #evaluate metrics on validataion data\n    print(\"\\nEvaluating Metrics on validation data . . . \")\n    metrics_valid, _, metrics_valid_list = evaluate_metrics(\n        y_true=y_valid, \n        y_pred=valid_pred, \n        metrics=metrics,\n        y_pred_probs = valid_pred_prob\n        )\n    print(\"\\nResults\")\n    \n    for fold_no in range(num_folds):\n        for met_no, met in enumerate(metrics_valid_list):\n            print(f\"Fold No: {fold_no} Metric: {met}  Score: {metrics_valid[fold_no, met_no]} \")\n\n    print(f\"Evaluated Metrics on the validation data successfully. Shape: {metrics_valid.shape}\")\n    \n    # evaluate ensemble results on complete dataset\n    print(\"\\nEvaluating Metrics on the data using ensmebles. . . \")\n    \n    # transform name of classes to int\n    y[:, 1] = label_encoder(y=y[:,1], classes=classes, to_numbers=True)\n    \n    _, _, y_pred_en, y_pred_prob_en = get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y, data_transforms=valid_data_transforms, device=device, batch_size=batch_size)\n    \n    y = np.expand_dims(y, axis=0)\n    y_pred_prob_en = np.expand_dims(y_pred_prob_en, axis=0)\n          \n    y_pred_en = np.expand_dims (np.concatenate((y[0,:,0].reshape(-1,1), y_pred_en), axis=1), axis=0)\n    \n    print(f\"Evaluated Metrics on the data using ensembles. Shape: labels: {y_pred_en.shape} probs: {y_pred_prob_en.shape}\")\n    # transform int labels to name of classes\n    y_pred_en[0, :, 1] = label_encoder(y=y_pred_en[0, :, 1], classes=classes, to_numbers=False)\n    y[0,:, 1] = label_encoder(y=y[0,:,1], classes=classes, to_numbers=False)\n    \n    metrics_en, metrics_en_config, metrics_en_list = evaluate_metrics(\n        y_true=y, \n        y_pred=y_pred_en, \n        metrics=metrics,\n        y_pred_probs = y_pred_prob_en\n        )\n    print(\"\\nResults\")\n    \n    for met_no, met in enumerate(metrics_en_list):\n            print(f\"Fold No: {0} Metric: {met}  Score: {metrics_valid[0, met_no]} \")\n            \n    # create plots\n    print(\"\\nCreating Plots for training data . . .\")\n    plots_train_config = create_plots(\n        y_true=y_train, \n        y_pred=train_pred, \n        plots= plots, \n        path_to_results=path_to_results,\n        path_to_images=path_to_images,\n        name_of_file = \"train\",\n        training_metric_scores=score_for_learning_curves,\n        y_pred_probs = train_pred_prob\n        )\n    print(\"Created Plots for training data\")\n\n    print(\"\\nCreating Plots for validation data\")\n    _ = create_plots(\n        y_true=y_valid, \n        y_pred=valid_pred, \n        plots= plots, \n        path_to_results=path_to_results,\n        path_to_images=path_to_images, \n        name_of_file = \"valid\",\n        y_pred_probs = valid_pred_prob\n        )\n    print(\"Created Plots for validation data\")\n    \n    print(\"\\nCreating Plots for ensemble data\")\n    _ = create_plots(\n        y_true=y, \n        y_pred=y_pred_en, \n        plots= plots, \n        path_to_results=path_to_results,\n        path_to_images=path_to_images, \n        name_of_file = \"ensemble\",\n        y_pred_probs = y_pred_prob_en\n        )\n    print(\"Created Plots for ensemble data\")\n\n    # save pipeline\n    print(\"\\nsaving pipeline dictionary to json\")\n    save_to_json(\n        output_config, \n        os.path.join(path_to_results, \"training_pipeline\")\n        )\n        # save labels\n    print(\"\\nGenerating text file for training data\")\n    generate_txt_file(\n        y=train_pred, \n        path_to_results=path_to_results, \n        name_of_file=\"train\",\n        y_probs = np.max(train_pred_prob, axis=-1)\n        )\n\n    print(\"\\nGenerating text file for validation data\")\n    generate_txt_file(\n        y=valid_pred, \n        path_to_results=path_to_results,  \n        name_of_file=\"valid\",\n        y_probs = np.max(valid_pred_prob, axis=-1)\n        )\n    \n    print(\"\\nGenerating text file for ensemble data\")\n    generate_txt_file(\n        y=y_pred_en, \n        path_to_results=path_to_results,  \n        name_of_file=\"ensemble\",\n        y_probs = np.max(y_pred_prob_en, axis=-1)\n        )\n    \n    # save metrics train and metrics_valid\n    print(\"\\nSaving training results \")\n    save_results(\n        results=metrics_train,\n        metrics=metrics_train_list,\n        path_to_results=path_to_results,\n        name_of_file=\"train\"\n    )\n\n    print(\"\\nSaving validation results \")\n    save_results(\n        results=metrics_valid,\n        metrics=metrics_valid_list,\n        path_to_results=path_to_results,\n        name_of_file=\"valid\"\n    )\n    \n    print(\"\\nSaving ensemble results \")\n    save_results(\n        results=metrics_en,\n        metrics=metrics_en_list,\n        path_to_results=path_to_results,\n        name_of_file=\"ensemble\"\n    )\n\n    print(\"\\nTraining Completed\\n\")\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T05:04:39.395490Z","iopub.execute_input":"2023-01-15T05:04:39.395898Z","iopub.status.idle":"2023-01-15T05:04:39.466389Z","shell.execute_reply.started":"2023-01-15T05:04:39.395863Z","shell.execute_reply":"2023-01-15T05:04:39.465294Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":"# Save\n* the model and all the info (model, parameters, results etc)","metadata":{}},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Metrics\nUsing the best model, evaluate the metircs and save the find results in csv file","metadata":{}},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plots:\n* learning curve\n* metrics\n* confusion matrix\n* misidentified samples\n* ROC\n* maybe weights\n\nsave them","metadata":{}},{"cell_type":"markdown","source":"# Prediction\nload the best model, generate prediction on train, test and noisy test dataset and create two txt files:\n- one with file name and label (like the one provided)\n- one with file name, label and probability","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional notes:\n* set up excel sheet for finding optimal hyperparameers in organized manner\n* set up excel for tracking results of different models in organized manner\n* or just find some function that finds optimal hyperparameters\n\n* Results may not stay saved if kaggle session is closed. Either download them in timely manner or find a way to save them","metadata":{}},{"cell_type":"markdown","source":"# Results Directory","metadata":{}},{"cell_type":"code","source":"run_name = 'test'\n\npath_to_result ='/kaggle/working/results'\nif not os.path.exists(path_to_result):\n    os.mkdir(path_to_result)\n    \npath_to_results = os.path.join(path_to_result, run_name)\nif not os.path.exists(path_to_results):\n    os.mkdir(path_to_results)\n    \npath_to_binary_results = os.path.join(path_to_results, \"binary\")\nif not os.path.exists(path_to_binary_results):\n    os.mkdir(path_to_binary_results)\n\npath_to_multiclass_results = os.path.join(path_to_results, \"multi\")\nif not os.path.exists(path_to_multiclass_results):\n    os.mkdir(path_to_multiclass_results)\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.857177Z","iopub.execute_input":"2023-01-15T02:26:58.858398Z","iopub.status.idle":"2023-01-15T02:26:58.867683Z","shell.execute_reply.started":"2023-01-15T02:26:58.858355Z","shell.execute_reply":"2023-01-15T02:26:58.866693Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Raw Data Directory","metadata":{}},{"cell_type":"code","source":"# path to data folders\npath_to_data = \"/kaggle/input/ismdatasetforclassificationofdieases/code_testing/code_testing\"\n\n# training data\npath_to_train_data = os.path.join(path_to_data, \"train\")\npath_to_binary_labels = os.path.join(path_to_data, \"train_binary.txt\")\npath_to_multi_labels = os.path.join(path_to_data, \"train_multi.txt\")\n\n# testing data\npath_to_test_data = os.path.join(path_to_data, \"test\")\n\n# noisy test data\npath_to_noisy_test_data = os.path.join(path_to_data, \"noisy_test\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.869262Z","iopub.execute_input":"2023-01-15T02:26:58.869926Z","iopub.status.idle":"2023-01-15T02:26:58.879607Z","shell.execute_reply.started":"2023-01-15T02:26:58.869886Z","shell.execute_reply":"2023-01-15T02:26:58.878550Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"num_train_data = len(os.listdir(path_to_train_data))\nnum_test_data = len(os.listdir(path_to_test_data))\nnum_noisy_test_data = len(os.listdir(path_to_noisy_test_data))\nprint(f\"Number of images in: training data: {num_train_data} test data: {num_test_data} noisy test data: {num_test_data}\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:26:58.881173Z","iopub.execute_input":"2023-01-15T02:26:58.881486Z","iopub.status.idle":"2023-01-15T02:26:58.922305Z","shell.execute_reply.started":"2023-01-15T02:26:58.881438Z","shell.execute_reply":"2023-01-15T02:26:58.921343Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Number of images in: training data: 8 test data: 6 noisy test data: 6\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Binary Classification","metadata":{}},{"cell_type":"markdown","source":"## Train ","metadata":{}},{"cell_type":"code","source":"#--------------------------------------Pipeline-------------------------------\n\npipeline = {}\npipeline[\"path_to_results\"] = os.path.join(path_to_binary_results, \"train\")\n\npipeline[\"batch_size\"] = 2\npipeline[\"num_epochs\"] = 10\n\n# for model\npipeline[\"input_shape\"] = (250, 250) \n\n# path to folder containing images \npipeline[\"path_to_images\"] = path_to_train_data\n# path to labels.txt\npipeline[\"path_to_labels\"] = path_to_binary_labels\n\n# split data\npipeline[\"split_type\"] = \"simple\" #\"simpleStratified\" #\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\"\npipeline[\"test_size\"] = 0.2\n#pipeline[\"data\"][\"num_folds\"] = 0.2\n\n# names of the class\npipeline[\"classes\"] = np.array([\"NO_COVID\", \"COVID\"])\n\n# ---------------------------------set up data preprocessing methods and parameters------------------------------------\npipeline[\"data_preprocessing\"] = {}\npipeline[\"data_preprocessing\"][\"train\"] = OrderedDict()\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"] = {}\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"name\"] = \"normalize\"\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"mean\"] = 0\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"std\"] = 255\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"] = {}\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"][\"name\"] = \"resize\"\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"][\"output_shape\"] = (250,250)\n\npipeline[\"data_preprocessing\"][\"valid\"] = OrderedDict()\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"] = {}\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"name\"] = \"normalize\"\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"mean\"] = 0\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"std\"] = 255\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"] = {}\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"][\"name\"] = \"resize\"\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"][\"output_shape\"] = (250,250)\n\n\n\n\n\n# ---------------------------------set up networks and parameters------------------------------------\n\npipeline[\"model\"] = OrderedDict()\npipeline[\"model\"][\"flatten\"] = {}\npipeline[\"model\"][\"flatten\"][\"name\"] = \"flatten\"\npipeline[\"model\"][\"linear1\"] = {}\npipeline[\"model\"][\"linear1\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear1\"][\"neurons\"] = 10\npipeline[\"model\"][\"relu1\"] = {}\npipeline[\"model\"][\"relu1\"][\"name\"] = \"relu\"\npipeline[\"model\"][\"linear2\"] = {}\npipeline[\"model\"][\"linear2\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear2\"][\"neurons\"] = 8\npipeline[\"model\"][\"linear2\"][\"bias\"] = False\npipeline[\"model\"][\"lrelu2\"] = {}\npipeline[\"model\"][\"lrelu2\"][\"name\"] = \"lrelu\"\npipeline[\"model\"][\"lrelu2\"][\"alpha\"] = 1\npipeline[\"model\"][\"linear3\"] = {}\npipeline[\"model\"][\"linear3\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear3\"][\"neurons\"] = 2\npipeline[\"model\"][\"relu3\"] = {}\npipeline[\"model\"][\"relu3\"][\"name\"] = \"relu\"\n\npipeline[\"optimizer\"] = {}\npipeline[\"optimizer\"][\"name\"] = \"adam\"\n\npipeline[\"loss\"] = {}\npipeline[\"loss\"][\"type\"] = \"cross_entropy\"\npipeline[\"loss\"][\"use_weighted_loss\"] = True\npipeline[\"loss\"][\"class_weights\"] = [8]\npipeline[\"loss\"][\"use_single_neuron\"] = False\n\n#---------------------------------------------set up evaluation metrics and parameters------------------------\n\n\npipeline[\"metrics\"] = {}\n\n# accuracy\npipeline[\"metrics\"][\"simple_accuracy\"] = {}\npipeline[\"metrics\"][\"simple_accuracy\"][\"name\"] = \"accuracy\"\npipeline[\"metrics\"][\"simple_accuracy\"][\"type\"] = \"simple\"  \n\npipeline[\"metrics\"][\"balanced_accuracy\"] = {}\npipeline[\"metrics\"][\"balanced_accuracy\"][\"name\"] = \"accuracy\"\npipeline[\"metrics\"][\"balanced_accuracy\"][\"type\"] = \"balanced\"\n\n# precision\npipeline[\"metrics\"][\"precision\"] = {}\npipeline[\"metrics\"][\"precision\"][\"name\"] = \"precision\"\npipeline[\"metrics\"][\"precision\"][\"class_result\"] = \"COVID\"\n\n# recall\npipeline[\"metrics\"][\"sensitivity\"] = {}\npipeline[\"metrics\"][\"sensitivity\"][\"name\"] = \"sensitivity\"\npipeline[\"metrics\"][\"sensitivity\"][\"class_result\"]  = \"COVID\"\n\n# F1 score\npipeline[\"metrics\"][\"f1_score\"] = {}\npipeline[\"metrics\"][\"f1_score\"][\"name\"] = \"F1_score\" \npipeline[\"metrics\"][\"f1_score\"][\"class_result\"] = \"COVID\"\n\n# mcc\npipeline[\"metrics\"][\"mcc\"] = {}\npipeline[\"metrics\"][\"mcc\"][\"name\"] =\"mcc\" \n\n#------------------------------------------------Create Plots --------------------------\npipeline[\"plots\"] = [\"CM\", \"LC\", \"MS\"]\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T03:45:47.959216Z","iopub.execute_input":"2023-01-15T03:45:47.959635Z","iopub.status.idle":"2023-01-15T03:45:47.984772Z","shell.execute_reply.started":"2023-01-15T03:45:47.959601Z","shell.execute_reply":"2023-01-15T03:45:47.983674Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"CNN_training(pipeline)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:02:25.274581Z","iopub.execute_input":"2023-01-15T04:02:25.275384Z","iopub.status.idle":"2023-01-15T04:02:28.487665Z","shell.execute_reply.started":"2023-01-15T04:02:25.275342Z","shell.execute_reply":"2023-01-15T04:02:28.486371Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true,"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Using Device: cuda\nUnique labels found and their frequencies: \nLabel: COVID, %age: 25.00\nLabel: NO_COVID, %age: 75.00\nModel(\n  (seq_model): Sequential(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (linear1): Linear(in_features=62500, out_features=10, bias=True)\n    (relu1): ReLU()\n    (linear2): Linear(in_features=10, out_features=8, bias=False)\n    (lrelu2): LeakyReLU(negative_slope=1)\n    (linear3): Linear(in_features=8, out_features=2, bias=True)\n    (relu3): ReLU()\n  )\n)\n\nFold No: 0 Training data: Unique labels: \nLabel: 0, %age: 66.67\nLabel: 1, %age: 33.33\n\nFold No: 0 Validation data: Unique labels: \nLabel: 0, %age: 100.00\nCrossEntropyLoss()\nAdam (\nParameter Group 0\n    amsgrad: True\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)\nTraining:Fold No: 1/1 Epoch:1/10 Training: Loss: 0.7143815755844116, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.18542680144309998, Bal_accu: 1.0, mcc: 0.0\nSaving Model of first epoch\nTraining:Fold No: 1/1 Epoch:2/10 Training: Loss: 0.5541934867699941, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.30711421370506287, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:3/10 Training: Loss: 0.37245868146419525, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.11562599241733551, Bal_accu: 1.0, mcc: 0.0\nValidation Loss score improved. Saving Model.\nTraining:Fold No: 1/1 Epoch:4/10 Training: Loss: 0.37145260783533257, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.18784111738204956, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:5/10 Training: Loss: 0.2947856585184733, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.5636579990386963, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:6/10 Training: Loss: 0.34245509281754494, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.6769577860832214, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:7/10 Training: Loss: 0.37169741342465085, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.5542483925819397, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:8/10 Training: Loss: 0.3540241202960412, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.4358161389827728, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n  warnings.warn(\"y_pred contains classes not in y_true\")\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n  warnings.warn(\"y_pred contains classes not in y_true\")\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n  warnings.warn(\"y_pred contains classes not in y_true\")\n","output_type":"stream"},{"name":"stdout","text":"Training:Fold No: 1/1 Epoch:9/10 Training: Loss: 0.3366408556078871, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.385858952999115, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTraining:Fold No: 1/1 Epoch:10/10 Training: Loss: 0.2524269421895345, Bal_accu: 0.6666666666666666, mcc: 0.0 Validation: Loss: 0.3017423152923584, Bal_accu: 1.0, mcc: 0.0\nValidaiton Loss score did not improve.\nTrained the model for all folds. Shape: train: loss: (1, 10) accu: (1, 10) mcc: (1, 10) valid: loss: (1, 10) accu: (1, 10) mcc: (1, 10) Learning scores: (1, 3, 2, 10)\nGenerating Predictions\nGenerating predicitons for fold no: 0\nLoading model from /kaggle/working/results/test/binary/train/0/model.pt\nGenerating predicitons for fold no: 0\nLoading model from /kaggle/working/results/test/binary/train/0/model.pt\ngenerated predictions. Shape: train: labels: (1, 6, 2) prob: (1, 6, 2) valid: labels: (1, 2, 2) prob: (1, 2, 2)\n\nEvaluating Metrics on training data . . . \nProcessing: Fold No: 0 Metric: simple_accuracy\nProcessing: Fold No: 0 Metric: balanced_accuracy\nProcessing: Fold No: 0 Metric: precision\nProcessing: Fold No: 0 Metric: sensitivity\nProcessing: Fold No: 0 Metric: f1_score\nProcessing: Fold No: 0 Metric: mcc\n\nResults\nFold No: 0 Metric: simple_accuracy  Score: 0.6666666865348816 \nFold No: 0 Metric: balanced_accuracy  Score: 0.5 \nFold No: 0 Metric: precision  Score: 0.0 \nFold No: 0 Metric: sensitivity  Score: 0.0 \nFold No: 0 Metric: f1_score  Score: 0.0 \nFold No: 0 Metric: mcc  Score: 0.0 \nEvaluated Metrics on the training data successfully. Shape:(1, 6)\n\nEvaluating Metrics on validation data . . . \nProcessing: Fold No: 0 Metric: simple_accuracy\nProcessing: Fold No: 0 Metric: balanced_accuracy\nProcessing: Fold No: 0 Metric: precision\nProcessing: Fold No: 0 Metric: sensitivity\nProcessing: Fold No: 0 Metric: f1_score\nProcessing: Fold No: 0 Metric: mcc\n\nResults\nFold No: 0 Metric: simple_accuracy  Score: 1.0 \nFold No: 0 Metric: balanced_accuracy  Score: 1.0 \nFold No: 0 Metric: precision  Score: 0.0 \nFold No: 0 Metric: sensitivity  Score: 0.0 \nFold No: 0 Metric: f1_score  Score: 0.0 \nFold No: 0 Metric: mcc  Score: 0.0 \nEvaluated Metrics on the validation data successfully. Shape: (1, 6)\n\nEvaluating Metrics on the data using ensmebles. . . \nGenerating predicitons for fold no: 0\nLoading model from /kaggle/working/results/test/binary/train/0/model.pt\nEvaluated Metrics on the data using ensembles. Shape: labels: (1, 8, 2) probs: (1, 8, 2)\nProcessing: Fold No: 0 Metric: simple_accuracy\nProcessing: Fold No: 0 Metric: balanced_accuracy\nProcessing: Fold No: 0 Metric: precision\nProcessing: Fold No: 0 Metric: sensitivity\nProcessing: Fold No: 0 Metric: f1_score\nProcessing: Fold No: 0 Metric: mcc\n\nResults\nFold No: 0 Metric: simple_accuracy  Score: 1.0 \nFold No: 0 Metric: balanced_accuracy  Score: 1.0 \nFold No: 0 Metric: precision  Score: 0.0 \nFold No: 0 Metric: sensitivity  Score: 0.0 \nFold No: 0 Metric: f1_score  Score: 0.0 \nFold No: 0 Metric: mcc  Score: 0.0 \n\nCreating Plots for training data . . .\nCreating Plot: CM Fold No: 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Creating Plot: LC Fold No: 0\nCreating Plot: MS Fold No: 0\nCreated Plots for training data\n\nCreating Plots for validation data\nCreating Plot: CM Fold No: 0\nWarning: key'learning_curves' provided in dict 'plots' but metric score not found. Skipping ploting learning curves\nCreating Plot: MS Fold No: 0\nCreated Plots for validation data\n\nCreating Plots for ensemble data\nCreating Plot: CM Fold No: 0\nWarning: key'learning_curves' provided in dict 'plots' but metric score not found. Skipping ploting learning curves\nCreating Plot: MS Fold No: 0\nCreated Plots for ensemble data\n\nsaving pipeline dictionary to json\n\nGenerating text file for training data\nProcessing Fold No: 0\n\nGenerating text file for validation data\nProcessing Fold No: 0\n\nGenerating text file for ensemble data\nProcessing Fold No: 0\n\nSaving training results \n\nSaving validation results \n\nSaving ensemble results \n\nTraining Completed\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## test data ","metadata":{}},{"cell_type":"code","source":"path_to_json = os.path.join(path_to_binary_results, \"train\", \"training_pipeline.json\")\nsave_path = os.path.join(path_to_binary_results, \"test\")\nCNN_prediction(path_to_images, path_to_json, save_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:53:40.392804Z","iopub.execute_input":"2023-01-15T04:53:40.393218Z","iopub.status.idle":"2023-01-15T04:53:40.428277Z","shell.execute_reply.started":"2023-01-15T04:53:40.393181Z","shell.execute_reply":"2023-01-15T04:53:40.427013Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"Warning: /kaggle/working/results/test/binary/test already exists. Content may get overwritten\nUsing Device: cuda\n(3, 1)\n\nGenerating labels for the data . . . \nGenerating predicitons for fold no: 0\nLoading model from /kaggle/working/results/test/binary/train/0/model.pt\nGenerated labels for the data successfully. Shape: y_pred: (1, 3) y_pred_probs: (1, 3, 2) y_pred_en: (3, 1) y_pred_probs_en: (3, 2)\n\nsaving pipeline dictionary to json\n\nGenerating text file for the data\nProcessing Fold No: 0\n\nGenerating text file for the data ensemble\nProcessing Fold No: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## noisy test data ","metadata":{}},{"cell_type":"code","source":"path_to_json = os.path.join(path_to_binary_results, \"train\", \"training_pipeline.json\")\nsave_path = os.path.join(path_to_binary_results, \"noisy_test\")\nCNN_prediction(path_to_images, path_to_json, save_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:54:47.005078Z","iopub.execute_input":"2023-01-15T04:54:47.005466Z","iopub.status.idle":"2023-01-15T04:54:47.044405Z","shell.execute_reply.started":"2023-01-15T04:54:47.005432Z","shell.execute_reply":"2023-01-15T04:54:47.043079Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":134,"outputs":[{"name":"stdout","text":"Created directory /kaggle/working/results/test/binary/noisy_test\nUsing Device: cuda\n(3, 1)\n\nGenerating labels for the data . . . \nGenerating predicitons for fold no: 0\nLoading model from /kaggle/working/results/test/binary/train/0/model.pt\nGenerated labels for the data successfully. Shape: y_pred: (1, 3) y_pred_probs: (1, 3, 2) y_pred_en: (3, 1) y_pred_probs_en: (3, 2)\n\nsaving pipeline dictionary to json\n\nGenerating text file for the data\nProcessing Fold No: 0\n\nGenerating text file for the data ensemble\nProcessing Fold No: 0\nGenerated Predictions Successfully\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Multiclass Classification","metadata":{}},{"cell_type":"markdown","source":"## Train ","metadata":{}},{"cell_type":"code","source":"pipeline = {}\npipeline[\"path_to_results\"] = os.path.join(path_to_multiclass_results, \"train\")\n\npipeline[\"batch_size\"] = 2\npipeline[\"num_epochs\"] = 10\n\n# for model\npipeline[\"input_shape\"] = (250, 250) \n\n# path to folder containing images \npipeline[\"path_to_images\"] = path_to_train_data\n# path to labels.txt\npipeline[\"path_to_labels\"] = path_to_multi_labels\n\n# split data\npipeline[\"split_type\"] = \"kfold\" #\"simpleStratified\" #\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\"\n#pipeline[\"test_size\"] = 0.2\npipeline[\"num_folds\"] = 3\n\n# names of the class\npipeline[\"classes\"] = np.array([\"Normal\", \"COVID\", \"pneumonia\", \"Lung_Opacity\"])\n\n# ---------------------------------set up data preprocessing methods and parameters------------------------------------\npipeline[\"data_preprocessing\"] = {}\npipeline[\"data_preprocessing\"][\"train\"] = OrderedDict()\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"] = {}\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"name\"] = \"normalize\"\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"mean\"] = 0\npipeline[\"data_preprocessing\"][\"train\"][\"t1\"][\"std\"] = 255\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"] = {}\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"][\"name\"] = \"resize\"\npipeline[\"data_preprocessing\"][\"train\"][\"t2\"][\"output_shape\"] = (250,250)\n\npipeline[\"data_preprocessing\"][\"valid\"] = OrderedDict()\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"] = {}\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"name\"] = \"normalize\"\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"mean\"] = 0\npipeline[\"data_preprocessing\"][\"valid\"][\"t1\"][\"std\"] = 255\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"] = {}\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"][\"name\"] = \"resize\"\npipeline[\"data_preprocessing\"][\"valid\"][\"t2\"][\"output_shape\"] = (250,250)\n\n\n\n\n\n# ---------------------------------set up networks and parameters------------------------------------\n\npipeline[\"model\"] = OrderedDict()\npipeline[\"model\"][\"flatten\"] = {}\npipeline[\"model\"][\"flatten\"][\"name\"] = \"flatten\"\npipeline[\"model\"][\"linear1\"] = {}\npipeline[\"model\"][\"linear1\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear1\"][\"neurons\"] = 10\npipeline[\"model\"][\"relu1\"] = {}\npipeline[\"model\"][\"relu1\"][\"name\"] = \"relu\"\npipeline[\"model\"][\"linear2\"] = {}\npipeline[\"model\"][\"linear2\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear2\"][\"neurons\"] = 8\npipeline[\"model\"][\"linear2\"][\"bias\"] = False\npipeline[\"model\"][\"lrelu2\"] = {}\npipeline[\"model\"][\"lrelu2\"][\"name\"] = \"lrelu\"\npipeline[\"model\"][\"lrelu2\"][\"alpha\"] = 1\npipeline[\"model\"][\"linear3\"] = {}\npipeline[\"model\"][\"linear3\"][\"name\"] = \"linear\"\npipeline[\"model\"][\"linear3\"][\"neurons\"] = 4\npipeline[\"model\"][\"relu3\"] = {}\npipeline[\"model\"][\"relu3\"][\"name\"] = \"relu\"\n\npipeline[\"optimizer\"] = {}\npipeline[\"optimizer\"][\"name\"] = \"adam\"\n\npipeline[\"loss\"] = {}\npipeline[\"loss\"][\"type\"] = \"cross_entropy\"\npipeline[\"loss\"][\"use_weighted_loss\"] = True\npipeline[\"loss\"][\"use_single_neuron\"] = False\n\n#---------------------------------------------set up evaluation metrics and parameters------------------------\n\n\npipeline[\"metrics\"] = {}\n\n# accuracy\npipeline[\"metrics\"][\"simple_accuracy\"] = {}\npipeline[\"metrics\"][\"simple_accuracy\"][\"name\"] = \"accuracy\"\npipeline[\"metrics\"][\"simple_accuracy\"][\"type\"] = \"simple\"  \n\npipeline[\"metrics\"][\"balanced_accuracy\"] = {}\npipeline[\"metrics\"][\"balanced_accuracy\"][\"name\"] = \"accuracy\"\npipeline[\"metrics\"][\"balanced_accuracy\"][\"type\"] = \"balanced\"\n\n# precision\npipeline[\"metrics\"][\"precision\"] = {}\npipeline[\"metrics\"][\"precision\"][\"name\"] = \"precision\"\npipeline[\"metrics\"][\"precision\"][\"class_result\"] = \"COVID\"\n\n# recall\npipeline[\"metrics\"][\"sensitivity\"] = {}\npipeline[\"metrics\"][\"sensitivity\"][\"name\"] = \"sensitivity\"\npipeline[\"metrics\"][\"sensitivity\"][\"class_result\"]  = \"COVID\"\n\n# F1 score\npipeline[\"metrics\"][\"f1_score\"] = {}\npipeline[\"metrics\"][\"f1_score\"][\"name\"] = \"F1_score\" \npipeline[\"metrics\"][\"f1_score\"][\"class_result\"] = \"COVID\"\n\n# mcc\npipeline[\"metrics\"][\"mcc\"] = {}\npipeline[\"metrics\"][\"mcc\"][\"name\"] =\"mcc\" \n\n#------------------------------------------------Create Plots --------------------------\npipeline[\"plots\"] = [\"CM\", \"LC\", \"MS\"]\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T05:06:09.379780Z","iopub.execute_input":"2023-01-15T05:06:09.380169Z","iopub.status.idle":"2023-01-15T05:06:09.401984Z","shell.execute_reply.started":"2023-01-15T05:06:09.380125Z","shell.execute_reply":"2023-01-15T05:06:09.400724Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"CNN_training(pipeline)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T05:06:09.932855Z","iopub.execute_input":"2023-01-15T05:06:09.933463Z","iopub.status.idle":"2023-01-15T05:06:09.984302Z","shell.execute_reply.started":"2023-01-15T05:06:09.933417Z","shell.execute_reply":"2023-01-15T05:06:09.981922Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"Using Device: cuda\nUnique labels found and their frequencies: \nLabel: COVID, %age: 25.00\nLabel: Lung_Opacity, %age: 25.00\nLabel: Normal, %age: 25.00\nLabel: pneumonia, %age: 25.00\nSplit the data successfully. Shape: y_train: (3,) y_valid: (3,)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1917950266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCNN_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/1116347226.py\u001b[0m in \u001b[0;36mCNN_training\u001b[0;34m(pipeline)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# number of images in train and valid data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mnum_images_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mnum_images_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}]},{"cell_type":"markdown","source":"## Test data ","metadata":{}},{"cell_type":"code","source":"path_to_json = os.path.join(path_to_multiclass_results, \"train\", \"training_pipeline.json\")\nsave_path = os.path.join(path_to_multiclass_results, \"test\")\nCNN_prediction(path_to_images, path_to_json, save_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:56:18.777556Z","iopub.execute_input":"2023-01-15T04:56:18.778233Z","iopub.status.idle":"2023-01-15T04:56:18.804867Z","shell.execute_reply.started":"2023-01-15T04:56:18.778182Z","shell.execute_reply":"2023-01-15T04:56:18.801818Z"},"trusted":true},"execution_count":138,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1053318610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_to_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_multiclass_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_pipeline.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_multi_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mCNN_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'path_to_multi_results' is not defined"],"ename":"NameError","evalue":"name 'path_to_multi_results' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Noisy data ","metadata":{}},{"cell_type":"code","source":"save_path = os.path.joib(path_to_multiclass_results, \"noisy_test\")\nCNN_prediction(path_to_noisy_test_data, path_to_results, save_path, data_transform, batch_size)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.735161Z","iopub.status.idle":"2023-01-15T02:27:05.735894Z","shell.execute_reply.started":"2023-01-15T02:27:05.735623Z","shell.execute_reply":"2023-01-15T02:27:05.735663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Joel code","metadata":{}},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport torch\nfrom skimage import io, transform\n\nfrom PIL import Image\n\nclass2id = test_count = {'Normal': 0, 'COVID': 1, 'pneumonia': 2, 'Lung_Opacity': 3}\n\nid2class = {0: 'Normal', 1: 'COVID', 2: 'pneumonia', 3:'Lung_Opacity'}\n\nclass COVIDxDataset(Dataset):\n    def __init__(self, txt_frame_file, images_path, transform=None):\n        \"\"\"\n        Args:\n            txt_frame_file (string): Path to the txt files with labels.\n            images_path (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.covidx_frame = pd.read_csv(txt_frame_file, delim_whitespace=True) \n        \n        #self.landmarks_frame = pd.read_csv(csv_file)\n        self.root_dir = images_path\n        self.transform = transform\n        self.class2id = test_count = {'Normal': 0, 'COVID': 1, 'pneumonia': 2, 'Lung_Opacity': 3}\n        self.id2class = {0: 'Normal', 1: 'COVID', 2: 'pneumonia', 3:'Lung_Opacity'}\n        \n        \n    def pil_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n        \n    \n    def __len__(self):\n        return len(self.covidx_frame)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        image_path = os.path.join(self.root_dir,\n                                self.covidx_frame.iloc[idx, 1])\n        #print(img_name)\n        \n        image = self.pil_loader(image_path)\n        #image = io.imread(img_name)\n        \n        \n        label = self.covidx_frame.iloc[idx, 2]\n        #landmarks = np.array([landmarks])\n        #landmarks = landmarks.astype('float').reshape(-1, 2)\n        #sample = {'image': image, 'label': label}\n\n        if self.transform is not None:\n            image = self.transform(image)\n            \n        sample = (image, self.class2id[label])\n\n        return sample\n        ","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.737200Z","iopub.status.idle":"2023-01-15T02:27:05.737924Z","shell.execute_reply.started":"2023-01-15T02:27:05.737672Z","shell.execute_reply":"2023-01-15T02:27:05.737696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms, utils\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nimport math\n\nfrom torch.utils.data import random_split","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.739343Z","iopub.status.idle":"2023-01-15T02:27:05.740074Z","shell.execute_reply.started":"2023-01-15T02:27:05.739814Z","shell.execute_reply":"2023-01-15T02:27:05.739839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'resnet'\nbatch_size = 32\nnum_epochs = 10\nfeature_extract = True\n\n#TODO: get automatically these parameters\nnum_classes = 4","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.741382Z","iopub.status.idle":"2023-01-15T02:27:05.742211Z","shell.execute_reply.started":"2023-01-15T02:27:05.741914Z","shell.execute_reply":"2023-01-15T02:27:05.741943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs = 25, is_inception= False):\n    since = time.time()\n    \n    val_acc_history = []\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs -1))\n        \n        #Each epoch as a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            \n            # Iterate over data\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                #zero the parameter gradients\n                optimizer.zero_grad()\n                \n                #forward\n                # track history\n                with torch.set_grad_enabled(phase == 'train'):\n                    \n                    if is_inception and phase == 'train':\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                        \n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                        \n                    _, preds = torch.max(outputs, 1)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                #statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            epoch_loss = running_loss /len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n            \n        print()\n        \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:.4f}'.format(best_acc))\n    \n    #load the best model\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.743805Z","iopub.status.idle":"2023-01-15T02:27:05.744532Z","shell.execute_reply.started":"2023-01-15T02:27:05.744265Z","shell.execute_reply":"2023-01-15T02:27:05.744289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set model parameters\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.745834Z","iopub.status.idle":"2023-01-15T02:27:05.746565Z","shell.execute_reply.started":"2023-01-15T02:27:05.746287Z","shell.execute_reply":"2023-01-15T02:27:05.746313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.747922Z","iopub.status.idle":"2023-01-15T02:27:05.748705Z","shell.execute_reply.started":"2023-01-15T02:27:05.748373Z","shell.execute_reply":"2023-01-15T02:27:05.748399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model for this run\n#model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\n#print(model_ft)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.750059Z","iopub.status.idle":"2023-01-15T02:27:05.750808Z","shell.execute_reply.started":"2023-01-15T02:27:05.750529Z","shell.execute_reply":"2023-01-15T02:27:05.750554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.752137Z","iopub.status.idle":"2023-01-15T02:27:05.752895Z","shell.execute_reply.started":"2023-01-15T02:27:05.752619Z","shell.execute_reply":"2023-01-15T02:27:05.752643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Data\n\n# configure paths to the description txt file and the images folder\n#train_txt_file = '/kaggle/input/ismdatasetforclassificationofdieases/ism_dataset/raw_data/train_multi.txt'\n#train_images_path = '/kaggle/input/ismdatasetforclassificationofdieases/ism_dataset/raw_data/train'\n\n#test_txt_file = '../COVID-Net/test_split_v2.txt'\n#test_images_path = '../covid-chestxray-dataset/data/test'\n\n#train_dataset = covidx.COVIDxDataset(train_txt_file, train_images_path)\n#test_dataset = covidx.COVIDxDataset(val_txt_file, val_images_path)\n\nprint(\"Initializing Datasets and Dataloaders...\")\n\n# Create training and validation datasets\nbatch_size = 128\nval_size = 150\n\n#training_dataset = COVIDxDataset(train_txt_file, train_images_path)\n#val_size =  math.floor(len(training_dataset)*0.3)\n#train_size = len(training_dataset) - val_size\n#train_data,val_data = random_split(training_dataset,[train_size,val_size])\n\n#image_datasets = {'train': train_data, 'val': val_data}\n#image_datasets = {'train': covidx.COVIDxDataset(train_txt_file, train_images_path, data_transforms['train']), 'val': covidx.COVIDxDataset(test_txt_file, test_images_path, data_transforms['val'])}\n#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# Create training and validation dataloaders\n#dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}\n\n#print(dataloaders_dict)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.754195Z","iopub.status.idle":"2023-01-15T02:27:05.754922Z","shell.execute_reply.started":"2023-01-15T02:27:05.754670Z","shell.execute_reply":"2023-01-15T02:27:05.754696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Detect if we have a GPU available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.756225Z","iopub.status.idle":"2023-01-15T02:27:05.757219Z","shell.execute_reply.started":"2023-01-15T02:27:05.756957Z","shell.execute_reply":"2023-01-15T02:27:05.756983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the optimizer\n\n#model_ft = model_ft.to(device)\n\n#params_to_update = model_ft.parameters()\n#print(\"Params to learn\")\n\n#if feature_extract:\n#    params_to_update = []\n#    for name, param in model_ft.named_parameters():\n#        if param.requires_grad == True:\n#            params_to_update.append(param)\n#            print(\"\\t\", name)\n#else:\n#    for name, param in model_ft.named_parameters():\n #       if param.requires_grad == True:\n  #          print(\"\\t\", name)\n #           \n#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum = 0.9)\n#criterion = nn.CrossEntropyLoss()\n\n#model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs = num_epochs, is_inception=(model_name==\"inception\"))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-15T02:27:05.758762Z","iopub.status.idle":"2023-01-15T02:27:05.759494Z","shell.execute_reply.started":"2023-01-15T02:27:05.759218Z","shell.execute_reply":"2023-01-15T02:27:05.759243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
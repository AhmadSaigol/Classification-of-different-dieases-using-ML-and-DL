{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:55.795432Z","iopub.status.busy":"2023-01-17T07:00:55.794979Z","iopub.status.idle":"2023-01-17T07:00:55.824479Z","shell.execute_reply":"2023-01-17T07:00:55.823580Z","shell.execute_reply.started":"2023-01-17T07:00:55.795340Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","#import numpy as np # linear algebra\n","#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Warnings"]},{"cell_type":"code","execution_count":2,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:55.827266Z","iopub.status.busy":"2023-01-17T07:00:55.826790Z","iopub.status.idle":"2023-01-17T07:00:55.835678Z","shell.execute_reply":"2023-01-17T07:00:55.834653Z","shell.execute_reply.started":"2023-01-17T07:00:55.827221Z"},"trusted":true},"outputs":[],"source":["# To ignore warinings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Import Necessary Libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:55.837984Z","iopub.status.busy":"2023-01-17T07:00:55.837285Z","iopub.status.idle":"2023-01-17T07:00:58.777566Z","shell.execute_reply":"2023-01-17T07:00:58.776155Z","shell.execute_reply.started":"2023-01-17T07:00:55.837948Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import cv2 \n","import os\n","\n","from collections import OrderedDict\n","\n","import torch\n","from torch import nn\n","from torchvision.io import read_image,ImageReadMode\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold, KFold\n","from sklearn import preprocessing\n","from sklearn.metrics import matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, f1_score, recall_score\n","\n","from matplotlib import pyplot as plt\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.image as mpimg\n","\n","import json\n","\n","import pandas as pd\n","\n","import time\n","import datetime"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["* load training labels.txt file and split the data set into train and valid dataset using simple Stratified or kfold stratified.\n","* Setup Dataset and Dataloader in Pytorch for loading training, validation, test and noisy dataset and for applying transformations and data augmentation\n","\n","Transformations (examples):\n","   * Normalize\n","   * resize\n","   * zero centering (AlexNet, VGG etc) during training and depedning the method, save values calculated during training and use them to apply on validation, testing and training\n","   * denoise the image (if required...how to know that?)\n","       \n","Data Augmentation (examples):\n","   * cropping, scaling images, similar to ResNet,or maybe something else etc (which ones to use will depend upon type of images we expect in the real world...or in our project in noisy test/test dataset)\n","   * If we know somehow what kind of noise will be there in noisy_test/test dataset (e.g. gaussion noise, salt and pepper, etc) then we can add something similar to training dataset to create more images and use them to train the model as well\n","\n","Make use of GPU\n","\n","Save all the hyperparameters somewhere. "]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Split the data"]},{"cell_type":"code","execution_count":4,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.780860Z","iopub.status.busy":"2023-01-17T07:00:58.779978Z","iopub.status.idle":"2023-01-17T07:00:58.795331Z","shell.execute_reply":"2023-01-17T07:00:58.794317Z","shell.execute_reply.started":"2023-01-17T07:00:58.780800Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def split_data(y, split_type, test_size=0.3, n_folds=5):\n","    \"\"\"\n","    Split the datasets\n","\n","    Parameters:\n","        y: array of labels and image ids with shape (num_images, 2)\n","        split_type: type of splitting (\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\")\n","        test_size: fraction of data for testing (default=0.3)\n","        n_folds: number of folds (default=5)\n","    Returns:\n","        train_labels: numpy array of shape(folds, num_images, 2)\n","        valid_labels: numpy array of shape(folds, num_images, 2)\n","    \n","    \"\"\"\n","\n","    if split_type==\"simple\":\n","        \n","        print(f\"Splitting data using Simple {100-test_size*100}-{test_size*100} ratio\")\n","       \n","        # shuffle data before split\n","        ss = ShuffleSplit(n_splits=1, test_size=test_size)\n","\n","        for train_index, valid_index in ss.split(X=np.ones(len(y))):\n","            y_train = np.expand_dims(y[train_index], axis=0)\n","            y_valid = np.expand_dims(y[valid_index], axis=0)\n","    \n","    elif split_type==\"simpleStratified\":\n","        \n","        \n","        print(f\"Splitting data using Simple Stratified with {100-test_size*100}-{test_size*100} ratio\")\n","\n","        # shuffle data before split\n","        ss = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n","\n","        for train_index, valid_index in ss.split(X=np.ones(len(y)), y=y[:,1]):\n","            y_train = np.expand_dims(y[train_index], axis=0)\n","            y_valid = np.expand_dims(y[valid_index], axis=0)\n","\n","    \n","    elif split_type==\"kfold\":\n","        \n","        print(f\"Splitting data using kfolds with number of folds: {n_folds}\")\n","\n","        # shuffle data before creating folds\n","        kf = KFold(n_splits=n_folds, shuffle=True)\n","        \n","        y_train = []\n","        y_valid = []\n","        for train_index, valid_index in kf.split(X=np.ones(len(y))):\n","            y_train.append(y[train_index])\n","            y_valid.append(y[valid_index])\n","        \n","        y_train = np.array(y_train)\n","        y_valid = np.array(y_valid)\n","\n","    \n","    elif split_type == \"kfoldStratified\":\n","        \n","        \n","        print(f\"Splitting data using kfold Stratfication with number of folds: {n_folds}\")\n","\n","        # shuffle data before creating folds\n","        skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n","        y_train = []\n","        y_valid = []\n","        \n","        for train_index, valid_index in skf.split(X=np.ones(len(y)), y=y[:,1]):\n","\n","            y_train.append(y[train_index])\n","            y_valid.append(y[valid_index])\n","\n","        y_train = np.array(y_train)\n","        y_valid = np.array(y_valid)\n","\n","    else:\n","        raise ValueError(f\"Unknown value encountered for the parameter 'split_type' during splitting of the data. received {split_type}\")\n","\n","    return y_train, y_valid"]},{"cell_type":"code","execution_count":5,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.800269Z","iopub.status.busy":"2023-01-17T07:00:58.799951Z","iopub.status.idle":"2023-01-17T07:00:58.814628Z","shell.execute_reply":"2023-01-17T07:00:58.813688Z","shell.execute_reply.started":"2023-01-17T07:00:58.800240Z"},"trusted":true},"outputs":[],"source":["\n","#path_to_labels = \"/kaggle/input/ismdatasetforclassificationofdieases/code_testing/code_testing/train_binary.txt\"\n","#split_type = \"simple\"\n","#test_size= 0.2\n","#n_folds = 4\n","#img_ids_labels = np.loadtxt(path_to_labels, dtype=str, delimiter=\" \")\n","#y_train, y_valid = split_data(y=img_ids_labels, split_type=split_type, test_size=test_size, n_folds=n_folds)  \n","#print(\"train\")\n","#print(y_train.shape)\n","#print(\"valid\")\n","#print(y_valid.shape)\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Encode labels"]},{"cell_type":"code","execution_count":6,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.816681Z","iopub.status.busy":"2023-01-17T07:00:58.815999Z","iopub.status.idle":"2023-01-17T07:00:58.825870Z","shell.execute_reply":"2023-01-17T07:00:58.824785Z","shell.execute_reply.started":"2023-01-17T07:00:58.816643Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def label_encoder(y, classes, to_numbers):\n","    \"\"\"\n","    encodes target labels with value between 0 and n_classes-1 and vice versa\n","\n","    Parameter:\n","        y: labels of numpy array (num_images,)\n","        classes: numpy array of names of classes\n","        to_numbers True/False: whether to transfer from string to numbers or vice versa\n","\n","    Returns:\n","        result: encoded labels of numpy array (num_images, 1)\n","                or labels of numpy array (num_images, 1)\n","    \"\"\"\n","\n","    le = preprocessing.LabelEncoder()\n","    \n","    if type(classes).__name__ == 'list':\n","        classes = np.array(classes)\n","    le.classes_ = classes\n","    \n","    if to_numbers:\n","        return le.transform(y.ravel())\n","    else:\n","        return le.inverse_transform(y.ravel().astype(int)) \n"]},{"cell_type":"code","execution_count":7,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.827945Z","iopub.status.busy":"2023-01-17T07:00:58.827613Z","iopub.status.idle":"2023-01-17T07:00:58.837021Z","shell.execute_reply":"2023-01-17T07:00:58.835962Z","shell.execute_reply.started":"2023-01-17T07:00:58.827869Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#classes = np.array([\"Normal\", \"COVID\", \"pneumonia\", \"Lung_Opacity\"]) \n","#classes = np.array([\"NO_COVID\", \"COVID\"])\n","#for nf in range(n_folds):\n","#    y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=True)\n","#    y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=True)\n","\n","#print(\"y-train: \", y_train.shape)\n","#print(\"y-valid: \", y_valid.shape)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Dataset "]},{"cell_type":"code","execution_count":8,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.840133Z","iopub.status.busy":"2023-01-17T07:00:58.839425Z","iopub.status.idle":"2023-01-17T07:00:58.853617Z","shell.execute_reply":"2023-01-17T07:00:58.852609Z","shell.execute_reply.started":"2023-01-17T07:00:58.840098Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    \"\"\"\n","    \n","    Parameters:\n","        labels: labels of shape(num_images, 2) or (num_images, 1)\n","        path_to_images: path to the folder containing the images\n","        transform: transform to be applied on a sample\n","        \n","        When combined with dataloader, it returns:\n","            image: tensor of shape (batch, 1, height, width)\n","            label: tensor of shape (batch)\n","    \n","    \"\"\"\n","    def __init__(self, labels, path_to_images, transform=None):\n","        self.img_labels = labels\n","        self.img_dir = path_to_images\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.img_labels.shape[0]\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.img_dir, self.img_labels[index, 0])\n","        \n","        # read image \n","        image = read_image(img_path, ImageReadMode.GRAY).float()\n","        \n","        if self.img_labels.shape[-1]==2:\n","            label = self.img_labels[index, 1].astype(int)\n","        else:\n","            label = -1.0 # just place holder for valid data\n","            \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        return image, label"]},{"cell_type":"code","execution_count":9,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.855556Z","iopub.status.busy":"2023-01-17T07:00:58.855136Z","iopub.status.idle":"2023-01-17T07:00:58.867042Z","shell.execute_reply":"2023-01-17T07:00:58.866034Z","shell.execute_reply.started":"2023-01-17T07:00:58.855522Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def data_preprocessing(transformations):\n","    \"\"\"\n","    Returns compose of transforms\n","    \n","    Parameters:\n","        transformations: Ordered dict with structure\n","        transformations[\"transform_1\"] = {}\n","        transformations[\"transform_1\"][\"name\"] = value\n","        transformations[\"transform_1\"][\"parameter_1\"] = value\n","        transformations[\"transform_1\"][\"parameter_2\"] = value\n","        \n","        transformations[\"transform_2\"] = {}\n","        transformations[\"transform_2\"][\"name\"] = value\n","        transformations[\"transform_2\"][\"parameter_1\"] = value\n","        transformations[\"transform_2\"][\"parameter_2\"] = value\n","        \n","    Currently supports transformation: \n","        \"normalize\": \n","                    keys: mean (default=0) \n","                           std (default=255), \n","        \"resize\": \n","                keys: output_shape, \n","                      \n","    \n","    \n","    # train transform will be different from valid transform (CHECK)\n","    \"\"\"\n","    \n","    preprocess = []\n","    \n","    for tran in transformations.keys():\n","        tran_name = transformations[tran][\"name\"]\n","        \n","        # normalization\n","        if tran_name == \"normalize\":\n","            norm = transformations[tran].keys()\n","            if \"mean\" in norm:\n","                mean = [transformations[tran][\"mean\"]]\n","            else:\n","                mean = [0]\n","            \n","            if \"std\" in norm:\n","                std = [transformations[tran][\"std\"]]\n","            else:\n","                std = [255]\n","                \n","            preprocess.append(transforms.Normalize(mean=mean,\n","                             std=std))\n","        # resize\n","        elif tran_name == \"resize\":\n","            resize = transformations[tran].keys()\n","            \n","            if \"output_shape\" in resize:\n","                output_shape = transformations[tran][\"output_shape\"]\n","            else:\n","                raise ValueError(\"Output shape must be provided while resizing\")\n","            \n","            preprocess.append(transforms.Resize(output_shape))\n","        \n","        else:\n","            raise ValueError(\"Unknown transformation passed\")\n","    \n","    return transforms.Compose(preprocess)"]},{"cell_type":"code","execution_count":10,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.869113Z","iopub.status.busy":"2023-01-17T07:00:58.868747Z","iopub.status.idle":"2023-01-17T07:00:58.883432Z","shell.execute_reply":"2023-01-17T07:00:58.882278Z","shell.execute_reply.started":"2023-01-17T07:00:58.869080Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","#path_to_images = \"/kaggle/input/ismdatasetforclassificationofdieases/code_testing/code_testing/train\"\n","#batch_size = 2\n","\n","#data_transform = OrderedDict()\n","#data_transform[\"t1\"] = {}\n","#data_transform[\"t1\"][\"name\"] = \"normalize\"\n","#data_transform[\"t1\"][\"mean\"] = 0\n","#data_transform[\"t1\"][\"std\"] = 255\n","#data_transform[\"t2\"] = {}\n","#data_transform[\"t2\"][\"name\"] = \"resize\"\n","#data_transform[\"t2\"][\"output_shape\"] = (5,5)\n","\n","\n","#data_transforms = data_preprocessing(data_transform)\n","\n","#data_transforms = transforms.Compose([\n","#        transforms.RandomSizedCrop(224),\n","#        transforms.RandomHorizontalFlip(),\n","#        transforms.ToTensor(),\n","#        transforms.Normalize(mean=[0],\n","#                             std=[255]),\n","#        transforms.Resize((250,250))\n","#    ])\n","\n","\n","\n","#for fold in range(n_folds):\n","\n","    #train_data = ImageDataset(y_train[fold], path_to_images, transform=data_transforms)\n","    #train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","#    print(len(train_dataloader))\n"," #   for x, y in train_dataloader:\"\"\"\n","  #  #print(f\"Fold No: {fold} Train: x shape: {x.shape} y_shape: {y.shape}\")\n","   # \"\"\"\n","   # valid_data = ImageDataset(y_valid[fold], path_to_images, transform=data_transforms)\n","   # valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n","  #  print(len(valid_dataloader))\n","  #  for x, y in valid_dataloader:\"\"\"\n","#print(f\"Fold No: {fold} Valid: x shape: {x.shape} y_shape: {y.shape}\")\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Setup Model"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["Model setup could be done using the following ways:\n","   1. Model with user defined layers.\n","   2. Pretrained Model\n","   3. Ensemble of models\n","\n","Layers could be:\n","   * Convolution\n","   * Activation (Linear, ReLU, LReLU, PReLU, tanh, etc)\n","   * Pooling (Max, Average, Global)\n","   * Fully Connected Layer\n","   * Dropout\n","   * Batch Normalization\n","and many others\n","\n","These layers could be added to the any model. Which layers to be used can be find by hit and trial method or from literature\n","\n","Pretrained Model could be:\n","   * VGG\n","   * ResNet\n","   * GoogleLeNet\n","and many others.\n","\n","Which pretrained model to use can be find by literature and how many layers to be trained can be determined by hit and trial or from literature.\n","\n","We can always combine pretrained model with own custom model.\n","\n","Make use of GPU\n","\n","Save the model, and all the hyperparamters and all the info that may be learned during training and may be required in testing phase"]},{"cell_type":"code","execution_count":2,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:04:27.871133Z","iopub.status.busy":"2023-01-17T07:04:27.870754Z","iopub.status.idle":"2023-01-17T07:04:27.896610Z","shell.execute_reply":"2023-01-17T07:04:27.895669Z","shell.execute_reply.started":"2023-01-17T07:04:27.871099Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Sets up the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    layers: OrderedDict with format:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    output layer must be added as well\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape, layers):\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}],"source":["class Model(nn.Module):\n","    \"\"\"\n","    Sets up the model\n","    layers: OrderedDict with format:\n","        layers[\"layer_1\"] = {}\n","        layers[\"layer_1\"][\"name\"] = value\n","        layers[\"layer_1\"][\"parameter1\"] = value\n","        layers[\"layer_1\"][\"parameter2\"] = value\n","        \n","        layers[\"layer_2\"] = {}\n","        layers[\"layer_2\"][\"name\"] = value\n","        layers[\"layer_2\"][\"parameter1\"] = value\n","        layers[\"layer_2\"][\"parameter2\"] = value\n","        \n","    currently supports layer names. \"linear\", \"flatten\", \"relu\", \"lrelu\"\n","    \n","    output layer must be added as well\n","    \"\"\"\n","    def __init__(self, input_shape, layers):\n","        super(Model, self).__init__()\n","        self.input_shape = input_shape\n","        self.layers = layers\n","        self.seq_model = nn.Sequential(self.get_model())\n","    \n","    def forward(self, x):\n","        return self.seq_model(x)\n","    \n","    def get_model(self):\n","        \n","        arch = []\n","        self.layer = \"Init\"\n","        self.pre_layer_output = self.input_shape  \n","        \n","        for layer in self.layers.keys():\n","            self.layer = layer\n","            layer_name = self.layers[layer][\"name\"] \n","            \n","            # Linear Layer \n","            if layer_name == \"linear\":\n","                arch.append(self.add_linear(self.layers[layer]))\n","                \n","            # ReLU\n","            elif layer_name == \"relu\":\n","                arch.append(self.add_relu(self.layers[layer]))\n","                \n","            # LeakyReLU\n","            elif layer_name == \"lrelu\":\n","                arch.append(self.add_lrelu(self.layers[layer]))\n","            \n","            # flatten\n","            elif layer_name == \"flatten\":\n","                arch.append(self.add_flatten(self.layers[layer]))\n","                \n","            # conv\n","            elif layer_name == \"conv\":\n","                arch.append(self.add_conv(self.layers[layer]))\n","            \n","            # max pooling\n","            elif layer_name == \"max_pool\":\n","                arch.append(self.add_max_pool(self.layers[layer]))\n","            \n","            else:\n","                raise ValueError(\"Unknown layer encountered\")\n","\n","        return OrderedDict(arch)\n","    \n","    def add_linear(self, parameters):\n","        \"\"\"\n","        Adds Linear Layer\n","        \n","        parameters: dict containing keys:\n","            neurons: number of neurons in layer\n","            bias: whether to add bias term (default = True)\n","        \"\"\"\n","        param = parameters.keys()\n","        \n","        if \"neurons\" in param:\n","            neurons = parameters[\"neurons\"]\n","        else:\n","            raise ValueError (\"Number of neurons must be provided\")\n","            \n","        if \"bias\" in param:\n","            bias = parameters[\"bias\"]\n","        else:\n","            bias = True\n","            \n","        linear = (f'{self.layer}', nn.Linear(\n","                                    in_features = self.pre_layer_output, \n","                                    out_features= neurons, \n","                                    bias = bias))\n","        self.pre_layer_output = neurons\n","        \n","        return linear\n","    \n","    def add_relu(self, parameters):\n","        \"\"\"\n","        Adds ReLU layer\n","        \"\"\"\n","        return (f'{self.layer}', nn.ReLU())\n","    \n","    def add_lrelu(self, parameters):\n","        \"\"\"\n","        Adds ReLU layer\n","        Parameters:\n","            alpha: negative slope (default = 1e-2)\n","        \"\"\"\n","        if \"alpha\" in parameters.keys():\n","            alpha = parameters[\"alpha\"]\n","        else:\n","            alpha = 1e-2\n","        return (f'{self.layer}', nn.LeakyReLU(alpha))\n","    \n","    def add_flatten(self, parameters):\n","        \"\"\"\n","        Adds Flatten layer\n","        \"\"\"\n","        flatten_layer = (f'{self.layer}', nn.Flatten())\n","        in_shape = self.pre_layer_output\n","        \n","        # calculate output shape\n","        out_shape = 1\n","        for d in range(len(in_shape)):\n","            out_shape *= in_shape[d]\n","        \n","        self.pre_layer_output = out_shape\n","        \n","        return flatten_layer\n","    \n","    def add_conv(self, parameters):\n","        \"\"\"\n","        Adds Conv layer\n","        \n","        Parameters:\n","            number_of_kernels: int\n","            kernel_size: int or tuple of ints\n","            stride: int or tuple of ints (default=1)\n","            padding: 'valid' or 'same' or tuple of ints (default='valid')\n","            bias: default=True\n","            \n","        \"\"\"\n","        param_keys = parameters.keys()\n","        \n","        if \"number_of_kernels\" in param_keys:\n","            out_channels = parameters[\"number_of_kernels\"]\n","        else:\n","            raise ValueError(\"When adding Convulational Layer, kernel_size must be provided\")\n","        \n","        \n","        if \"kernel_size\" in param_keys:\n","            kernel_size = parameters[\"kernel_size\"]\n","        else:\n","            raise ValueError(\"When adding Convulational Layer, kernel_size must be provided\")\n","        \n","        if \"stride\" in param_keys:\n","            stride = parameters[\"stride\"]\n","        else:\n","            stride = 1\n","            \n","        if \"padding\" in param_keys:\n","            padding = parameters[\"padding\"]\n","        else:\n","            padding = 'valid'\n","        \n","        if \"bias\" in param_keys:\n","            bias = parameters[\"bias\"]\n","        else:\n","            bias = True\n","        \n","        if(len(self.pre_layer_output)) != 3:\n","            raise ValueError(f\"The input shape to the Conv Layer is not correct. {self.pre_layer_output}\")\n","         \n","        if len(self.pre_layer_output) == 2:\n","            in_channels = 1\n","            in_height, in_width =  self.pre_layer_output\n","        else:\n","            in_channels, in_height, in_width =  self.pre_layer_output\n","        \n","        if padding == 'valid':\n","            pad = 0\n","        \n","        if padding == 'same':\n","            pad =  ( (in_height - 1)* stride + kernel_size - in_height)/2\n","       \n","        \n","        out_height = (in_height + 2*pad - kernel_size)/ stride + 1\n","        out_width = (in_width + 2*pad - kernel_size)/ stride + 1\n","        \n","        if out_width %1 !=0 or out_height %1 !=0 :\n","            raise ValueError(f\"Combination of pad, stride and kernel size lead to decimal number in conv layer. {out_height}\")\n","\n","        self.pre_layer_output = (out_channels, int(out_height), int(out_width))\n","        \n","        conv_layer = (f'{self.layer}', nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias))\n","        \n","        return conv_layer\n","    \n","    def add_max_pool(self, parameters):\n","        \"\"\"\n","        Adds Max pooling layer\n","        \n","        Parameters:\n","            kernel_size: int or tuple of ints\n","            stride: int or tuple of ints (default=2)\n","            padding:int or tuple of ints (default=0)\n","        \n","        \"\"\"\n","        \n","        param_keys = parameters.keys()\n","        \n","        if \"kernel_size\" in param_keys:\n","            kernel_size = parameters[\"kernel_size\"]\n","        else:\n","            raise ValueError(\"When adding Convulational Layer, kernel_size must be provided\")\n","        \n","        if \"stride\" in param_keys:\n","            stride = parameters[\"stride\"]\n","        else:\n","            stride = 2\n","            \n","        if \"padding\" in param_keys:\n","            padding = parameters[\"padding\"]\n","        else:\n","            padding = 0\n","        \n","        \n","        if(len(self.pre_layer_output)) != 3:\n","            raise ValueError(f\"The input shape to the Max Pooling Layer is not correct. {self.pre_layer_output}\")\n","         \n","        in_channels, in_height, in_width =  self.pre_layer_output\n","        \n","        out_height = (in_height + 2*padding - kernel_size)/ stride + 1\n","        out_width = (in_width + 2*padding - kernel_size)/ stride + 1\n","        out_channels = in_channels\n","       \n","        if out_width %1 !=0 or out_height %1 !=0 :\n","            raise ValueError(f\"Combination of pad, stride and kernel size lead to decimal number in conv layer. {out_height}\")\n","\n","\n","        self.pre_layer_output = (out_channels, int(out_height), int(out_width))\n","        \n","        max_pool_layer = (f'{self.layer}', nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding))\n","        \n","        return max_pool_layer"]},{"cell_type":"code","execution_count":12,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.918200Z","iopub.status.busy":"2023-01-17T07:00:58.917595Z","iopub.status.idle":"2023-01-17T07:00:58.932032Z","shell.execute_reply":"2023-01-17T07:00:58.931032Z","shell.execute_reply.started":"2023-01-17T07:00:58.918162Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# order is important\n","#layers = OrderedDict()\n","\n","#layers[\"flatten1\"] = {}\n","#layers[\"flatten1\"][\"name\"] = \"flatten\"\n","\n","# layer 1\n","#layers[\"linear1\"] = {}\n","#layers[\"linear1\"][\"name\"] = \"linear\"\n","#layers[\"linear1\"][\"neurons\"] = 10\n","\n","# layer 2\n","#layers[\"relu1\"] = {}\n","#layers[\"relu1\"][\"name\"] = \"relu\"\n","\n","# layer 3\n","#layers[\"linear2\"] = {}\n","#layers[\"linear2\"][\"name\"] = \"linear\"\n","#layers[\"linear2\"][\"neurons\"] = 8\n","#layers[\"linear2\"][\"bias\"] = False\n","\n","# layer 4\n","#layers[\"lrelu2\"] = {}\n","#layers[\"lrelu2\"][\"name\"] = \"lrelu\"\n","#layers[\"lrelu2\"][\"alpha\"] = 1\n","\n","# layer 5\n","#layers[\"linear3\"] = {}\n","#layers[\"linear3\"][\"name\"] = \"linear\"\n","#layers[\"linear3\"][\"neurons\"] = 2\n","\n","# layer 6\n","#layers[\"relu3\"] = {}\n","#layers[\"relu3\"][\"name\"] = \"relu\"\n","\n","\n","\n","#model = Model((5,5), layers )\n","\n","#print(model)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Setup loss function\n","* Binary entropy loss \n","* cross entropy loss\n","* weighted loss function\n","* maybe something from literature"]},{"cell_type":"code","execution_count":13,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.935760Z","iopub.status.busy":"2023-01-17T07:00:58.935498Z","iopub.status.idle":"2023-01-17T07:00:58.948692Z","shell.execute_reply":"2023-01-17T07:00:58.947664Z","shell.execute_reply.started":"2023-01-17T07:00:58.935737Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def setup_loss(parameters):\n","    \"\"\"\n","    Returns loss function\n","    \n","    Parameters:\n","        parameters: dict with the following keys:\n","            \"type\": \"binary\" or \"cross_entropy\"\n","            \"use_weighted_loss\": default = False\n","            \"class_weights\": weights for each class (list)\n","        \n","        Note: currently the loss function is basically Softmax + Log Loss.\n","        loss_type == \"binary\" assumes that output layer has single neuron\n","        When loss_type == \"binary\", class weights must be equal to [num_of_neg_samples/num_of_pos_samples]\n","        else: class_weights can be list containing any value but length of class_weights must be equal to number of classes\n","        \n","    \"\"\"\n","    \n","    loss_keys = parameters.keys()\n","    \n","    if \"type\" in loss_keys:\n","        loss_type = parameters[\"type\"]\n","    else:\n","        raise ValueError (\"'loss_type' must be provided\")\n","         \n","    if \"use_weighted_loss\" in loss_keys:\n","        use_weighted_loss = parameters[\"use_weighted_loss\"]\n","    else:\n","        use_weighted_loss = False\n","    \n","    if \"class_weights\" in loss_keys:\n","        class_weights = parameters[\"class_weights\"]\n","    else:\n","        class_weights = []\n","        \n","    if use_weighted_loss and not class_weights:\n","        raise ValueError(\"When using weighted loss, class weights must be provided\")\n","        \n","    class_weights = torch.tensor(class_weights).cuda()\n","    \n","    print(\"Loss type \", loss_type)\n","    print(\"weights \", class_weights)\n","    print(\"usl \", use_weighted_loss)\n","    \n","    if loss_type == \"binary\":\n","        \n","        if use_weighted_loss:\n","            print(\"using Weighted Loss\")\n","            loss_fnt = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n","        else:\n","            print(\"BE: without weights\")\n","            loss_fnt = nn.BCEWithLogitsLoss()\n","    \n","    elif loss_type == \"cross_entropy\":\n","         \n","        if use_weighted_loss:\n","            print(\"CE: using Weighted Loss\")\n","            loss_fnt= nn.CrossEntropyLoss(weight=class_weights)\n","        else:\n","            print(\"CE: without weights\")\n","            loss_fnt= nn.CrossEntropyLoss()\n","            \n","    else:\n","        raise ValueError(\"Unknown Value for loss_type\")\n","    \n","    return loss_fnt\n","    "]},{"cell_type":"code","execution_count":14,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.955920Z","iopub.status.busy":"2023-01-17T07:00:58.955575Z","iopub.status.idle":"2023-01-17T07:00:58.965981Z","shell.execute_reply":"2023-01-17T07:00:58.965002Z","shell.execute_reply.started":"2023-01-17T07:00:58.955893Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#loss_param = {}\n","#loss_param[\"type\"] = \"cross_entropy\"\n","#loss_param[\"use_weighted_loss\"] = True\n","#loss_param[\"class_weights\"] = [8, 6]\n","\n","#loss_fnt = setup_loss(loss_param)\n","#print(loss_fnt)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Setup Optimizer\n","* adam\n","* SGD with momenteum\n","* something from literature\n","* regularization\n","* learning rate change with time (if required) \n","* betas"]},{"cell_type":"code","execution_count":15,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.968497Z","iopub.status.busy":"2023-01-17T07:00:58.967747Z","iopub.status.idle":"2023-01-17T07:00:58.978921Z","shell.execute_reply":"2023-01-17T07:00:58.978044Z","shell.execute_reply.started":"2023-01-17T07:00:58.968461Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def setup_optimizer(model_parameters, optim_parameters):\n","    \"\"\"\n","    Setups Optimizer\n","    \n","    Parameters:\n","        model_parameters: parameters of models that will be trained\n","        \n","        optim_parameters: dict with the following structure:\n","            optim_parameters[\"name\"] = name of optimizer (adam or sgd)\n","            optim_parameters[\"parameter1\"] = value\n","            optim_parameters[\"parameter2\"] = value\n","            \n","        for Adam optimizer, it supports following keys:\n","            \"betas\": default = (0.9,0.999)\n","            \n","        for SGD, it supports following keys.\n","            \"momentum\":  (default = 0)\n","            \"dampening\": (default=0)\n","        \n","        following keys are supported for both optimizers:\n","            \"lr\": learning rate (default = 1e-3)\n","            \"lmbda\": regularization (default = 0)     \n","            \n","    \"\"\"\n","    \n","    optim_keys=optim_parameters.keys()\n","    \n","    if \"name\" in optim_keys:\n","        optim = optim_parameters[\"name\"]\n","    else:\n","        raise ValueError(\"'name' of the optimizer must be provided\")\n","    \n","    if \"lmbda\" in optim_keys:\n","        lmbda = optim_parameters[\"lmbda\"]\n","    else:\n","        lmbda = 0\n","    \n","    if \"lr\" in optim_keys:\n","        lr = optim_parameters[\"lr\"]\n","    else: \n","        lr = 1e-3\n","    \n","    if optim == \"adam\":\n","        \n","        if \"betas\" in optim_keys:\n","            betas = optim_parameters[\"betas\"]\n","        else:\n","            betas = (0.9,0.999)\n","        \n","        optimizer = torch.optim.Adam(model_parameters,  lr=lr, betas=betas, amsgrad=True, weight_decay=lmbda)\n","    \n","    elif optim == \"sgd\":\n","        \n","        if \"momentum\" in optim_keys:\n","            momentum = optim_parameters[\"momentum\"]\n","        else:\n","            momentum = 0\n","        \n","        if \"dampening\" in optim_keys:\n","            dampening = optim_parameters[\"dampening\"]\n","        else:\n","            dampening = 0\n","        \n","        optimizer = torch.optim.SGD(model_parameters, momentum=momentum, dampening=dampening, weight_decay=lmbda)\n","    else:\n","        raise ValueError(\"Unknown name of the optimizer provided\")\n","    \n","    return optimizer"]},{"cell_type":"code","execution_count":16,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.981255Z","iopub.status.busy":"2023-01-17T07:00:58.980441Z","iopub.status.idle":"2023-01-17T07:00:58.996363Z","shell.execute_reply":"2023-01-17T07:00:58.995386Z","shell.execute_reply.started":"2023-01-17T07:00:58.981199Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#optim_parameters = {}\n","#optim_parameters[\"name\"] = \"adam\"\n","#optimizer = setup_optimizer (model.parameters(), optim_parameters)\n","#print(optimizer)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Metrics"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Accuracy "]},{"cell_type":"code","execution_count":17,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:58.997618Z","iopub.status.busy":"2023-01-17T07:00:58.997378Z","iopub.status.idle":"2023-01-17T07:00:59.010077Z","shell.execute_reply":"2023-01-17T07:00:59.009128Z","shell.execute_reply.started":"2023-01-17T07:00:58.997595Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def accuracy(y_true, y_pred, parameters):\n","    \"\"\"\n","    Calculates accuracy\n","    \n","    Parameters:\n","        y_true: numpy array of shape (num_images,)\n","        y_pred: numpy array of shape (num_images,)\n","        parameters: dictionary with the following keys:\n","            type: \"simple\" (default) or \"balanced\"\n","    \n","    Returns:\n","        score: float\n","        config:\n","\n","    Additional Notes:\n","\n","        Simple Accuracy: fraction of labels that are equal.\n","        Balanced Accuracy: \n","            Binary class: equal to the arithmetic mean of sensitivity (true positive rate) \n","                            and specificity (true negative rate)\n","                             = 1/2 ( (TP/TP+FN) + (TN/TN+FP))\n","\n","            Multiclass: the macro-average of recall scores per class\n","                        recall for each class and then take the mean\n","                        recall = TP /(TP+FN)\n","\n","            if the classifier predicts same label for all examples, the score will be equal to 1/num_classes (for binary: 0.5)\n","            for more info, see\n","                \"https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\"\n","    \"\"\"\n","\n","    config={}\n","    if \"type\" in parameters.keys():\n","        accu_type = parameters[\"type\"]\n","    else:\n","        accu_type = \"simple\"\n","\n","    config[\"type\"] = accu_type\n","    \n","    if accu_type == \"simple\":\n","        score = accuracy_score(y_true=y_true, y_pred=y_pred) \n","    elif accu_type == \"balanced\":\n","        score = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n","    else:\n","        raise ValueError(\"Unknown Value encountered for parameter 'type' while calculating accuracy\")#\n","\n","    \n","    return score, config"]},{"cell_type":"code","execution_count":18,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.012211Z","iopub.status.busy":"2023-01-17T07:00:59.011335Z","iopub.status.idle":"2023-01-17T07:00:59.025599Z","shell.execute_reply":"2023-01-17T07:00:59.024586Z","shell.execute_reply.started":"2023-01-17T07:00:59.012176Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#y_true = np.array([0, 2, 1, 3])\n","#y_predict = np.array([0, 1, 2, 3])\n","#print(\"simple: \", accuracy(y_true, y_predict, {}))\n","#y_true = np.array([0, 1, 0, 0, 1, 0])\n","#y_predict = np.array([0, 1, 0, 0, 0, 1])\n","#print(\"balanced: \", accuracy(y_true, y_predict, {\"type\": \"balanced\"}))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## MCC "]},{"cell_type":"code","execution_count":19,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.028051Z","iopub.status.busy":"2023-01-17T07:00:59.026971Z","iopub.status.idle":"2023-01-17T07:00:59.036945Z","shell.execute_reply":"2023-01-17T07:00:59.035866Z","shell.execute_reply.started":"2023-01-17T07:00:59.028016Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def mcc(y_true, y_pred, parameters):\n","    \"\"\"\n","    Calculates mcc\n","    \n","    Parameters:\n","        y_true: numpy array of shape (num_images,)\n","        y_pred: numpy array of shape (num_images,)\n","        parameters: dictionary with the following keys:\n","            \n","    Returns:\n","        score: float\n","        config:\n","\n","    Additional Notes:\n","        Binary:\n","        \n","            +1 -> prefect, 0-> random, -1 -> inverse \n","\n","            mcc = (tp*tn) - (fp*fn) / sqrt( (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)  )\n","\n","        Multiclass:\n","            \n","            +1 -> perfect, between -1 and 0 -> min\n","\n","            for more info, see\n","                \"https://scikit-learn.org/stable/modules/model_evaluation.html#matthews-corrcoef\"\n","    \"\"\"\n","\n","    config = {}\n","\n","    score = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n","\n","    return score, config"]},{"cell_type":"code","execution_count":20,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.039074Z","iopub.status.busy":"2023-01-17T07:00:59.038183Z","iopub.status.idle":"2023-01-17T07:00:59.052560Z","shell.execute_reply":"2023-01-17T07:00:59.051678Z","shell.execute_reply.started":"2023-01-17T07:00:59.039040Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#y_true = np.array([+1, +1, +1, -1])\n","#y_predict = np.array([+1, -1, +1, +1])\n","#print(\"mcc: \", mcc(y_true, y_predict, {}))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Sensitivity "]},{"cell_type":"code","execution_count":21,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.055095Z","iopub.status.busy":"2023-01-17T07:00:59.054031Z","iopub.status.idle":"2023-01-17T07:00:59.065042Z","shell.execute_reply":"2023-01-17T07:00:59.064121Z","shell.execute_reply.started":"2023-01-17T07:00:59.055061Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def sensitivity(y_true, y_pred, parameters):\n","    \"\"\"\n","    Calculates sensitivity (recall)\n","    \n","    Parameters:\n","        y_true: numpy array of shape (num_images,)\n","        y_pred: numpy array of shape (num_images,)\n","        parameters: dictionary with the following keys:\n","            class_result: for binary classes, name of class for which metric will be calculated\n","            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n","    \n","    Returns:\n","        score: float\n","        config:\n","\n","    Additional Notes:\n","        recall = TP/ TP+FN\n","\n","        average:\n","            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n","            'macro': Calculate metrics for each label, and find their unweighted mean\n","            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n","\n","    \"\"\"\n","\n","    config = {}\n","\n","    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n","\n","        if \"class_result\" in parameters.keys():\n","            pos_label = parameters[\"class_result\"]\n","        else:\n","           ytl = np.unique(y_true)\n","           ypl = np.unique(y_pred)\n","           labels = np.unique(np.concatenate((ytl, ypl))) \n","           pos_label = labels[0]\n","        \n","        config[\"class_result\"] = pos_label\n","\n","        score = recall_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n","    \n","    else:\n","        \n","        if \"average\" in parameters.keys():\n","            average = parameters[\"average\"]\n","        else:\n","            average = \"weighted\"\n","\n","        config[\"average\"] = average\n","\n","        score = recall_score(y_true=y_true, y_pred=y_pred, average=average)\n","\n","    return score, config"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Precision "]},{"cell_type":"code","execution_count":22,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.067372Z","iopub.status.busy":"2023-01-17T07:00:59.066393Z","iopub.status.idle":"2023-01-17T07:00:59.080285Z","shell.execute_reply":"2023-01-17T07:00:59.079393Z","shell.execute_reply.started":"2023-01-17T07:00:59.067335Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def precision(y_true, y_pred, parameters):\n","    \"\"\"\n","    Calculates precision\n","    \n","    Parameters:\n","        y_true: numpy array of shape (num_images,)\n","        y_pred: numpy array of shape (num_images,)\n","        parameters: dictionary with the following keys:\n","            class_result: for binary classes, name of class for which metric will be calculated\n","            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n","    \n","    Returns:\n","        score: float\n","        config:\n","\n","    Additional Notes:\n","        precision = TP/ TP+FP\n","\n","        average:\n","            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n","            'macro': Calculate metrics for each label, and find their unweighted mean\n","            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n","\n","    \"\"\"\n","    config = {}\n","\n","    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n","\n","        if \"class_result\" in parameters.keys():\n","            pos_label = parameters[\"class_result\"]\n","        else:\n","           ytl = np.unique(y_true)\n","           ypl = np.unique(y_pred)\n","           labels = np.unique(np.concatenate((ytl, ypl))) \n","           pos_label = labels[0]\n","        \n","        config[\"class_result\"] = pos_label\n","\n","        score = precision_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n","    \n","    else:\n","        \n","        if \"average\" in parameters.keys():\n","            average = parameters[\"average\"]\n","        else:\n","            average = \"weighted\"\n","\n","        config[\"average\"] = average\n","\n","        score = precision_score(y_true=y_true, y_pred=y_pred, average=average)\n","\n","    return score, config"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## F1 Score"]},{"cell_type":"code","execution_count":23,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.082340Z","iopub.status.busy":"2023-01-17T07:00:59.081557Z","iopub.status.idle":"2023-01-17T07:00:59.096226Z","shell.execute_reply":"2023-01-17T07:00:59.095029Z","shell.execute_reply.started":"2023-01-17T07:00:59.082306Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def F1_score(y_true, y_pred, parameters):\n","    \"\"\"\n","    Calculates f1 score\n","    \n","    Parameters:\n","        y_true: numpy array of shape (num_images,)\n","        y_pred: numpy array of shape (num_images,)\n","        parameters: dictionary with the following keys:\n","            class_result: for binary classes, name of class for which metric will be calculated\n","            average: for mulitlcass, how to calculate metrics for each class: 'micro', 'macro', 'weighted' \n","    \n","    Returns:\n","        score: float\n","        config:\n","\n","    Additional Notes:\n","        f1_score = 2 * (Precision * Recall)/ (Precision + Recall)\n","\n","        average:\n","            'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives\n","            'macro': Calculate metrics for each label, and find their unweighted mean\n","            'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label)\n","\n","    \"\"\"\n","\n","    config = {}\n","\n","    if len(np.unique(y_true)) <= 2 and len(np.unique(y_pred)) <= 2:\n","\n","        if \"class_result\" in parameters.keys():\n","            pos_label = parameters[\"class_result\"]\n","        else:\n","           ytl = np.unique(y_true)\n","           ypl = np.unique(y_pred)\n","           labels = np.unique(np.concatenate((ytl, ypl))) \n","           pos_label = labels[0]\n","        \n","        config[\"class_result\"] = pos_label\n","\n","        score = f1_score(y_true=y_true, y_pred=y_pred, pos_label=pos_label)\n","    \n","    else:\n","        \n","        if \"average\" in parameters.keys():\n","            average = parameters[\"average\"]\n","        else:\n","            average = \"weighted\"\n","\n","        config[\"average\"] = average\n","\n","        score = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n","\n","    return score, config\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Evaluate Metrics "]},{"cell_type":"code","execution_count":24,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.098161Z","iopub.status.busy":"2023-01-17T07:00:59.097598Z","iopub.status.idle":"2023-01-17T07:00:59.112518Z","shell.execute_reply":"2023-01-17T07:00:59.111605Z","shell.execute_reply.started":"2023-01-17T07:00:59.098127Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def evaluate_metrics(y_true, y_pred, metrics, y_pred_probs=None):\n","    \"\"\"\n","    Applies each metric and generates evaluation score\n","\n","    Parameters:\n","        y_true: numpy array of shape (folds, num_images, 2)\n","        y_pred: numpy array of shape (folds, num_images, 2)\n","        metrics: dictionary with following structure:\n","            metrics[\"metrics_1\"][\"name\"] = name of metric\n","            metrics[\"metrics_1\"][\"parameter_1\"] = value\n","            metrics[\"metrics_1\"][\"parameter_2\"] = value\n","\n","            metrics[\"metrics_2\"][\"name\"] = name of metric\n","            metrics[\"metrics_2\"][\"parameter_1\"] = value\n","            metrics[\"metrics_2\"][\"parameter_2\"] = value\n","            \n","    \n","    currently, supports \"accuracy\", \"mcc\", \"precision\", \"sensitivity\", \"F1_score\"\n","  \n","\n","    Returns:\n","        scores:numpy array of shape (folds, metrics)\n","        output_config:\n","       \n","    Additional Notes:\n","\n","    \"\"\"\n","    # check whether correct shapes of y_* are provided or not\n","\n","    if len(y_true.shape) !=3:\n","        raise ValueError(\"Shape of y_true is not correct.\")\n","\n","    if len(y_pred.shape) == 3:\n","        num_folds = y_pred.shape[0]\n","        met_keys = list(metrics.keys())\n","        num_metrics = len(met_keys)\n","    else:\n","        raise ValueError(\"Shape of y_pred is not correct.\")\n","\n","    config={}\n","\n","    list_of_metrics = []\n","\n","    scores = np.full((num_folds, num_metrics), 1000, dtype=np.float32)\n","    \n","    flag = True\n","\n","\n","    for fold_no in range(num_folds):\n","\n","        for metric_no in range(num_metrics):\n","\n","            print(f\"Processing: Fold No: {fold_no} Metric: {met_keys[metric_no]}\")\n","\n","            metric_name = metrics[met_keys[metric_no]][\"name\"]\n","            \n","            if metric_name == \"accuracy\":\n","                fnt_pointer = accuracy\n","            elif metric_name == \"mcc\":\n","                fnt_pointer = mcc\n","            elif metric_name == \"precision\":\n","                fnt_pointer = precision\n","            elif metric_name ==\"sensitivity\":\n","                fnt_pointer = sensitivity\n","            elif metric_name ==\"F1_score\":\n","                fnt_pointer = F1_score\n","            else:\n","                raise ValueError(\"Unknown metric found\")\n","\n","            \n","            metric_score, fnt_config = fnt_pointer(y_true=y_true[fold_no, :, 1], \n","                                                    y_pred=y_pred[fold_no, :, 1], \n","                                                    parameters=metrics[met_keys[metric_no]])\n","\n","\n","            scores[fold_no, metric_no] = metric_score\n","\n","            # setup output config\n","            if flag:\n","                fnt_config[\"name\"] = metric_name\n","                config[met_keys[metric_no]] = {} \n","                config[met_keys[metric_no]] = fnt_config\n","\n","                list_of_metrics.append(met_keys[metric_no])\n","\n","        flag=False\n","    \n","    return scores, config, list_of_metrics\n"]},{"cell_type":"code","execution_count":25,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.114685Z","iopub.status.busy":"2023-01-17T07:00:59.113780Z","iopub.status.idle":"2023-01-17T07:00:59.128031Z","shell.execute_reply":"2023-01-17T07:00:59.126982Z","shell.execute_reply.started":"2023-01-17T07:00:59.114645Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# multi\n","#y_true = np.array([\"aa\", \"a\", \"ab\", \"b\", \"ac\", \"c\",\n","#                    \"ad\", \"a\", \"ae\", \"c\", \"af\", \"a\",\n","#                    \"ag\", \"c\", \"ah\", \"b\", \"ai\", \"a\"]).reshape(3,3, 2)\n","#y_pred = np.array([\"aa\", \"b\", \"ab\", \"b\", \"ac\", \"b\",\n","#                    \"ad\", \"a\", \"ae\", \"c\", \"af\", \"a\",\n","#                    \"ag\", \"a\", \"ah\", \"b\", \"ai\", \"c\",]).reshape(3,3,2)\n","\n","\n","\n","\n","#metrics = {}\n","\n","#metrics[\"simple_accuracy\"] = {}\n","#metrics[\"simple_accuracy\"][\"name\"] = \"accuracy\"\n","#metrics[\"simple_accuracy\"][\"type\"] = \"simple\"  \n","\n","#metrics[\"balanced_accuracy\"] = {}\n","#metrics[\"balanced_accuracy\"][\"name\"] = \"accuracy\"\n","#metrics[\"balanced_accuracy\"][\"type\"] = \"balanced\"\n","\n","\n","# precision\n","#metrics[\"precision\"] = {}\n","#metrics[\"precision\"][\"name\"] = \"precision\" \n","#metrics[\"precision\"][\"class_result\"] = \"a\"\n","#metrics[\"precision\"][\"average\"] = \"weighted\"\n","\n","\n","# recall\n","#metrics[\"sensitivity\"] = {}\n","#metrics[\"sensitivity\"][\"name\"] = \"sensitivity\"\n","#metrics[\"sensitivity\"][\"class_result\"]  = \"a\"\n","#metrics[\"sensitivity\"][\"average\"]  = \"weighted\"\n","\n","# f1_score\n","#metrics[\"f1_score\"] = {}\n","#metrics[\"f1_score\"][\"name\"] = \"F1_score\" \n","#metrics[\"f1_score\"][\"class_result\"] = \"a\"\n","#metrics[\"f1_score\"][\"average\"] = \"weighted\"\n","\n","# mcc\n","#metrics[\"mcc\"] = {}\n","#metrics[\"mcc\"][\"name\"] = \"mcc\" \n","\n","\n","#print(\"true labels\")\n","#print(y_true)\n","#print(y_true.shape)\n","\n","#print(\"pred labels\")\n","#print(y_pred)\n","#print(y_pred.shape)\n","\n","#scores, config, list_of_metrics =evaluate_metrics(y_true=y_true, y_pred=y_pred, metrics =metrics)\n","\n","#print(\"scores \")\n","#print(scores)\n","\n","#print(\"config \")\n","#print(config)\n","\n","#print(\"metrics list \")\n","#print(list_of_metrics)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Plots"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Learning Curves "]},{"cell_type":"code","execution_count":26,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.132231Z","iopub.status.busy":"2023-01-17T07:00:59.131382Z","iopub.status.idle":"2023-01-17T07:00:59.143975Z","shell.execute_reply":"2023-01-17T07:00:59.143199Z","shell.execute_reply.started":"2023-01-17T07:00:59.132205Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def plot_LC(metric_score, path_to_results, path_to_images):\n","\n","    \"\"\"\n","    Plots and saves learning curves\n","    \n","    metric_score: numpy array of shape (metrics, 2, epochs)\n","    path_to_results: path where plot will be saved\n","    \n","    \"\"\"\n","    num_metrics = metric_score.shape[0]\n","    metrics = [\"CELoss\", \"Bal_Accu\", \"MCC\"]\n","    \n","    fig, axes = plt.subplots(num_metrics, 1)\n","    \n","    fig.suptitle(\"Learning Curves\")\n","\n","    for met in range(num_metrics):\n","\n","        # plot training curve\n","        train_line, = axes[met].plot(metric_score[met][0], color='blue', label='Training')\n","\n","        # plot validation curve\n","        valid_line, = axes[met].plot(metric_score[met][1], color= 'orangered', label='Validation')\n","\n","        # setup x-axis\n","        if met != num_metrics -1 :\n","            axes[met].set_xticks([])\n","        else:\n","            axes[met].set_xlabel(\"Epochs\")\n","\n","        # setup y-axis\n","        axes[met].set_ylabel(metrics[met])\n","\n","    fig.legend(handles= [train_line, valid_line])\n","\n","    plt.savefig(path_to_results + \"_LC\")\n","    plt.close()"]},{"cell_type":"code","execution_count":27,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.145744Z","iopub.status.busy":"2023-01-17T07:00:59.145224Z","iopub.status.idle":"2023-01-17T07:00:59.157814Z","shell.execute_reply":"2023-01-17T07:00:59.156971Z","shell.execute_reply.started":"2023-01-17T07:00:59.145711Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#x= np.random.rand(3, 2, 10)\n","#x[0,0] = np.arange(1, 11)\n","#x[1, 1] = np.arange(11,21)\n","\n","#print(x)\n","#path_to_results = \"/\"\n","\n","#plot_LC(\n","#    x, path_to_results, x)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Misidentified Samples "]},{"cell_type":"code","execution_count":28,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.159941Z","iopub.status.busy":"2023-01-17T07:00:59.159321Z","iopub.status.idle":"2023-01-17T07:00:59.183546Z","shell.execute_reply":"2023-01-17T07:00:59.182611Z","shell.execute_reply.started":"2023-01-17T07:00:59.159906Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def plot_MS(y_true, y_pred, path_to_results, path_to_images):\n","    \"\"\"\n","    Plots and save missclassified samples\n","    \n","    y_true: numpy array of shape (num_of_images,2)\n","    y_pred: numpy array of shape (num_of_images,2)\n","    path_to_results: path where plot will be saved\n","    path_to_images: folder containing images\n","\n","\n","    Only works with (num_samples)^2 = whole number\n","\n","    \"\"\"\n","    num_samples_to_plot = 4\n","\n","    classes = np.unique(y_true[:,1])\n","\n","    if np.sqrt(num_samples_to_plot) %1 !=0:\n","        raise ValueError(\"Currently, this function only supports those number of samples whose sqaure is a whole number\")\n","\n","    \n","    \n","    cm = create_dict(classes)\n","\n","    for true_label in classes:\n","        \n","        # get all images for a class in y_true\n","        pos = y_true[np.where(y_true[:,1] == true_label)]\n","        \n","        pred_classes = classes.tolist()\n","      \n","        for sample in pos:\n","            \n","            # find given image in y_pred\n","            img_id = y_pred[np.where(y_pred[:,0] == sample[0])]\n","            \n","            # store img_ids in their respective col\n","            for pred_label in pred_classes:\n","                if img_id[0,1] == pred_label:\n","                    cm[true_label][pred_label].append(img_id[0,0])\n","\n","            # check whether there are requried number of samples in each col\n","            for l in cm[true_label].keys():\n","                \n","                if l in pred_classes and len(cm[true_label][l]) == num_samples_to_plot:\n","                    pred_classes.remove(l)\n","                \n","            if not len(pred_classes):\n","                break\n","    \n","    plot_CM_images(cm, num_samples_to_plot, path_to_images, path_to_results)\n","\n","\n","\n","def plot_CM_images(cm, num_samples, path_to_images, path_to_results):\n","    \"\"\"\n","    Plots and saves images\n","    \n","    \"\"\"\n","    num_classes = len(cm.keys())\n","    \n","    num_imgs_axis = int(np.sqrt(num_samples)) \n","    \n","    num_rows= num_imgs_axis * num_classes\n","    num_cols = num_imgs_axis * num_classes\n","\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10,10))\n","    \n","    fig.suptitle(\"Confusion Matrix of misclassified images\")\n","    plt.subplots_adjust(wspace=0, hspace=0)\n","\n","    fig.text(0.5, 0.04, 'Predicted Labels', ha='center', va='center')\n","    fig.text(0.06, 0.5, 'True Labels', ha='center', va='center', rotation='vertical')\n","\n","    for i, true_label in enumerate(cm.keys()):\n","        \n","        pred_labels = cm[true_label]\n","        \n","        if i==0:\n","            row_i = i\n","        \n","\n","        for j, pred_label in enumerate(pred_labels.keys()):\n","\n","            img_ids = pred_labels[pred_label]\n","\n","            empty_img_ids = num_samples - len(img_ids)\n","\n","            if j==0:\n","                col_j = j\n","            \n","            row = 0\n","            col = 0\n","\n","            for id in img_ids:\n","\n","                img = mpimg.imread(os.path.join(path_to_images, id))\n","                img_shape = img.shape\n","                \n","                axes[row_i+row, col_j+col].imshow(img, cmap='gray', vmin=0, vmax=255, aspect='auto')\n","                axes[row_i+row, col_j+col].set_xticks([])\n","                axes[row_i+row, col_j+col].set_yticks([])\n","\n","                if row_i + row == num_rows-1:\n","                    axes[row_i+row, col_j+col].set_xlabel(pred_label)\n","\n","            \n","                if col_j + col == 0:\n","                    axes[row_i+row, col_j+col].set_ylabel(true_label)\n","\n","\n","\n","\n","                if col ==num_imgs_axis-1:\n","                    col =0\n","                    row +=1\n","                else:\n","                    col +=1\n","\n","            if len(img_ids) ==0:\n","                img_shape = (299,299)        \n","            \n","            if empty_img_ids > 0:\n","                temp = np.full(img_shape, 255)\n","\n","                for _ in range(empty_img_ids):\n","                    \n","                    axes[row_i+row, col_j+col].imshow(temp, cmap='gray', vmin=0, vmax=255, aspect='auto')\n","                    axes[row_i+row, col_j+col].set_xticks([])\n","                    axes[row_i+row, col_j+col].set_yticks([])\n","\n","                    if row_i + row == num_rows-1:\n","                        axes[row_i+row, col_j+col].set_xlabel(pred_label)\n","\n","                \n","                    if col_j + col == 0:\n","                        axes[row_i+row, col_j+col].set_ylabel(true_label)\n","                        \n","                    \n","                    if col ==num_imgs_axis-1:\n","                        col =0\n","                        row+=1\n","                    else:\n","                        col +=1\n","                   \n","            if empty_img_ids<0:\n","                raise ValueError(\"There are more image ids in the dict than number of samples to be plotted\")\n","            \n","            col_j = col_j + num_imgs_axis\n","        \n","        row_i += num_imgs_axis\n","    \n","    plt.savefig(path_to_results + \"_MS\")\n","    plt.close()\n","\n","    \n","def create_dict(classes):\n","    \"\"\"\n","    Setups a dictionary for storing image ids in confusion matrix\n","    \n","    \"\"\"\n","\n","    output_dict = dict()\n","    for i in classes:\n","        output_dict[i] = {}\n","        for j in classes:\n","            output_dict[i][j]= []\n","\n","    return output_dict      "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"jupyter":{"source_hidden":true}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Confusion Matrix"]},{"cell_type":"code","execution_count":29,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.186611Z","iopub.status.busy":"2023-01-17T07:00:59.186305Z","iopub.status.idle":"2023-01-17T07:00:59.199891Z","shell.execute_reply":"2023-01-17T07:00:59.198976Z","shell.execute_reply.started":"2023-01-17T07:00:59.186586Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def plot_CM(y_true, y_pred, path_to_results, path_to_images):\n","    \"\"\"\n","    Plots and save Confusion Matrix\n","    \n","    y_true: numpy array of shape (num_of_images,2)\n","    y_pred: numpy array of shape (num_of_images,2)\n","    path_to_results: path where plot will be saved\n","\n","    \"\"\"\n","\n","    ConfusionMatrixDisplay.from_predictions(y_pred=y_pred[:,1], y_true =y_true[:,1])\n","\n","    plt.savefig(path_to_results + \"_CM\")\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Create Plots "]},{"cell_type":"code","execution_count":30,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.202003Z","iopub.status.busy":"2023-01-17T07:00:59.201465Z","iopub.status.idle":"2023-01-17T07:00:59.215423Z","shell.execute_reply":"2023-01-17T07:00:59.214508Z","shell.execute_reply.started":"2023-01-17T07:00:59.201965Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_plots(y_true, y_pred, path_to_results, path_to_images, plots, name_of_file, training_metric_scores=None, y_pred_probs = None):\n","    \"\"\"\n","    Generates differenet plots\n","    Parameters:\n","        y_true: numpy array of shape (folds, num_images, 2)\n","        y_pred: numoy array of shape (folds, num_images, 2)\n","        path_to_results: path to the folder where the results will be stored\n","        plots: dictionary with following structure:\n","                plots[\"plots_1\"][\"name\"] = name of plot\n","                plots[\"plots_1\"][\"parameter_1\"] = value\n","                plots[\"plots_1\"][\"parameter_2\"] = value\n","\n","                plots[\"plots_2\"][\"name\"] = name of plot\n","                plots[\"plots_2\"][\"parameter_1\"] = value\n","                plots[\"plots_2\"][\"parameter_2\"] = value\n","        \n","        name_of_file:\n","        training_metric_scores: (default=None) list of numpy array with each having shape of (folds, metrics, 2, epochs).Each item in list should represent results of a network.\n","\n","    Returns:\n","        output_config:\n","\n","    Additional Notes:\n","    currently supports CM, LC and MS\n","\n","\n","    \"\"\"\n","\n","    # check whether correct shapes of y_* are provided or not\n","\n","    if len(y_true.shape) !=3:\n","        raise ValueError(\"Shape of y_true is not correct.\")\n","\n","    if len(y_pred.shape) == 3:\n","        num_folds = y_pred.shape[0]\n","    else:\n","        raise ValueError(\"Shape of y_pred is not correct.\")\n","\n","    # determine whether to plot learning curves or not\n","    if training_metric_scores is not None:\n","        lc = True\n","    else:\n","        lc = False\n","   \n","\n","\n","    for fold_no in range(num_folds):\n","\n","        # create directory for fold\n","        path_to_fold = os.path.join(path_to_results, str(fold_no))\n","        if not os.path.exists(path_to_fold):\n","            os.mkdir(path_to_fold)\n","\n","        # create directory for plots\n","        path_to_plots = os.path.join(path_to_fold, \"plots\")\n","        if not os.path.exists(path_to_plots):\n","            os.mkdir(path_to_plots)\n","\n","        for pl in plots:\n","\n","            # if dict has key \"learning_curves\" but no metric score is provided,\n","            if pl == \"LC\" and not lc:\n","                print(\"Warning: key'learning_curves' provided in dict 'plots' but metric score not found. Skipping ploting learning curves\" )\n","                continue \n","\n","\n","            print(f\"Creating Plot: {pl} Fold No: {fold_no}\")\n","            \n","            plot_name = pl\n","            if plot_name == \"CM\":\n","                fnt_pointer = plot_CM\n","            elif plot_name == \"MS\":\n","                fnt_pointer = plot_MS\n","            elif plot_name == \"LC\":\n","                fnt_pointer = plot_LC\n","            else:\n","                raise ValueError(\"Unknown plot found\")\n","                \n","            path_to_figs = path_to_plots+f\"/{name_of_file}\"\n","\n","            if plot_name == \"LC\":\n","                fnt_pointer(metric_score= training_metric_scores[fold_no], path_to_results=path_to_figs, path_to_images=path_to_images)\n","            else:\n","                fnt_pointer(y_true=y_true[fold_no], y_pred=y_pred[fold_no], path_to_results=path_to_figs, path_to_images=path_to_images)\n","\n","\n","    return plots"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Misc"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Load from json "]},{"cell_type":"code","execution_count":31,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.219082Z","iopub.status.busy":"2023-01-17T07:00:59.218402Z","iopub.status.idle":"2023-01-17T07:00:59.231022Z","shell.execute_reply":"2023-01-17T07:00:59.229984Z","shell.execute_reply.started":"2023-01-17T07:00:59.219000Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def load_from_json(path_to_json):\n","    \"\"\"\n","    Load a json file\n","\n","    Parameters:\n","        path_to_json: path to json file\n","    \n","    Returns:\n","        dictionary with contents of the json\n","    \"\"\"\n","    with open(path_to_json, 'r') as f:\n","        dic = json.load(f)\n","    \n","    return dic"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Save to json "]},{"cell_type":"code","execution_count":32,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.232792Z","iopub.status.busy":"2023-01-17T07:00:59.232441Z","iopub.status.idle":"2023-01-17T07:00:59.242964Z","shell.execute_reply":"2023-01-17T07:00:59.242039Z","shell.execute_reply.started":"2023-01-17T07:00:59.232757Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def save_to_json(dic, path_to_results):\n","    \"\"\"\n","    Save a dicitonary to a location\n","\n","    Parameters:\n","        dic: dictionary to be saved\n","        path_to_results: path where to save the dictionary\n","\n","    \"\"\"\n","    with open(path_to_results+\".json\", \"w\") as fp:\n","        json.dump(dic, fp, indent=4)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Generate txt file "]},{"cell_type":"code","execution_count":33,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.245236Z","iopub.status.busy":"2023-01-17T07:00:59.244544Z","iopub.status.idle":"2023-01-17T07:00:59.256391Z","shell.execute_reply":"2023-01-17T07:00:59.255184Z","shell.execute_reply.started":"2023-01-17T07:00:59.245201Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def generate_txt_file(y, path_to_results, name_of_file, y_probs=None):\n","    \"\"\"\n","    Generates a text file with structure as follows:\n","    file_name_1 label\n","    file_name_2 label\n","\n","\n","    Parameters:\n","        y: numpy array of shape(folds, num_images, 2)\n","        path_to_results: path to the folder where to store results\n","        name_of_file (without .txt)\n","        y_probs: numpy array of shape (folds, num_images, 1)\n","\n","    \"\"\"\n","    \n","\n","    num_folds = y.shape[0]\n","    num_images = y.shape[1]\n","\n","\n","    for fold_no in range(num_folds):\n","\n","        print(f\"Processing Fold No: {fold_no}\")\n","\n","        path_to_fold = os.path.join(path_to_results, str(fold_no))\n","        if not os.path.exists(path_to_fold):\n","                os.mkdir(path_to_fold)\n","        \n","        # generate file\n","        path_to_file = path_to_fold + \"/\" + name_of_file + \".txt\"\n","        open(path_to_file, \"w\").close()\n","        with open(path_to_file, \"a\") as file:\n","            for img_no in range(num_images):\n","                file.write(f\"{y[fold_no, img_no, 0]} {y[fold_no, img_no, 1]}\\n\")\n","        \n","        # generate files with prob\n","        if y_probs is not None:\n","            path_to_prob_file = path_to_fold + \"/\" + name_of_file + \"_with_probs.txt\"\n","            open(path_to_prob_file, \"w\").close()\n","            with open(path_to_prob_file, \"a\") as file:\n","                for img_no in range(num_images):\n","                    file.write(f\"{y[fold_no, img_no, 0]} {y[fold_no, img_no, 1]} {np.around(y_probs[fold_no, img_no], 4)*100}\\n\")\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Save results "]},{"cell_type":"code","execution_count":34,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.259192Z","iopub.status.busy":"2023-01-17T07:00:59.258406Z","iopub.status.idle":"2023-01-17T07:00:59.273427Z","shell.execute_reply":"2023-01-17T07:00:59.272396Z","shell.execute_reply.started":"2023-01-17T07:00:59.259157Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def save_results(results, metrics, path_to_results, name_of_file):\n","    \"\"\"\n","    Save results to csv file\n","\n","    Parameters:\n","        results: numpy array of shape (num_folds, metrics)\n","        metrics: numpy array of name of the metrics\n","        path_to_results: path to the folder where the results will be stored\n","        name_of_file: file name\n","       \n","    \"\"\"\n","    df = pd.DataFrame([], columns=[\"Fold No\", \"Metric\", \"Score\"])\n","    num_folds = results.shape[0]\n","    num_metrics = results.shape[1]\n","\n","    for fold_no in range(num_folds):\n","        for metric_no in range(num_metrics):\n","            temp = pd.DataFrame([[fold_no, metrics[metric_no], results[fold_no, metric_no]]], columns=[\"Fold No\", \"Metric\", \"Score\"])\n","            df = pd.concat([df, temp])\n","\n","    df.reset_index(inplace=True, drop=True ) \n","       \n","    df.to_csv(path_to_results + \"/\" + name_of_file +\".csv\")"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Count Model parameters "]},{"cell_type":"code","execution_count":35,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.276042Z","iopub.status.busy":"2023-01-17T07:00:59.275227Z","iopub.status.idle":"2023-01-17T07:00:59.290934Z","shell.execute_reply":"2023-01-17T07:00:59.289652Z","shell.execute_reply.started":"2023-01-17T07:00:59.276005Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    \"\"\"\n","    \n","    Counts number of parameters in the model\n","    \n","    Parameter:\n","        model\n","    \n","    Returns:\n","        a dict with keys:\n","            parameters: \n","                name: dict with keys: trainable and total \n","            total_trainable_parameters:\n","            total_parameters\n","    \n","    \"\"\"\n","    output_config = {}\n","    output_config[\"parameters\"] = {}\n","    total_params = 0\n","    train_params = 0\n","    \n","    \n","    for name, parameter in model.named_parameters():\n","        params = parameter.numel()\n","        \n","        # trainable parameters\n","        if parameter.requires_grad:\n","            tr_p = params\n","            train_params += params \n","        else:\n","            tr_p = 0\n","        \n","        # total parameters\n","        total_params+=params\n","        \n","        output_config[\"parameters\"][name] = {}\n","        output_config[\"parameters\"][\"trainable\"] = params\n","        output_config[\"parameters\"][\"total\"] = tr_p\n","       \n","    output_config[\"total_trainable_parameters\"] =  train_params\n","    output_config[\"total_parameters\"] =  total_params\n","    \n","    \n","    return output_config"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Prediction"]},{"cell_type":"code","execution_count":36,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.293593Z","iopub.status.busy":"2023-01-17T07:00:59.292910Z","iopub.status.idle":"2023-01-17T07:00:59.309810Z","shell.execute_reply":"2023-01-17T07:00:59.308839Z","shell.execute_reply.started":"2023-01-17T07:00:59.293540Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def get_predictions(path_to_results, path_to_images, y, data_transforms, batch_size, device, fold=-2):\n","    \"\"\"\n","    generates predictions\n","    \n","    path_to_results: where models are saved\n","    path_to_images: images dir\n","    y: (num_images, 1)\n","    data_transforms: transformation to apply\n","    fold: prediction for specific fold\n","    \n","    \n","    Returns:\n","        y_preds_folds: (num_folds, num_images)\n","        y_preds_probs_folds: (num_folds, num_images, num_classes) \n","        y_preds_en: (num_images,1)\n","        y_preds_probs_ensemble: (num_images, num_classes)\n","        \n","    thresholding could be added for binary (>th)/multi(>th for each class) classsifcation\n","    \"\"\"\n","    y_preds_probs_folds=[]\n","    y_preds_folds = []\n","    \n","    sigmoid = torch.nn.Sigmoid()\n","    softmax = torch.nn.Softmax(dim=1)       \n","    \n","    flag = False\n","    single_neuron = False\n","    \n","    for fold_no in sorted(os.listdir(path_to_results)):\n","        \n","        path_to_model = os.path.join(path_to_results, fold_no)\n","        \n","        if os.path.isdir(path_to_model):\n","            \n","            if fold == -2:\n","                flag = True\n","            else:\n","                if fold_no == str(fold):\n","                    flag = True\n","                else:\n","                    flag =False\n","            \n","            if flag:\n","                print(f\"Generating predicitons for fold no: {fold_no}\")\n","\n","                # get data\n","                data = ImageDataset(y, path_to_images, transform=data_transforms)\n","                dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n","\n","                # load model\n","                model_path = os.path.join(path_to_model, \"model.pt\")\n","                print (f\"Loading model from {model_path}\")\n","                model = torch.load(model_path)\n","                model.to(device)\n","                model.eval()\n","\n","                with torch.no_grad():\n","\n","                    y_pred_prob=[]\n","                    y_pred_labels =[]\n","\n","                    for images, _ in dataloader:\n","                        images = images.to(device)\n","\n","                        y_pred = model(images)\n","\n","                        if y_pred.shape[-1] == 1:\n","                            # get probs\n","                            prob = sigmoid(y_pred)\n","\n","                            # get hard labels\n","                            labels = np.round(prob.detach().cpu().clone().numpy())\n","\n","                            single_neuron = True\n","                        else:\n","                            #get probs\n","                            prob = softmax(y_pred)\n","\n","                            # get hard labels\n","                            labels = np.argmax(prob.detach().cpu().clone().numpy(), axis=1) \n","\n","                        #combine iter results\n","                        y_pred_prob.extend(prob.detach().cpu().clone().numpy())\n","                        y_pred_labels.extend(labels)\n","\n","\n","                    # combine fold results\n","                    y_preds_folds.append(y_pred_labels)\n","                    y_preds_probs_folds.append(y_pred_prob)\n","\n","        \n","    # get ensemble results\n","    y_preds_probs_ensemble = np.mean(y_preds_probs_folds, axis=0)\n","    \n","\n","    if single_neuron:\n","        y_preds_en = np.round(y_preds_probs_ensemble).reshape(-1,1)\n","    else:\n","        y_preds_en = np.argmax(y_preds_probs_ensemble, axis=1).reshape(-1,1)\n","        \n","    return np.array(y_preds_folds), np.array(y_preds_probs_folds), np.array(y_preds_en), np.array(y_preds_probs_ensemble)\n"]},{"cell_type":"code","execution_count":37,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.312075Z","iopub.status.busy":"2023-01-17T07:00:59.311641Z","iopub.status.idle":"2023-01-17T07:00:59.330670Z","shell.execute_reply":"2023-01-17T07:00:59.329701Z","shell.execute_reply.started":"2023-01-17T07:00:59.312037Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def CNN_prediction(path_to_images, path_to_json, save_path):\n","    \"\"\"\n","    Generates prediction for the given data set\n","\n","    Parameters:\n","        path_to_images: path to the folder containing images on which prediction will be generated\n","        path_to_results: path to the folder where models are saved\n","        save_path: path to the folder where the results will be stored\n","        data_transform: transformation to apply\n","        batch_size: batch size\n","\n","    \"\"\"\n","\n","    if not os.path.isdir(path_to_images):\n","        raise ValueError(\"'path_to_images' must be a directory\")\n","\n","    if not os.path.exists(save_path):\n","        os.mkdir(save_path)\n","        print(f\"Created directory {save_path}\")\n","    else:\n","        print(f\"Warning: {save_path} already exists. Content may get overwritten\")\n","    \n","    # loading training pipeline\n","    pipeline = load_from_json(path_to_json)\n","\n","    pipeline[\"path_to_images\"] = path_to_images\n","    path_to_models = pipeline[\"path_to_results\"]\n","    \n","    pipeline[\"path_to_models\"] = path_to_models\n","    pipeline[\"path_to_results\"] = save_path\n","    \n","\n","    del pipeline['path_to_labels']\n","    \n","    device = pipeline[\"device\"]\n","    batch_size= pipeline[\"batch_size\"]\n","    classes = pipeline[\"classes\"]\n","    \n","    \n","    # get transforms\n","    data_transform = pipeline[\"data_preprocessing\"][\"valid\"]\n","    data_transforms = data_preprocessing(data_transform)\n","    \n","    # generate y\n","    y=np.array(sorted(os.listdir(path_to_images))).reshape(-1,1)\n","    \n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print(f\"Using Device: {device}\")\n","  \n","    print(\"\\nGenerating labels for the data . . . \")\n","    y_pred, y_pred_probs, y_pred_en, y_pred_probs_en = get_predictions(path_to_results=path_to_models, path_to_images=path_to_images, y=y, data_transforms=data_transforms, batch_size=batch_size, device=device)\n","    \n","   \n","    # transform labels and add image ids\n","    y_pred_tr = np.full((y_pred.shape[0], y.shape[0], 2), -1000) \n","    for nf in range(y_pred.shape[0]):\n","        y_pred_tr[nf, :, 0] = y[:,0]\n","        y_pred_tr[nf, :, 1] = label_encoder(y=y_pred[nf,:], classes=classes, to_numbers=False)\n","    \n","    \n","    y_pred_probs_en = np.expand_dims(y_pred_probs_en, axis=0)\n","    y_pred_en = np.expand_dims (np.concatenate((y, y_pred_en), axis=1), axis=0)\n","    y_pred_en[0, :, 1] = label_encoder(y=y_pred_en[0, :, 1], classes=classes, to_numbers=False)\n","    \n","    print(f\"Generated labels for the data successfully. Shape: y_pred: {y_pred_tr.shape} y_pred_probs: {y_pred_probs.shape} y_pred_en: {y_pred_en.shape} y_pred_probs_en: {y_pred_probs_en.shape}\")\n","    \n","    \n","\n","    # save pipeline\n","    print(\"\\nsaving pipeline dictionary to json\")\n","    save_to_json(\n","        pipeline, \n","        save_path +\"/pipeline\"\n","        )\n","    \n","    # save labels\n","    print(\"\\nGenerating text file for the data\")\n","    generate_txt_file(\n","        y=y_pred_tr, \n","        path_to_results=save_path, \n","        name_of_file=\"labels\",\n","        y_probs = np.max(y_pred_probs, axis=-1)\n","        )\n","    \n","     # save labels with probs\n","    print(\"\\nGenerating text file for the data ensemble\")\n","    generate_txt_file(\n","        y=y_pred_en, \n","        path_to_results=save_path, \n","        name_of_file=\"labels_en\",\n","        y_probs = np.max(y_pred_probs_en, axis=-1)\n","        )\n","    \n","    \n","    pipeline[\"path_to_models\"] = path_to_results\n","    pipeline[\"path_to_results\"] = save_path\n","    \n","    print(\"\\nGenerated Predictions Successfully\")"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Training\n","\n","* for each epoch, train the model and evaluate the model on training and validaiton data using metrics: loss, balanced accuracy, mcc etc\n","\n","* store evaluation results for each epoch that will be used for learning curves\n","* save the best model using val loss or some other metric\n","\n","* generate prediction and prediction probabilities using best model on training and validation data\n","\n","save all the necessary info"]},{"cell_type":"code","execution_count":38,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.333126Z","iopub.status.busy":"2023-01-17T07:00:59.332377Z","iopub.status.idle":"2023-01-17T07:00:59.346033Z","shell.execute_reply":"2023-01-17T07:00:59.345345Z","shell.execute_reply.started":"2023-01-17T07:00:59.333089Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def train_epoch(model, device, dataloader, loss_fnt, optimizer):\n","    \"\"\"\n","    trains a model \n","    \n","    Parameters:\n","        model: model to be trained\n","        device: device on which model to be trained\n","        dataloader: of training dataset\n","        lost_fnt: loss function\n","        optimizer:\n","        \n","    Returns:\n","        train_loss, train_balanced_accu, train_mcc \n","        unnormalized values (No multiplication of 1/num_images)\n","    \n","    \"\"\"\n","    \n","    train_loss = 0\n","    train_balanced_accu = 0\n","    train_mcc = 0\n","    \n","    sigmoid = torch.nn.Sigmoid()\n","    \n","    model.train()\n","\n","    for images, labels in dataloader:\n","\n","        images,labels = images.to(device),labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(images)\n","        \n","        loss = loss_fnt(output,labels)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        train_loss += loss.item() * images.size(0)\n","        \n","        if output.shape[-1] == 1:\n","            y_pred = torch.round(sigmoid(output.detach().clone())).cpu().numpy()\n","        else:\n","            y_pred = np.argmax(output.detach().clone().cpu().numpy(), axis=1)\n","                    \n","        train_balanced_accu += accuracy(y_true=labels.detach().clone().cpu().numpy(), y_pred=y_pred, parameters={\"type\": \"balanced\"})[0] * images.size(0)\n","        train_mcc += mcc(y_true=labels.detach().clone().cpu().numpy(), y_pred=y_pred, parameters={})[0] * images.size(0) \n","\n","        \n","    return train_loss, train_balanced_accu, train_mcc"]},{"cell_type":"code","execution_count":39,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.348244Z","iopub.status.busy":"2023-01-17T07:00:59.347539Z","iopub.status.idle":"2023-01-17T07:00:59.362943Z","shell.execute_reply":"2023-01-17T07:00:59.361852Z","shell.execute_reply.started":"2023-01-17T07:00:59.348198Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def valid_epoch(model, device, dataloader, loss_fnt):\n","    \"\"\"\n","    Generates results on validation data\n","    \n","    Parameters:\n","        model: model to be used for evaluatioon\n","        device: device on which model will be evaluated\n","        dataloader: of validation dataset\n","        lost_fnt: loss function\n","        \n","    Returns:\n","        valid_loss, valid_balanced_accu, valid_mcc \n","        unnormalized values (No multiplication of 1/num_images)\n","    \n","    \"\"\"\n","    \n","    valid_loss = 0\n","    valid_balanced_accu = 0\n","    valid_mcc = 0\n","    \n","    sigmoid = torch.nn.Sigmoid()\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","        \n","        for images, labels in dataloader:\n","\n","            images,labels = images.to(device),labels.to(device)\n","\n","            output = model(images)\n","\n","            loss=loss_fnt(output,labels)\n","\n","            valid_loss+=loss.item()*images.size(0)\n","            \n","            if output.shape[-1] == 1:\n","                y_pred = torch.round(sigmoid(output.detach().clone())).cpu().numpy()\n","            else:\n","                y_pred = np.argmax(output.detach().clone().cpu().numpy(), axis=1)\n","            \n","            valid_balanced_accu += accuracy(y_true=labels.cpu().numpy(), y_pred=y_pred, parameters={\"type\": \"balanced\"})[0] * images.size(0)\n","            valid_mcc += mcc(y_true=labels.cpu().numpy(), y_pred=y_pred, parameters={})[0] * images.size(0) \n","\n","    return valid_loss, valid_balanced_accu, valid_mcc\n"]},{"cell_type":"code","execution_count":40,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.365868Z","iopub.status.busy":"2023-01-17T07:00:59.365090Z","iopub.status.idle":"2023-01-17T07:00:59.548501Z","shell.execute_reply":"2023-01-17T07:00:59.547399Z","shell.execute_reply.started":"2023-01-17T07:00:59.365804Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def CNN_training(pipeline):\n","    \n","    output_config = {}\n","    \n","    # set up whether to use cpu or gpu\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print(f\"Using Device: {device}\")\n","    output_config[\"device\"] = device\n","    \n","    #get results folder\n","    path_to_results = pipeline[\"path_to_results\"]\n","    output_config[\"path_to_results\"] = path_to_results\n","    if not os.path.exists(path_to_results):\n","            os.mkdir(path_to_results)\n","    \n","    #get iamge folder\n","    path_to_images = pipeline[\"path_to_images\"]\n","    output_config[\"path_to_images\"] = path_to_images\n","    \n","    # get batch size\n","    batch_size= pipeline[\"batch_size\"]\n","    output_config[\"batch_size\"] =batch_size\n","    \n","    # get batch size\n","    num_epochs= pipeline[\"num_epochs\"]\n","    output_config[\"num_epochs\"] =num_epochs\n","    \n","    \n","    # read labels from txt\n","    path_to_labels = pipeline[\"path_to_labels\"]\n","    output_config[\"path_to_labels\"] = path_to_labels\n","\n","    y = np.loadtxt(path_to_labels, dtype=str, delimiter=\" \")\n","    \n","    # get unique labels and their ratios\n","    original_labels = {}\n","    unique_labels, counts = np.unique(y[:,1], return_counts=True)\n","    print(f\"Unique labels found and their frequencies: \")\n","    for ul, c in zip(unique_labels, counts):\n","        original_labels[ul] = format(c*100/y.shape[0], '.4f')\n","        print(f\"Label: {ul}, %age: {format(c*100/y.shape[0], '.4f')}\")\n","    output_config[\"original_labels\"] = original_labels\n","    \n","    # split data\n","    split_type = pipeline[\"split_type\"]\n","    output_config[\"split_type\"] = split_type\n","    \n","    if \"simple\" in split_type:\n","        test_size = pipeline[\"test_size\"]\n","        output_config[\"test_size\"] = test_size\n","        num_folds=1\n","        y_train, y_valid = split_data(y=y, split_type=split_type, test_size=test_size)\n","    \n","    elif \"fold\" in split_type:\n","        num_folds = pipeline[\"num_folds\"]\n","        output_config[\"num_folds\"] = num_folds\n","        y_train, y_valid = split_data(y=y, split_type=split_type, n_folds=num_folds)\n","    \n","    else:\n","        raise ValueError(\"Unknown spliting type\")\n","        \n","    print(f\"Split the data successfully. Shape: y_train: {y_train.shape} y_valid: {y_valid.shape}\")\n","        \n","        \n","    # number of images in train and valid data\n","    num_images_train = y_train.shape[1]\n","    num_images_valid = y_valid.shape[1]\n","    \n","    # transform labels\n","    classes = pipeline[\"classes\"]\n","    for nf in range(num_folds):\n","        y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=True)\n","        y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=True)\n","    \n","    output_config[\"classes\"] = classes.tolist()\n","    output_config[\"data_preprocessing\"]={}\n","    output_config[\"data_preprocessing\"][\"train\"] = OrderedDict()\n","    output_config[\"data_preprocessing\"][\"valid\"] = OrderedDict()\n","    \n","    # get preprocessing transformations for training data\n","    train_data_transform = pipeline[\"data_preprocessing\"][\"train\"]\n","    output_config[\"data_preprocessing\"][\"train\"] = train_data_transform\n","    \n","    train_data_transforms = data_preprocessing(train_data_transform)\n","    \n","        \n","    # get preprocessing transformations for validation data\n","    valid_data_transform = pipeline[\"data_preprocessing\"][\"valid\"]\n","    output_config[\"data_preprocessing\"][\"valid\"] = valid_data_transform\n","    \n","    valid_data_transforms = data_preprocessing(valid_data_transform)\n","    \n","     # get input shape for the model\n","    input_shape = pipeline[\"input_shape\"]\n","    output_config[\"input_shape\"] = input_shape\n","    \n","    # get layers of the model\n","    layers = pipeline[\"model\"]\n","    output_config[\"model\"] = layers\n","    \n","    #get loss settings\n","    loss_param = pipeline[\"loss\"]\n","    output_config[\"loss\"] = loss_param\n","    \n","    # get optimizer settings\n","    optim_parameters = pipeline[\"optimizer\"]\n","    output_config[\"optimizer\"] =optim_parameters \n","    \n","    #get metrics\n","    metrics = pipeline[\"metrics\"]\n","    output_config[\"metrics\"] =metrics\n","    \n","    # get plots\n","    plots = pipeline[\"plots\"]\n","    output_config[\"plots\"] =plots\n","    \n","    \n","    # for saving scores of each fold\n","    train_loss_fold, train_accu_fold,train_mcc_fold = [],[],[]\n","    valid_loss_fold, valid_accu_fold,valid_mcc_fold = [],[],[]\n","    \n","    # for saving scores of best model of each model\n","    train_loss_fold_best, train_accu_fold_best,train_mcc_fold_best = [],[],[]\n","    valid_loss_fold_best, valid_accu_fold_best,valid_mcc_fold_best = [],[],[]\n","    best_model_epoch_no_fold = []\n","    \n","    train_labels ={}\n","    valid_labels={}\n","    \n","    for fold_no in range(num_folds):\n","        \n","        path_to_fold = os.path.join(path_to_results, str(fold_no))\n","        if not os.path.exists(path_to_fold):\n","            os.mkdir(path_to_fold)\n","        \n","        # get training data\n","        train_data = ImageDataset(y_train[fold_no], path_to_images, transform=train_data_transforms)\n","        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","        \n","        # get validation data\n","        valid_data = ImageDataset(y_valid[fold_no], path_to_images, transform=valid_data_transforms)\n","        valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n","        \n","        # load model\n","        model = Model(input_shape,layers)\n","        model.to(device)\n","        model_parameters = count_parameters(model)\n","        \n","        if fold_no == 0:\n","            output_config[\"model_parameters\"] = model_parameters\n","        \n","        trainable_params = model_parameters[\"total_trainable_parameters\"]\n","        total_params = model_parameters[\"total_parameters\"]\n","    \n","\n","        print(f\"\\nFold No: {fold_no+1} Model: \\n {model}\")\n","        print(f\"Total trainable parameters: {trainable_params} Total parameters: {total_params}\")\n","        \n","        # get ratio of each class in y_train\n","        train_labels[str(fold_no)] = {}\n","        unique_labels, counts = np.unique(y_train[fold_no,:,1], return_counts=True)\n","        print(f\"\\nFold No: {fold_no+1} Training data: Unique labels: \")\n","        for ul, c in zip(unique_labels, counts):\n","                train_labels[str(fold_no)][ul] = format(c*100/num_images_train, '.4f')\n","                print(f\"Label: {ul}, %age: {format(c*100/num_images_train, '.4f')}\")\n","\n","        # get ratio of each class in y_valid\n","        valid_labels[str(fold_no)] = {}\n","        unique_labels, counts =np.unique(y_valid[fold_no, :,1], return_counts=True)\n","        print(f\"\\nFold No: {fold_no+1} Validation data: Unique labels: \")\n","        for ul, c in zip(unique_labels, counts):\n","            valid_labels[str(fold_no)][ul] = format(c*100/num_images_valid, '.4f')\n","            print(f\"Label: {ul}, %age: {format(c*100/num_images_valid, '.4f')}\")\n","        \n","        # setup loss\n","        if loss_param[\"use_single_neuron\"]:\n","            class_weights = [float(train_labels[str(fold_no)]['0']) / float(train_labels[str(fold_no)]['1'])]\n","            \n","            loss_fnt = setup_loss({**loss_param, **{\"class_weights\": class_weights}})\n","            print(f\"\\nFold No: {fold_no+1} loss: {loss_fnt} weights: {loss_fnt.pos_weight}\")\n","        \n","        else:\n","            class_weights = []\n","            for cl in range(len(classes)):\n","                class_weights.append(1 - float(train_labels[str(fold_no)][str(cl)])/100 )\n","\n","            loss_fnt = setup_loss({**loss_param, **{\"class_weights\": class_weights}})\n","            print(f\"\\nFold No: {fold_no+1} loss: {loss_fnt} weights: {loss_fnt.weight}\")\n","        \n","\n","        # setup optimizer\n","        optimizer = setup_optimizer(model.parameters(), optim_parameters)\n","        print(f\"\\nFold No: {fold_no+1} Optimizer: \\n {optimizer}\")\n","          \n","        # for saving scores of each epoch of best model\n","        train_loss_epoch, train_accu_epoch,train_mcc_epoch = [],[],[]\n","        valid_loss_epoch, valid_accu_epoch,valid_mcc_epoch = [],[],[]\n","        \n","        for epoch in range(num_epochs):\n","            \n","            print(f\"Training :Fold No: {fold_no+1}/{num_folds} Epoch:{epoch+1}/{num_epochs} . . .\")\n","            \n","            train_loss, train_accu, train_mcc = train_epoch(model, device, train_dataloader, loss_fnt, optimizer)\n","            valid_loss, valid_accu, valid_mcc = valid_epoch(model, device, valid_dataloader, loss_fnt)\n","            \n","            train_loss, train_accu, train_mcc = train_loss/num_images_train, train_accu/num_images_train, train_mcc/num_images_train\n","            valid_loss, valid_accu, valid_mcc = valid_loss/num_images_valid, valid_accu/num_images_valid, valid_mcc/num_images_valid\n","            \n","            print(f'Evaluated:Fold No: {fold_no+1}/{num_folds} Epoch:{epoch+1}/{num_epochs} Training: Loss: {np.around(train_loss, 4)}, Bal_accu: {np.around(train_accu, 4)}, mcc: {np.around(train_mcc, 4)} Validation: Loss: {np.around(valid_loss, 4)}, Bal_accu: {np.around(valid_accu, 4)}, mcc: {np.around(valid_mcc, 4)}')\n","             \n","            # save best model\n","            if epoch == 0:\n","                print(f\"Saving Model of first epoch\")\n","                \n","                torch.save(model, os.path.join(path_to_fold, \"model.pt\"))\n","                \n","                # save best model scores\n","                best_model_epoch_no = epoch\n","                train_loss_epoch_best = train_loss\n","                train_accu_epoch_best = train_accu\n","                train_mcc_epoch_best = train_mcc\n","\n","                valid_loss_epoch_best = valid_loss\n","                valid_accu_epoch_best = valid_accu\n","                valid_mcc_epoch_best = valid_mcc   \n","\n","            elif  valid_loss_epoch_best > valid_loss:\n","                \n","                print(f\"Validation Loss score improved. Saving Model.\")\n","                \n","                torch.save(model, os.path.join(path_to_fold, \"model.pt\"))\n","                \n","                # save best model scores\n","                best_model_epoch_no = epoch\n","                train_loss_epoch_best = train_loss\n","                train_accu_epoch_best = train_accu\n","                train_mcc_epoch_best = train_mcc\n","\n","                valid_loss_epoch_best = valid_loss\n","                valid_accu_epoch_best = valid_accu\n","                valid_mcc_epoch_best = valid_mcc   \n","\n","            else:\n","                print(\"Validaiton Loss score did not improve.\")\n","            \n","            # save scores for learning curves\n","            train_loss_epoch.append(train_loss)\n","            train_accu_epoch.append(train_accu)\n","            train_mcc_epoch.append(train_mcc)\n","            \n","            valid_loss_epoch.append(valid_loss)\n","            valid_accu_epoch.append(valid_accu)\n","            valid_mcc_epoch.append(valid_mcc)\n","            \n","        print(f\"Fold No: {fold_no+1}/{num_folds} Best Validation Loss score recorded on epoch {best_model_epoch_no}: {valid_loss_epoch_best}\")\n","\n","        # save best model for each fold\n","        best_model_epoch_no_fold.append(best_model_epoch_no)\n","        \n","        train_loss_fold_best.append(train_loss_epoch_best)\n","        train_accu_fold_best.append(train_accu_epoch_best)\n","        train_mcc_fold_best.append(train_mcc_epoch_best)\n","\n","        valid_loss_fold_best.append(valid_loss_epoch_best)\n","        valid_accu_fold_best.append(valid_accu_epoch_best)\n","        valid_mcc_fold_best.append(valid_mcc_epoch_best)\n","        \n","        # save scores for each fold\n","        train_loss_fold.append(train_loss_epoch)\n","        train_accu_fold.append(train_accu_epoch)\n","        train_mcc_fold.append(train_mcc_epoch)\n","\n","        valid_loss_fold.append(valid_loss_epoch)\n","        valid_accu_fold.append(valid_accu_epoch)\n","        valid_mcc_fold.append(valid_mcc_epoch)\n","    \n","    \n","    #convert to numpy\n","    train_loss_fold = np.array(train_loss_fold)\n","    train_accu_fold = np.array(train_accu_fold)\n","    train_mcc_fold = np.array(train_mcc_fold)\n","    \n","    valid_loss_fold = np.array(valid_loss_fold)\n","    valid_accu_fold = np.array(valid_accu_fold)\n","    valid_mcc_fold = np.array(valid_mcc_fold)\n","    \n","    \n","    \n","    # generate learning curves array\n","    score_for_learning_curves = np.full((num_folds, 3,2, num_epochs), -1000)\n","    for nf in range(num_folds):\n","        score_for_learning_curves[nf, 0, 0, :] = train_loss_fold[nf]\n","        score_for_learning_curves[nf, 1, 0, :] = train_accu_fold[nf]\n","        score_for_learning_curves[nf, 2, 0, :] = train_mcc_fold[nf]\n","        \n","        score_for_learning_curves[nf, 0, 1, :] = valid_loss_fold[nf]\n","        score_for_learning_curves[nf, 1, 1, :] = valid_accu_fold[nf]\n","        score_for_learning_curves[nf, 2, 1, :] = valid_mcc_fold[nf]\n","    \n","    print(f\"Trained the model for all folds. Shape: train: loss: {train_loss_fold.shape} accu: {train_accu_fold.shape} mcc: {train_mcc_fold.shape} valid: loss: {valid_loss_fold.shape} accu: {valid_accu_fold.shape} mcc: {valid_mcc_fold.shape} Learning scores: {score_for_learning_curves.shape}\")\n","    \n","    output_config[\"train_labels\"] = train_labels\n","    output_config[\"valid_labels\"] = valid_labels\n","    \n","    output_config[\"results\"] = {}\n","    output_config[\"results\"][\"best_model\"]={}\n","    output_config[\"results\"][\"best_model\"][\"epoch_number\"]=best_model_epoch_no_fold\n","    output_config[\"results\"][\"best_model\"][\"train\"]={}\n","    output_config[\"results\"][\"best_model\"][\"train\"][\"loss\"]=train_loss_fold_best\n","    output_config[\"results\"][\"best_model\"][\"train\"][\"balanced_accuracy\"]=train_accu_fold_best\n","    output_config[\"results\"][\"best_model\"][\"train\"][\"mcc\"]=train_mcc_fold_best\n","    output_config[\"results\"][\"best_model\"][\"valid\"]={}\n","    output_config[\"results\"][\"best_model\"][\"valid\"][\"loss\"]=valid_loss_fold_best\n","    output_config[\"results\"][\"best_model\"][\"valid\"][\"balanced_accuracy\"]=valid_accu_fold_best\n","    output_config[\"results\"][\"best_model\"][\"valid\"][\"mcc\"]=valid_mcc_fold_best\n","    \n","    # generate predicitons\n","    print(\"Generating Predictions on training and validation data\")\n","    train_pred = []\n","    train_pred_prob = []\n","    valid_pred = []\n","    valid_pred_prob = []\n","    for fn in range(num_folds):\n","        train_pred_fn, train_pred_prob_fn, _,_= get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y_train[fn], data_transforms=valid_data_transforms, fold=fn, batch_size=batch_size, device=device)\n","        valid_pred_fn, valid_pred_prob_fn, _,_= get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y_valid[fn], data_transforms=valid_data_transforms, fold=fn, batch_size=batch_size, device=device)\n","        \n","        train_pred_fn = label_encoder(y=train_pred_fn, classes=classes, to_numbers=False)\n","        valid_pred_fn = label_encoder(y=valid_pred_fn, classes=classes, to_numbers=False)\n","     \n","        \n","        train_pred.append([y_train[fn, :, 0], train_pred_fn])\n","        train_pred_prob.append(train_pred_prob_fn[0])\n","        valid_pred.append([y_valid[fn, :, 0],valid_pred_fn])\n","        valid_pred_prob.append(valid_pred_prob_fn[0])\n","        \n","\n","    train_pred =np.array(train_pred).swapaxes(-1,-2)\n","    train_pred_prob =np.array(train_pred_prob)\n","    valid_pred =np.array(valid_pred).swapaxes(-1,-2)\n","    valid_pred_prob =np.array(valid_pred_prob)\n","    \n","    print(f\"Generated predictions on training and validation dataset. Shape: train: labels: {train_pred.shape} prob: {train_pred_prob.shape} valid: labels: {valid_pred.shape} prob: {valid_pred_prob.shape}\")    \n","    \n","    # transform int labels to name of classes\n","    for nf in range(num_folds):\n","        y_train[nf, :, 1] = label_encoder(y=y_train[nf,:,1], classes=classes, to_numbers=False)\n","        y_valid[nf, :, 1] = label_encoder(y=y_valid[nf,:,1], classes=classes, to_numbers=False)\n","        \n","    \n","     # generate predicitons on complete dataset\n","    print(\"\\nGenerating predicitons on complete dataset. . . \")\n","    \n","    # transform name of classes to int\n","    y[:, 1] = label_encoder(y=y[:,1], classes=classes, to_numbers=True)\n","    \n","    y_pred_comp, y_pred_prob_comp, y_pred_en, y_pred_prob_en = get_predictions(path_to_results=path_to_results, path_to_images=path_to_images, y=y, data_transforms=valid_data_transforms, device=device, batch_size=batch_size)\n","     \n","    # transform labels and add image ids\n","    y_pred_com = np.full((num_folds, y.shape[0],2), \"-1000\") \n","    for nf in range(num_folds):\n","        y_pred_com[nf, :, 0] = y[:,0]\n","        y_pred_com[nf, :, 1] = label_encoder(y=y_pred_comp[nf], classes=classes, to_numbers=False)\n","    \n","    y_pred_prob_com = y_pred_prob_comp\n","        \n","    y_pred_en = np.expand_dims (np.concatenate((y[:,0].reshape(-1,1), y_pred_en), axis=1), axis=0)\n","    y_pred_prob_en = np.expand_dims(y_pred_prob_en, axis=0)   \n","    \n","    y = np.repeat(y[None, :,:], num_folds, axis=0)#np.expand_dims(y, axis=0)\n","    \n","    print(f\"Generated predicitons on complete dataset. Shape: Folds: labels: {y_pred_com.shape} probs: {y_pred_prob_com.shape} Ensembles: labels: {y_pred_en.shape} probs: {y_pred_prob_en.shape}\")\n","    \n","    \n","    #evaluate metrics on training data\n","    print(\"\\nEvaluating Metrics on training data . . . \")\n","    metrics_train, metrics_train_config, metrics_train_list = evaluate_metrics(\n","        y_true=y_train, \n","        y_pred=train_pred, \n","        metrics=metrics,\n","        y_pred_probs = train_pred_prob\n","        )\n","    print(\"\\nResults\")\n","\n","\n","    for fold_no in range(num_folds):\n","        for met_no, met in enumerate(metrics_train_list):\n","            print(f\"Fold No: {fold_no} Metric: {met}  Score: {np.around(metrics_train[fold_no, met_no], 4)} \")\n","\n","    print(f\"Evaluated Metrics on the training data successfully. Shape:{metrics_train.shape}\")\n","\n","    #evaluate metrics on validataion data\n","    print(\"\\nEvaluating Metrics on validation data . . . \")\n","    metrics_valid, _, metrics_valid_list = evaluate_metrics(\n","        y_true=y_valid, \n","        y_pred=valid_pred, \n","        metrics=metrics,\n","        y_pred_probs = valid_pred_prob\n","        )\n","    print(\"\\nResults\")\n","    \n","    for fold_no in range(num_folds):\n","        for met_no, met in enumerate(metrics_valid_list):\n","            print(f\"Fold No: {fold_no} Metric: {met}  Score: {np.around(metrics_valid[fold_no, met_no],4)} \")\n","\n","    print(f\"Evaluated Metrics on the validation data successfully. Shape: {metrics_valid.shape}\")\n","    \n","    print(\"\\nEvaluating Metrics on complete data . . . \")\n","    # transform int labels to name of classes\n","    for nf in range(num_folds):\n","        y[nf,:, 1] = label_encoder(y=y[nf,:,1], classes=classes, to_numbers=False)\n","    \n","    metrics_com, metrics_com_config, metrics_com_list = evaluate_metrics(\n","        y_true=y, \n","        y_pred=y_pred_com, \n","        metrics=metrics,\n","        y_pred_probs = y_pred_prob_com\n","        )\n","    print(\"\\nResults\")\n","    \n","    for nf in range(num_folds):\n","        for met_no, met in enumerate(metrics_com_list):\n","            print(f\"Fold No: {nf} Metric: {met}  Score: {np.around(metrics_com[nf, met_no],4)} \")\n","            \n","    print(f\"Evaluated Metrics on the complete dataset successfully. Shape:{metrics_com.shape}\")\n","    \n","    print(\"\\nEvaluating Metrics on complete dataset using ensembles . . . \")\n","    # transform int labels to name of classes\n","    y_pred_en[0, :, 1] = label_encoder(y=y_pred_en[0, :, 1], classes=classes, to_numbers=False)\n","     \n","    metrics_en, metrics_en_config, metrics_en_list = evaluate_metrics(\n","        y_true=np.expand_dims(y[0], axis=0), \n","        y_pred=y_pred_en, \n","        metrics=metrics,\n","        y_pred_probs = y_pred_prob_en\n","        )\n","    print(\"\\nResults\")\n","    \n","    for met_no, met in enumerate(metrics_en_list):\n","            print(f\"Fold No: {0} Metric: {met}  Score: {np.around( metrics_en[0, met_no], 4)} \")\n","            \n","    print(f\"Evaluated Metrics on the complete dataset using ensemble successfully. Shape:{metrics_en.shape}\")\n","\n","            \n","    # create plots\n","    print(\"\\nCreating Plots for training data . . .\")\n","    plots_train_config = create_plots(\n","        y_true=y_train, \n","        y_pred=train_pred, \n","        plots= plots, \n","        path_to_results=path_to_results,\n","        path_to_images=path_to_images,\n","        name_of_file = \"train\",\n","        training_metric_scores=score_for_learning_curves,\n","        y_pred_probs = train_pred_prob\n","        )\n","    print(\"Created Plots for training data\")\n","\n","    print(\"\\nCreating Plots for validation data\")\n","    _ = create_plots(\n","        y_true=y_valid, \n","        y_pred=valid_pred, \n","        plots= plots, \n","        path_to_results=path_to_results,\n","        path_to_images=path_to_images, \n","        name_of_file = \"valid\",\n","        y_pred_probs = valid_pred_prob\n","        )\n","    print(\"Created Plots for validation data\")\n","    \n","    print(\"\\nCreating Plots for complete dataset\")\n","    _ = create_plots(\n","        y_true=y, \n","        y_pred=y_pred_com, \n","        plots= plots, \n","        path_to_results=path_to_results,\n","        path_to_images=path_to_images, \n","        name_of_file = \"complete\",\n","        y_pred_probs = y_pred_prob_com\n","        )\n","    print(\"Created Plots for complete dataset\")\n","    \n","    print(\"\\nCreating Plots for ensemble dataset\")\n","    _ = create_plots(\n","        y_true=np.expand_dims(y[0], axis=0), \n","        y_pred=y_pred_en, \n","        plots= plots, \n","        path_to_results=path_to_results,\n","        path_to_images=path_to_images, \n","        name_of_file = \"ensemble\",\n","        y_pred_probs = y_pred_prob_en\n","        )\n","    print(\"Created Plots for ensemble data\")\n","\n","    # save pipeline\n","    print(\"\\nsaving pipeline dictionary to json\")\n","    save_to_json(\n","        output_config, \n","        os.path.join(path_to_results, \"training_pipeline\")\n","        )\n","    \n","        # save labels\n","    print(\"\\nGenerating text file for training data\")\n","    generate_txt_file(\n","        y=train_pred, \n","        path_to_results=path_to_results, \n","        name_of_file=\"train\",\n","        y_probs = np.max(train_pred_prob, axis=-1)\n","        )\n","\n","    print(\"\\nGenerating text file for validation data\")\n","    generate_txt_file(\n","        y=valid_pred, \n","        path_to_results=path_to_results,  \n","        name_of_file=\"valid\",\n","        y_probs = np.max(valid_pred_prob, axis=-1)\n","        )\n","    \n","    print(\"\\nGenerating text file for complete data\")\n","    generate_txt_file(\n","        y=y_pred_com, \n","        path_to_results=path_to_results,  \n","        name_of_file=\"complete\",\n","        y_probs = np.max(y_pred_prob_com, axis=-1)\n","        )\n","    \n","    print(\"\\nGenerating text file for ensemble data\")\n","    generate_txt_file(\n","        y=y_pred_en, \n","        path_to_results=path_to_results,  \n","        name_of_file=\"ensemble\",\n","        y_probs = np.max(y_pred_prob_en, axis=-1)\n","        )\n","    \n","    # save metrics train and metrics_valid\n","    print(\"\\nSaving training results \")\n","    save_results(\n","        results=metrics_train,\n","        metrics=metrics_train_list,\n","        path_to_results=path_to_results,\n","        name_of_file=\"train\"\n","    )\n","\n","    print(\"\\nSaving validation results \")\n","    save_results(\n","        results=metrics_valid,\n","        metrics=metrics_valid_list,\n","        path_to_results=path_to_results,\n","        name_of_file=\"valid\"\n","    )\n","    \n","    print(\"\\nSaving complete data results \")\n","    save_results(\n","        results=metrics_com,\n","        metrics=metrics_com_list,\n","        path_to_results=path_to_results,\n","        name_of_file=\"complete\"\n","    )\n","    \n","    print(\"\\nSaving ensemble results \")\n","    save_results(\n","        results=metrics_en,\n","        metrics=metrics_en_list,\n","        path_to_results=path_to_results,\n","        name_of_file=\"ensemble\"\n","    )\n","\n","    print(\"\\nTraining Completed\\n\")\n","    \n","\n","\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Save\n","* the model and all the info (model, parameters, results etc)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"jupyter":{"source_hidden":true}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Evaluate Metrics\n","Using the best model, evaluate the metircs and save the find results in csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Plots:\n","* learning curve\n","* metrics\n","* confusion matrix\n","* misidentified samples\n","* ROC\n","* maybe weights\n","\n","save them"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Prediction\n","load the best model, generate prediction on train, test and noisy test dataset and create two txt files:\n","- one with file name and label (like the one provided)\n","- one with file name, label and probability"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Additional notes:\n","* set up excel sheet for finding optimal hyperparameers in organized manner\n","* set up excel for tracking results of different models in organized manner\n","* or just find some function that finds optimal hyperparameters\n","\n","* Results may not stay saved if kaggle session is closed. Either download them in timely manner or find a way to save them"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Results Directory"]},{"cell_type":"code","execution_count":41,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.557341Z","iopub.status.busy":"2023-01-17T07:00:59.557060Z","iopub.status.idle":"2023-01-17T07:00:59.565648Z","shell.execute_reply":"2023-01-17T07:00:59.564718Z","shell.execute_reply.started":"2023-01-17T07:00:59.557315Z"},"trusted":true},"outputs":[],"source":["run_name = 'benchmark'\n","\n","path_to_result ='/kaggle/working/results'\n","if not os.path.exists(path_to_result):\n","    os.mkdir(path_to_result)\n","    \n","path_to_results = os.path.join(path_to_result, run_name)\n","if not os.path.exists(path_to_results):\n","    os.mkdir(path_to_results)\n","    \n","path_to_binary_results = os.path.join(path_to_results, \"binary\")\n","if not os.path.exists(path_to_binary_results):\n","    os.mkdir(path_to_binary_results)\n","\n","path_to_multiclass_results = os.path.join(path_to_results, \"multi\")\n","if not os.path.exists(path_to_multiclass_results):\n","    os.mkdir(path_to_multiclass_results)\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Raw Data Directory"]},{"cell_type":"code","execution_count":42,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.567523Z","iopub.status.busy":"2023-01-17T07:00:59.567042Z","iopub.status.idle":"2023-01-17T07:00:59.578660Z","shell.execute_reply":"2023-01-17T07:00:59.577594Z","shell.execute_reply.started":"2023-01-17T07:00:59.567470Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# path to data folders\n","path_to_data = \"/kaggle/input/ismdatasetforclassificationofdieases/ism_dataset/raw_data\"\n","\n","# training data\n","path_to_train_data = os.path.join(path_to_data, \"train\")\n","path_to_binary_labels = os.path.join(path_to_data, \"train_binary.txt\")\n","path_to_multi_labels = os.path.join(path_to_data, \"train_multi.txt\")\n","\n","# testing data\n","path_to_test_data = os.path.join(path_to_data, \"test\")\n","\n","# noisy test data\n","path_to_noisy_test_data = os.path.join(path_to_data, \"noisy_test\")"]},{"cell_type":"code","execution_count":43,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:00:59.581897Z","iopub.status.busy":"2023-01-17T07:00:59.581616Z","iopub.status.idle":"2023-01-17T07:01:00.113067Z","shell.execute_reply":"2023-01-17T07:01:00.112066Z","shell.execute_reply.started":"2023-01-17T07:00:59.581858Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of images in: training data: 16930 test data: 4235 noisy test data: 4235\n"]}],"source":["num_train_data = len(os.listdir(path_to_train_data))\n","num_test_data = len(os.listdir(path_to_test_data))\n","num_noisy_test_data = len(os.listdir(path_to_noisy_test_data))\n","print(f\"Number of images in: training data: {num_train_data} test data: {num_test_data} noisy test data: {num_test_data}\")"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Binary Classification"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Train "]},{"cell_type":"code","execution_count":46,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:01:58.354368Z","iopub.status.busy":"2023-01-17T07:01:58.353981Z","iopub.status.idle":"2023-01-17T07:01:58.380244Z","shell.execute_reply":"2023-01-17T07:01:58.379314Z","shell.execute_reply.started":"2023-01-17T07:01:58.354337Z"},"trusted":true},"outputs":[],"source":["#--------------------------------------Pipeline-------------------------------\n","\n","pipeline_binary = {}\n","pipeline_binary[\"path_to_results\"] = os.path.join(path_to_binary_results, \"train\")\n","\n","pipeline_binary[\"batch_size\"] = 256\n","pipeline_binary[\"num_epochs\"] = 500\n","\n","# for model\n","pipeline_binary[\"input_shape\"] = (250, 250) \n","\n","# path to folder containing images \n","pipeline_binary[\"path_to_images\"] = path_to_train_data\n","# path to labels.txt\n","pipeline_binary[\"path_to_labels\"] = path_to_binary_labels\n","\n","# split data\n","pipeline_binary[\"split_type\"] = \"simpleStratified\" #\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\"\n","pipeline_binary[\"test_size\"] = 0.3\n","\n","# names of the class\n","pipeline_binary[\"classes\"] = np.array([\"NO_COVID\", \"COVID\"])\n","\n","# ---------------------------------set up data preprocessing methods and parameters------------------------------------\n","pipeline_binary[\"data_preprocessing\"] = {}\n","pipeline_binary[\"data_preprocessing\"][\"train\"] = OrderedDict()\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"] = {}\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"name\"] = \"normalize\"\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"mean\"] = 0\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"std\"] = 255\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"resize\"] = {}\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"resize\"][\"name\"] = \"resize\"\n","pipeline_binary[\"data_preprocessing\"][\"train\"][\"resize\"][\"output_shape\"] = (250,250)\n","\n","pipeline_binary[\"data_preprocessing\"][\"valid\"] = OrderedDict()\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"] = {}\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"name\"] = \"normalize\"\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"mean\"] = 0\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"std\"] = 255\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"resize\"] = {}\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"resize\"][\"name\"] = \"resize\"\n","pipeline_binary[\"data_preprocessing\"][\"valid\"][\"resize\"][\"output_shape\"] = (250,250)\n","\n","\n","\n","# ---------------------------------set up networks and parameters------------------------------------\n","\n","pipeline_binary[\"model\"] = OrderedDict()\n","\n","pipeline_binary[\"model\"][\"conv1\"] = {}\n","pipeline_binary[\"model\"][\"conv1\"][\"name\"] = \"conv\"\n","pipeline_binary[\"model\"][\"conv1\"][\"number_of_kernels\"] = 32\n","pipeline_binary[\"model\"][\"conv1\"][\"kernel_size\"] = 7\n","pipeline_binary[\"model\"][\"lrelu1\"] = {}\n","pipeline_binary[\"model\"][\"lrelu1\"][\"name\"] = \"lrelu\"\n","pipeline_binary[\"model\"][\"maxpool1\"] = {}\n","pipeline_binary[\"model\"][\"maxpool1\"][\"name\"] = \"max_pool\"\n","pipeline_binary[\"model\"][\"maxpool1\"][\"kernel_size\"] = 2\n","\n","\n","pipeline_binary[\"model\"][\"conv2\"] = {}\n","pipeline_binary[\"model\"][\"conv2\"][\"name\"] = \"conv\"\n","pipeline_binary[\"model\"][\"conv2\"][\"number_of_kernels\"] = 64\n","pipeline_binary[\"model\"][\"conv2\"][\"kernel_size\"] = 5\n","pipeline_binary[\"model\"][\"lrelu2\"] = {}\n","pipeline_binary[\"model\"][\"lrelu2\"][\"name\"] = \"lrelu\"\n","pipeline_binary[\"model\"][\"maxpool2\"] = {}\n","pipeline_binary[\"model\"][\"maxpool2\"][\"name\"] = \"max_pool\"\n","pipeline_binary[\"model\"][\"maxpool2\"][\"kernel_size\"] = 2\n","\n","\n","pipeline_binary[\"model\"][\"conv3\"] = {}\n","pipeline_binary[\"model\"][\"conv3\"][\"name\"] = \"conv\"\n","pipeline_binary[\"model\"][\"conv3\"][\"number_of_kernels\"] = 128\n","pipeline_binary[\"model\"][\"conv3\"][\"kernel_size\"] = 3\n","pipeline_binary[\"model\"][\"lrelu3\"] = {}\n","pipeline_binary[\"model\"][\"lrelu3\"][\"name\"] = \"lrelu\"\n","pipeline_binary[\"model\"][\"maxpool3\"] = {}\n","pipeline_binary[\"model\"][\"maxpool3\"][\"name\"] = \"max_pool\"\n","pipeline_binary[\"model\"][\"maxpool3\"][\"kernel_size\"] = 2\n","\n","pipeline_binary[\"model\"][\"flatten4\"] = {}\n","pipeline_binary[\"model\"][\"flatten4\"][\"name\"] = \"flatten\"\n","\n","pipeline_binary[\"model\"][\"linear5\"] = {}\n","pipeline_binary[\"model\"][\"linear5\"][\"name\"] = \"linear\"\n","pipeline_binary[\"model\"][\"linear5\"][\"neurons\"] = 256\n","pipeline_binary[\"model\"][\"lrelu5\"] = {}\n","pipeline_binary[\"model\"][\"lrelu5\"][\"name\"] = \"lrelu\"\n","\n","pipeline_binary[\"model\"][\"linear6\"] = {}\n","pipeline_binary[\"model\"][\"linear6\"][\"name\"] = \"linear\"\n","pipeline_binary[\"model\"][\"linear6\"][\"neurons\"] = 128\n","pipeline_binary[\"model\"][\"lrelu6\"] = {}\n","pipeline_binary[\"model\"][\"lrelu6\"][\"name\"] = \"lrelu\"\n","\n","pipeline_binary[\"model\"][\"output\"] = {}\n","pipeline_binary[\"model\"][\"output\"][\"name\"] = \"linear\"\n","pipeline_binary[\"model\"][\"output\"][\"neurons\"] = 2\n","\n","pipeline_binary[\"optimizer\"] = {}\n","pipeline_binary[\"optimizer\"][\"name\"] = \"adam\"\n","\n","pipeline_binary[\"loss\"] = {}\n","pipeline_binary[\"loss\"][\"type\"] = \"cross_entropy\"\n","pipeline_binary[\"loss\"][\"use_weighted_loss\"] = True\n","pipeline_binary[\"loss\"][\"use_single_neuron\"] = False\n","\n","#---------------------------------------------set up evaluation metrics and parameters------------------------\n","\n","\n","pipeline_binary[\"metrics\"] = {}\n","\n","# accuracy\n","pipeline_binary[\"metrics\"][\"simple_accuracy\"] = {}\n","pipeline_binary[\"metrics\"][\"simple_accuracy\"][\"name\"] = \"accuracy\"\n","pipeline_binary[\"metrics\"][\"simple_accuracy\"][\"type\"] = \"simple\"  \n","\n","pipeline_binary[\"metrics\"][\"balanced_accuracy\"] = {}\n","pipeline_binary[\"metrics\"][\"balanced_accuracy\"][\"name\"] = \"accuracy\"\n","pipeline_binary[\"metrics\"][\"balanced_accuracy\"][\"type\"] = \"balanced\"\n","\n","# precision\n","#pipeline_binary[\"metrics\"][\"precision\"] = {}\n","#pipeline_binary[\"metrics\"][\"precision\"][\"name\"] = \"precision\"\n","#pipeline_binary[\"metrics\"][\"precision\"][\"class_result\"] = \"COVID\"\n","\n","# recall\n","#pipeline_binary[\"metrics\"][\"sensitivity\"] = {}\n","#pipeline_binary[\"metrics\"][\"sensitivity\"][\"name\"] = \"sensitivity\"\n","#pipeline_binary[\"metrics\"][\"sensitivity\"][\"class_result\"]  = \"COVID\"\n","\n","# F1 score\n","#pipeline_binary[\"metrics\"][\"f1_score\"] = {}\n","#pipeline_binary[\"metrics\"][\"f1_score\"][\"name\"] = \"F1_score\" \n","#pipeline_binary[\"metrics\"][\"f1_score\"][\"class_result\"] = \"COVID\"\n","\n","# mcc\n","pipeline_binary[\"metrics\"][\"mcc\"] = {}\n","pipeline_binary[\"metrics\"][\"mcc\"][\"name\"] =\"mcc\" \n","\n","#------------------------------------------------Create Plots --------------------------\n","pipeline_binary[\"plots\"] = [\"CM\", \"LC\", \"MS\"]\n"]},{"cell_type":"code","execution_count":54,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-17T07:04:49.522240Z","iopub.status.busy":"2023-01-17T07:04:49.521864Z","iopub.status.idle":"2023-01-17T07:04:49.741186Z","shell.execute_reply":"2023-01-17T07:04:49.738757Z","shell.execute_reply.started":"2023-01-17T07:04:49.522209Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Device: cuda\n","Unique labels found and their frequencies: \n","Label: COVID, %age: 17.0821\n","Label: NO_COVID, %age: 82.9179\n","Splitting data using Simple Stratified with 70.0-30.0 ratio\n","Split the data successfully. Shape: y_train: (1, 11851, 2) y_valid: (1, 5079, 2)\n"]},{"ename":"TypeError","evalue":"empty(): argument 'size' must be tuple of ints, but found element of type float at pos 2","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/447289640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCNN_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken to train the model : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2054572214.py\u001b[0m in \u001b[0;36mCNN_training\u001b[0;34m(pipeline)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mmodel_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3336849452.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, layers)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3336849452.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Linear Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0march\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3336849452.py\u001b[0m in \u001b[0;36madd_linear\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     \u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_layer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                     \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                     bias = bias))\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_layer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of ints, but found element of type float at pos 2"]}],"source":["start = time.time()\n","CNN_training(pipeline_binary)\n","end = time.time()\n","print(\"Time taken to train the model : \", datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## test data "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.595280Z","iopub.status.idle":"2023-01-17T07:01:00.596154Z","shell.execute_reply":"2023-01-17T07:01:00.595899Z","shell.execute_reply.started":"2023-01-17T07:01:00.595863Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["path_to_json = os.path.join(path_to_binary_results, \"train\", \"training_pipeline.json\")\n","save_path = os.path.join(path_to_binary_results, \"test\")\n","\n","start = time.time()\n","CNN_prediction(path_to_test_data, path_to_json, save_path)\n","end = time.time()\n","print(\"Time taken to generate predictions on test data : \", datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## noisy test data "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.597987Z","iopub.status.idle":"2023-01-17T07:01:00.598531Z","shell.execute_reply":"2023-01-17T07:01:00.598261Z","shell.execute_reply.started":"2023-01-17T07:01:00.598238Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["path_to_json = os.path.join(path_to_binary_results, \"train\", \"training_pipeline.json\")\n","save_path = os.path.join(path_to_binary_results, \"noisy_test\")\n","\n","start = time.time()\n","CNN_prediction(path_to_noisy_test_data, path_to_json, save_path)\n","end = time.time()\n","print(\"Time taken to generate predictions on noisy test data : \", datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Multiclass Classification"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Train "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.600187Z","iopub.status.idle":"2023-01-17T07:01:00.602207Z","shell.execute_reply":"2023-01-17T07:01:00.601949Z","shell.execute_reply.started":"2023-01-17T07:01:00.601925Z"},"trusted":true},"outputs":[],"source":["pipeline_multi = {}\n","pipeline_multi[\"path_to_results\"] = os.path.join(path_to_multiclass_results, \"train\")\n","\n","pipeline_multi[\"batch_size\"] = 256\n","pipeline_multi[\"num_epochs\"] = 500\n","\n","# for model\n","pipeline_multi[\"input_shape\"] = (250, 250) \n","\n","# path to folder containing images \n","pipeline_multi[\"path_to_images\"] = path_to_train_data\n","# path to labels.txt\n","pipeline_multi[\"path_to_labels\"] = path_to_multi_labels\n","\n","# split data\n","pipeline_multi[\"split_type\"] = \"kfoldStratified\" #\"simpleStratified\" #\"simple\", \"simpleStratified\", \"kfold\", \"kfoldStratified\"\n","pipeline_multi[\"num_folds\"] = 5\n","\n","# names of the class\n","pipeline_multi[\"classes\"] = np.array([\"Normal\", \"COVID\", \"pneumonia\", \"Lung_Opacity\"])\n","\n","# ---------------------------------set up data preprocessing methods and parameters------------------------------------\n","pipeline_multi[\"data_preprocessing\"] = {}\n","pipeline_multi[\"data_preprocessing\"][\"train\"] = OrderedDict()\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"] = {}\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"name\"] = \"normalize\"\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"mean\"] = 0\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"normalize_0_1\"][\"std\"] = 255\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"resize\"] = {}\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"resize\"][\"name\"] = \"resize\"\n","pipeline_multi[\"data_preprocessing\"][\"train\"][\"resize\"][\"output_shape\"] = (250,250)\n","\n","pipeline_multi[\"data_preprocessing\"][\"valid\"] = OrderedDict()\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"] = {}\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"name\"] = \"normalize\"\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"mean\"] = 0\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"normalize_0_1\"][\"std\"] = 255\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"resize\"] = {}\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"resize\"][\"name\"] = \"resize\"\n","pipeline_multi[\"data_preprocessing\"][\"valid\"][\"resize\"][\"output_shape\"] = (250,250)\n","\n","\n","\n","\n","\n","# ---------------------------------set up networks and parameters------------------------------------\n","pipeline_multi[\"model\"] = OrderedDict()\n","\n","pipeline_multi[\"model\"][\"conv1\"] = {}\n","pipeline_multi[\"model\"][\"conv1\"][\"name\"] = \"conv\"\n","pipeline_multi[\"model\"][\"conv1\"][\"number_of_kernels\"] = 32\n","pipeline_multi[\"model\"][\"conv1\"][\"kernel_size\"] = 7\n","pipeline_multi[\"model\"][\"lrelu1\"] = {}\n","pipeline_multi[\"model\"][\"lrelu1\"][\"name\"] = \"lrelu\"\n","pipeline_multi[\"model\"][\"maxpool1\"] = {}\n","pipeline_multi[\"model\"][\"maxpool1\"][\"name\"] = \"max_pool\"\n","pipeline_multi[\"model\"][\"maxpool1\"][\"kernel_size\"] = 2\n","\n","\n","pipeline_multi[\"model\"][\"conv2\"] = {}\n","pipeline_multi[\"model\"][\"conv2\"][\"name\"] = \"conv\"\n","pipeline_multi[\"model\"][\"conv2\"][\"number_of_kernels\"] = 64\n","pipeline_multi[\"model\"][\"conv2\"][\"kernel_size\"] = 5\n","pipeline_multi[\"model\"][\"lrelu2\"] = {}\n","pipeline_multi[\"model\"][\"lrelu2\"][\"name\"] = \"lrelu\"\n","pipeline_multi[\"model\"][\"maxpool2\"] = {}\n","pipeline_multi[\"model\"][\"maxpool2\"][\"name\"] = \"max_pool\"\n","pipeline_multi[\"model\"][\"maxpool2\"][\"kernel_size\"] = 2\n","\n","\n","pipeline_multi[\"model\"][\"conv3\"] = {}\n","pipeline_multi[\"model\"][\"conv3\"][\"name\"] = \"conv\"\n","pipeline_multi[\"model\"][\"conv3\"][\"number_of_kernels\"] = 128\n","pipeline_multi[\"model\"][\"conv3\"][\"kernel_size\"] = 3\n","pipeline_multi[\"model\"][\"lrelu3\"] = {}\n","pipeline_multi[\"model\"][\"lrelu3\"][\"name\"] = \"lrelu\"\n","pipeline_multi[\"model\"][\"maxpool3\"] = {}\n","pipeline_multi[\"model\"][\"maxpool3\"][\"name\"] = \"max_pool\"\n","pipeline_multi[\"model\"][\"maxpool3\"][\"kernel_size\"] = 2\n","\n","pipeline_multi[\"model\"][\"flatten4\"] = {}\n","pipeline_multi[\"model\"][\"flatten4\"][\"name\"] = \"flatten\"\n","\n","pipeline_multi[\"model\"][\"linear5\"] = {}\n","pipeline_multi[\"model\"][\"linear5\"][\"name\"] = \"linear\"\n","pipeline_multi[\"model\"][\"linear5\"][\"neurons\"] = 256\n","pipeline_multi[\"model\"][\"lrelu5\"] = {}\n","pipeline_multi[\"model\"][\"lrelu5\"][\"name\"] = \"lrelu\"\n","\n","pipeline_multi[\"model\"][\"linear6\"] = {}\n","pipeline_multi[\"model\"][\"linear6\"][\"name\"] = \"linear\"\n","pipeline_multi[\"model\"][\"linear6\"][\"neurons\"] = 128\n","pipeline_multi[\"model\"][\"lrelu6\"] = {}\n","pipeline_multi[\"model\"][\"lrelu6\"][\"name\"] = \"lrelu\"\n","\n","pipeline_multi[\"model\"][\"output\"] = {}\n","pipeline_multi[\"model\"][\"output\"][\"name\"] = \"linear\"\n","pipeline_multi[\"model\"][\"output\"][\"neurons\"] = 4\n","\n","pipeline_multi[\"optimizer\"] = {}\n","pipeline_multi[\"optimizer\"][\"name\"] = \"adam\"\n","\n","pipeline_multi[\"loss\"] = {}\n","pipeline_multi[\"loss\"][\"type\"] = \"cross_entropy\"\n","pipeline_multi[\"loss\"][\"use_weighted_loss\"] = True\n","pipeline_multi[\"loss\"][\"use_single_neuron\"] = False\n","\n","\n","\n","#---------------------------------------------set up evaluation metrics and parameters------------------------\n","\n","\n","pipeline_multi[\"metrics\"] = {}\n","\n","# accuracy\n","pipeline_multi[\"metrics\"][\"simple_accuracy\"] = {}\n","pipeline_multi[\"metrics\"][\"simple_accuracy\"][\"name\"] = \"accuracy\"\n","pipeline_multi[\"metrics\"][\"simple_accuracy\"][\"type\"] = \"simple\"  \n","\n","pipeline_multi[\"metrics\"][\"balanced_accuracy\"] = {}\n","pipeline_multi[\"metrics\"][\"balanced_accuracy\"][\"name\"] = \"accuracy\"\n","pipeline_multi[\"metrics\"][\"balanced_accuracy\"][\"type\"] = \"balanced\"\n","\n","# precision\n","#pipeline_multi[\"metrics\"][\"precision\"] = {}\n","#pipeline_multi[\"metrics\"][\"precision\"][\"name\"] = \"precision\"\n","#pipeline_multi[\"metrics\"][\"precision\"][\"class_result\"] = \"COVID\"\n","\n","# recall\n","#pipeline_multi[\"metrics\"][\"sensitivity\"] = {}\n","#pipeline_multi[\"metrics\"][\"sensitivity\"][\"name\"] = \"sensitivity\"\n","#pipeline_multi[\"metrics\"][\"sensitivity\"][\"class_result\"]  = \"COVID\"\n","\n","# F1 score\n","#pipeline_multi[\"metrics\"][\"f1_score\"] = {}\n","#pipeline_multi[\"metrics\"][\"f1_score\"][\"name\"] = \"F1_score\" \n","#pipeline_multi[\"metrics\"][\"f1_score\"][\"class_result\"] = \"COVID\"\n","\n","# mcc\n","pipeline_multi[\"metrics\"][\"mcc\"] = {}\n","pipeline_multi[\"metrics\"][\"mcc\"][\"name\"] =\"mcc\" \n","\n","#------------------------------------------------Create Plots --------------------------\n","pipeline_multi[\"plots\"] = [\"CM\", \"LC\", \"MS\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.603717Z","iopub.status.idle":"2023-01-17T07:01:00.604231Z","shell.execute_reply":"2023-01-17T07:01:00.603997Z","shell.execute_reply.started":"2023-01-17T07:01:00.603973Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["start =time.time()\n","CNN_training(pipeline_multi)\n","end = time.time()\n","print(\"Time taken to train the model : \", datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Test data "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.605998Z","iopub.status.idle":"2023-01-17T07:01:00.606486Z","shell.execute_reply":"2023-01-17T07:01:00.606269Z","shell.execute_reply.started":"2023-01-17T07:01:00.606246Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["path_to_json = os.path.join(path_to_multiclass_results, \"train\", \"training_pipeline.json\")\n","save_path = os.path.join(path_to_multiclass_results, \"test\")\n","\n","start = time.time()\n","CNN_prediction(path_to_test_data, path_to_json, save_path)\n","end = time.time()\n","print(\"Time taken to generate predicitons on test data: \",  datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Noisy data "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.607864Z","iopub.status.idle":"2023-01-17T07:01:00.608663Z","shell.execute_reply":"2023-01-17T07:01:00.608403Z","shell.execute_reply.started":"2023-01-17T07:01:00.608379Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["save_path = os.path.join(path_to_multiclass_results, \"noisy_test\")\n","\n","start = time.time()\n","CNN_prediction(path_to_noisy_test_data, path_to_json, save_path)\n","end = time.time()\n","print(\"Time taken to generate predicitons on noisy test data: \", datetime.timedelta(seconds=end-start))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Create zip file"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.610693Z","iopub.status.idle":"2023-01-17T07:01:00.611212Z","shell.execute_reply":"2023-01-17T07:01:00.610975Z","shell.execute_reply.started":"2023-01-17T07:01:00.610949Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["cmd = \"tar -zcvf \" + path_to_results + \".tar.gz \" + path_to_results\n","os.system(cmd)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Joel code"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.612992Z","iopub.status.idle":"2023-01-17T07:01:00.613490Z","shell.execute_reply":"2023-01-17T07:01:00.613258Z","shell.execute_reply.started":"2023-01-17T07:01:00.613234Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["raise ValueError(\"Entering Joel Code\")"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.621179Z","iopub.status.idle":"2023-01-17T07:01:00.621592Z","shell.execute_reply":"2023-01-17T07:01:00.621375Z","shell.execute_reply.started":"2023-01-17T07:01:00.621354Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import os\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import torch\n","from skimage import io, transform\n","\n","from PIL import Image\n","\n","class2id = test_count = {'Normal': 0, 'COVID': 1, 'pneumonia': 2, 'Lung_Opacity': 3}\n","\n","id2class = {0: 'Normal', 1: 'COVID', 2: 'pneumonia', 3:'Lung_Opacity'}\n","\n","class COVIDxDataset(Dataset):\n","    def __init__(self, txt_frame_file, images_path, transform=None):\n","        \"\"\"\n","        Args:\n","            txt_frame_file (string): Path to the txt files with labels.\n","            images_path (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.covidx_frame = pd.read_csv(txt_frame_file, delim_whitespace=True) \n","        \n","        #self.landmarks_frame = pd.read_csv(csv_file)\n","        self.root_dir = images_path\n","        self.transform = transform\n","        self.class2id = test_count = {'Normal': 0, 'COVID': 1, 'pneumonia': 2, 'Lung_Opacity': 3}\n","        self.id2class = {0: 'Normal', 1: 'COVID', 2: 'pneumonia', 3:'Lung_Opacity'}\n","        \n","        \n","    def pil_loader(self, path):\n","        with open(path, 'rb') as f:\n","            img = Image.open(f)\n","            return img.convert('RGB')\n","        \n","    \n","    def __len__(self):\n","        return len(self.covidx_frame)\n","    \n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        image_path = os.path.join(self.root_dir,\n","                                self.covidx_frame.iloc[idx, 1])\n","        #print(img_name)\n","        \n","        image = self.pil_loader(image_path)\n","        #image = io.imread(img_name)\n","        \n","        \n","        label = self.covidx_frame.iloc[idx, 2]\n","        #landmarks = np.array([landmarks])\n","        #landmarks = landmarks.astype('float').reshape(-1, 2)\n","        #sample = {'image': image, 'label': label}\n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","            \n","        sample = (image, self.class2id[label])\n","\n","        return sample\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.623110Z","iopub.status.idle":"2023-01-17T07:01:00.623805Z","shell.execute_reply":"2023-01-17T07:01:00.623576Z","shell.execute_reply.started":"2023-01-17T07:01:00.623552Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms, utils\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","import math\n","\n","from torch.utils.data import random_split"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.625094Z","iopub.status.idle":"2023-01-17T07:01:00.625808Z","shell.execute_reply":"2023-01-17T07:01:00.625556Z","shell.execute_reply.started":"2023-01-17T07:01:00.625533Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["model_name = 'resnet'\n","batch_size = 32\n","num_epochs = 10\n","feature_extract = True\n","\n","#TODO: get automatically these parameters\n","num_classes = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.627181Z","iopub.status.idle":"2023-01-17T07:01:00.627881Z","shell.execute_reply":"2023-01-17T07:01:00.627642Z","shell.execute_reply.started":"2023-01-17T07:01:00.627619Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs = 25, is_inception= False):\n","    since = time.time()\n","    \n","    val_acc_history = []\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs -1))\n","        \n","        #Each epoch as a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            \n","            # Iterate over data\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                \n","                #zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                #forward\n","                # track history\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    \n","                    if is_inception and phase == 'train':\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                        \n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                        \n","                    _, preds = torch.max(outputs, 1)\n","                    \n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                #statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                \n","            epoch_loss = running_loss /len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","            \n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","            \n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","            \n","        print()\n","        \n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:.4f}'.format(best_acc))\n","    \n","    #load the best model\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.629149Z","iopub.status.idle":"2023-01-17T07:01:00.629903Z","shell.execute_reply":"2023-01-17T07:01:00.629662Z","shell.execute_reply.started":"2023-01-17T07:01:00.629639Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# set model parameters\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.631198Z","iopub.status.idle":"2023-01-17T07:01:00.631916Z","shell.execute_reply":"2023-01-17T07:01:00.631666Z","shell.execute_reply.started":"2023-01-17T07:01:00.631642Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"alexnet\":\n","        \"\"\" Alexnet\n","        \"\"\"\n","        model_ft = models.alexnet(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"vgg\":\n","        \"\"\" VGG11_bn\n","        \"\"\"\n","        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"squeezenet\":\n","        \"\"\" Squeezenet\n","        \"\"\"\n","        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n","        model_ft.num_classes = num_classes\n","        input_size = 224\n","\n","    elif model_name == \"densenet\":\n","        \"\"\" Densenet\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        num_ftrs = model_ft.AuxLogits.fc.in_features\n","        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n","        input_size = 299\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.633180Z","iopub.status.idle":"2023-01-17T07:01:00.633906Z","shell.execute_reply":"2023-01-17T07:01:00.633659Z","shell.execute_reply.started":"2023-01-17T07:01:00.633635Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# Initialize the model for this run\n","#model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","#print(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.635173Z","iopub.status.idle":"2023-01-17T07:01:00.635914Z","shell.execute_reply":"2023-01-17T07:01:00.635646Z","shell.execute_reply.started":"2023-01-17T07:01:00.635622Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.637230Z","iopub.status.idle":"2023-01-17T07:01:00.637939Z","shell.execute_reply":"2023-01-17T07:01:00.637704Z","shell.execute_reply.started":"2023-01-17T07:01:00.637680Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# Load Data\n","\n","# configure paths to the description txt file and the images folder\n","#train_txt_file = '/kaggle/input/ismdatasetforclassificationofdieases/ism_dataset/raw_data/train_multi.txt'\n","#train_images_path = '/kaggle/input/ismdatasetforclassificationofdieases/ism_dataset/raw_data/train'\n","\n","#test_txt_file = '../COVID-Net/test_split_v2.txt'\n","#test_images_path = '../covid-chestxray-dataset/data/test'\n","\n","#train_dataset = covidx.COVIDxDataset(train_txt_file, train_images_path)\n","#test_dataset = covidx.COVIDxDataset(val_txt_file, val_images_path)\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","batch_size = 128\n","val_size = 150\n","\n","#training_dataset = COVIDxDataset(train_txt_file, train_images_path)\n","#val_size =  math.floor(len(training_dataset)*0.3)\n","#train_size = len(training_dataset) - val_size\n","#train_data,val_data = random_split(training_dataset,[train_size,val_size])\n","\n","#image_datasets = {'train': train_data, 'val': val_data}\n","#image_datasets = {'train': covidx.COVIDxDataset(train_txt_file, train_images_path, data_transforms['train']), 'val': covidx.COVIDxDataset(test_txt_file, test_images_path, data_transforms['val'])}\n","#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","# Create training and validation dataloaders\n","#dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}\n","\n","#print(dataloaders_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.639305Z","iopub.status.idle":"2023-01-17T07:01:00.640120Z","shell.execute_reply":"2023-01-17T07:01:00.639872Z","shell.execute_reply.started":"2023-01-17T07:01:00.639844Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T07:01:00.641484Z","iopub.status.idle":"2023-01-17T07:01:00.642279Z","shell.execute_reply":"2023-01-17T07:01:00.642004Z","shell.execute_reply.started":"2023-01-17T07:01:00.641980Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# create the optimizer\n","\n","#model_ft = model_ft.to(device)\n","\n","#params_to_update = model_ft.parameters()\n","#print(\"Params to learn\")\n","\n","#if feature_extract:\n","#    params_to_update = []\n","#    for name, param in model_ft.named_parameters():\n","#        if param.requires_grad == True:\n","#            params_to_update.append(param)\n","#            print(\"\\t\", name)\n","#else:\n","#    for name, param in model_ft.named_parameters():\n"," #       if param.requires_grad == True:\n","  #          print(\"\\t\", name)\n"," #           \n","#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum = 0.9)\n","#criterion = nn.CrossEntropyLoss()\n","\n","#model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs = num_epochs, is_inception=(model_name==\"inception\"))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('ISM': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"1245e537f49f36515f2fe2ada6417b5ef8f3abea8876a4d93eabac15ef0e31b7"}}},"nbformat":4,"nbformat_minor":4}
